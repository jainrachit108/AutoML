2023-04-25 12:49:15,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 12:49:15,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 12:49:15,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 12:49:15,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 12:49:16,494:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-25 12:50:01,241:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pandas_profiling\visualisation\utils.py:73: UserWarning: Glyph 9 (	) missing from current font.
  plt.savefig(

2023-04-25 12:50:01,541:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pandas_profiling\visualisation\utils.py:73: UserWarning: Glyph 9 (	) missing from current font.
  plt.savefig(

2023-04-25 12:50:02,268:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pandas_profiling\visualisation\utils.py:73: UserWarning: Glyph 9 (	) missing from current font.
  plt.savefig(

2023-04-25 12:51:20,691:INFO:PyCaret RegressionExperiment
2023-04-25 12:51:20,691:INFO:Logging name: reg-default-name
2023-04-25 12:51:20,691:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-25 12:51:20,691:INFO:version 3.0.0
2023-04-25 12:51:20,691:INFO:Initializing setup()
2023-04-25 12:51:20,691:INFO:self.USI: 97e1
2023-04-25 12:51:20,691:INFO:self._variable_keys: {'html_param', '_ml_usecase', 'X_test', 'n_jobs_param', 'exp_name_log', 'memory', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param', 'USI', 'seed', 'X_train', 'X', 'gpu_param', 'pipeline', 'target_param', 'data', 'idx', 'fold_groups_param', 'transform_target_param', 'y_train', 'fold_shuffle_param', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_id'}
2023-04-25 12:51:20,691:INFO:Checking environment
2023-04-25 12:51:20,691:INFO:python_version: 3.9.12
2023-04-25 12:51:20,691:INFO:python_build: ('main', 'Apr  4 2022 05:22:27')
2023-04-25 12:51:20,691:INFO:machine: AMD64
2023-04-25 12:51:20,703:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-25 12:51:20,703:INFO:Memory: svmem(total=8362713088, available=1079263232, percent=87.1, used=7283449856, free=1079263232)
2023-04-25 12:51:20,703:INFO:Physical Core: 4
2023-04-25 12:51:20,703:INFO:Logical Core: 8
2023-04-25 12:51:20,703:INFO:Checking libraries
2023-04-25 12:51:20,703:INFO:System:
2023-04-25 12:51:20,703:INFO:    python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]
2023-04-25 12:51:20,703:INFO:executable: C:\Users\91888\anaconda3\python.exe
2023-04-25 12:51:20,703:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-25 12:51:20,703:INFO:PyCaret required dependencies:
2023-04-25 12:51:20,704:INFO:                 pip: 21.2.4
2023-04-25 12:51:20,704:INFO:          setuptools: 61.2.0
2023-04-25 12:51:20,704:INFO:             pycaret: 3.0.0
2023-04-25 12:51:20,704:INFO:             IPython: 8.2.0
2023-04-25 12:51:20,704:INFO:          ipywidgets: 7.6.5
2023-04-25 12:51:20,704:INFO:                tqdm: 4.64.0
2023-04-25 12:51:20,704:INFO:               numpy: 1.21.5
2023-04-25 12:51:20,704:INFO:              pandas: 1.4.2
2023-04-25 12:51:20,704:INFO:              jinja2: 2.11.3
2023-04-25 12:51:20,704:INFO:               scipy: 1.7.3
2023-04-25 12:51:20,704:INFO:              joblib: 1.2.0
2023-04-25 12:51:20,704:INFO:             sklearn: 1.0.2
2023-04-25 12:51:20,704:INFO:                pyod: 1.0.9
2023-04-25 12:51:20,704:INFO:            imblearn: 0.10.1
2023-04-25 12:51:20,704:INFO:   category_encoders: 2.6.0
2023-04-25 12:51:20,704:INFO:            lightgbm: 3.3.5
2023-04-25 12:51:20,704:INFO:               numba: 0.55.1
2023-04-25 12:51:20,704:INFO:            requests: 2.27.1
2023-04-25 12:51:20,704:INFO:          matplotlib: 3.5.1
2023-04-25 12:51:20,704:INFO:          scikitplot: 0.3.7
2023-04-25 12:51:20,704:INFO:         yellowbrick: 1.5
2023-04-25 12:51:20,704:INFO:              plotly: 5.6.0
2023-04-25 12:51:20,704:INFO:             kaleido: 0.2.1
2023-04-25 12:51:20,704:INFO:         statsmodels: 0.13.2
2023-04-25 12:51:20,704:INFO:              sktime: 0.17.1
2023-04-25 12:51:20,704:INFO:               tbats: 1.1.3
2023-04-25 12:51:20,705:INFO:            pmdarima: 2.0.3
2023-04-25 12:51:20,705:INFO:              psutil: 5.9.5
2023-04-25 12:51:20,705:INFO:PyCaret optional dependencies:
2023-04-25 12:51:20,712:INFO:                shap: Not installed
2023-04-25 12:51:20,712:INFO:           interpret: Not installed
2023-04-25 12:51:20,712:INFO:                umap: Not installed
2023-04-25 12:51:20,712:INFO:    pandas_profiling: 4.1.2
2023-04-25 12:51:20,712:INFO:  explainerdashboard: Not installed
2023-04-25 12:51:20,712:INFO:             autoviz: Not installed
2023-04-25 12:51:20,712:INFO:           fairlearn: Not installed
2023-04-25 12:51:20,712:INFO:             xgboost: Not installed
2023-04-25 12:51:20,712:INFO:            catboost: Not installed
2023-04-25 12:51:20,712:INFO:              kmodes: Not installed
2023-04-25 12:51:20,712:INFO:             mlxtend: Not installed
2023-04-25 12:51:20,713:INFO:       statsforecast: Not installed
2023-04-25 12:51:20,713:INFO:        tune_sklearn: Not installed
2023-04-25 12:51:20,713:INFO:                 ray: Not installed
2023-04-25 12:51:20,713:INFO:            hyperopt: Not installed
2023-04-25 12:51:20,713:INFO:              optuna: Not installed
2023-04-25 12:51:20,713:INFO:               skopt: Not installed
2023-04-25 12:51:20,713:INFO:              mlflow: Not installed
2023-04-25 12:51:20,713:INFO:              gradio: Not installed
2023-04-25 12:51:20,713:INFO:             fastapi: Not installed
2023-04-25 12:51:20,713:INFO:             uvicorn: Not installed
2023-04-25 12:51:20,713:INFO:              m2cgen: Not installed
2023-04-25 12:51:20,713:INFO:           evidently: Not installed
2023-04-25 12:51:20,713:INFO:               fugue: Not installed
2023-04-25 12:51:20,713:INFO:           streamlit: 1.21.0
2023-04-25 12:51:20,713:INFO:             prophet: Not installed
2023-04-25 12:51:20,713:INFO:None
2023-04-25 12:51:20,713:INFO:Set up data.
2023-04-25 12:51:20,720:INFO:Set up train/test split.
2023-04-25 12:51:20,729:INFO:Set up index.
2023-04-25 12:51:20,729:INFO:Set up folding strategy.
2023-04-25 12:51:20,729:INFO:Assigning column types.
2023-04-25 12:51:20,732:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-25 12:51:20,732:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 12:51:20,736:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 12:51:20,740:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 12:51:20,793:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 12:51:20,829:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 12:51:20,830:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:51:20,870:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:51:20,871:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 12:51:20,875:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 12:51:20,879:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 12:51:20,932:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 12:51:20,969:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 12:51:20,969:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:51:20,970:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:51:20,970:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-25 12:51:20,974:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 12:51:20,978:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 12:51:21,030:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 12:51:21,068:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 12:51:21,068:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:51:21,069:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:51:21,072:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 12:51:21,077:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 12:51:21,124:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 12:51:21,162:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 12:51:21,162:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:51:21,162:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:51:21,162:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-25 12:51:21,170:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 12:51:21,217:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 12:51:21,255:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 12:51:21,255:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:51:21,255:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:51:21,263:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 12:51:21,313:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 12:51:21,349:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 12:51:21,350:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:51:21,350:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:51:21,350:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-25 12:51:21,406:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 12:51:21,445:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 12:51:21,446:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:51:21,446:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:51:21,507:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 12:51:21,543:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 12:51:21,543:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:51:21,544:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:51:21,544:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-25 12:51:21,597:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 12:51:21,632:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:51:21,632:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:51:21,686:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 12:51:21,722:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:51:21,722:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:51:21,722:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-25 12:51:21,832:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:51:21,832:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:51:21,927:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:51:21,927:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:51:21,929:INFO:Preparing preprocessing pipeline...
2023-04-25 12:51:21,929:INFO:Set up simple imputation.
2023-04-25 12:51:21,934:INFO:Set up encoding of ordinal features.
2023-04-25 12:51:21,940:INFO:Set up encoding of categorical features.
2023-04-25 12:52:38,787:INFO:PyCaret RegressionExperiment
2023-04-25 12:52:38,787:INFO:Logging name: reg-default-name
2023-04-25 12:52:38,787:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-25 12:52:38,787:INFO:version 3.0.0
2023-04-25 12:52:38,787:INFO:Initializing setup()
2023-04-25 12:52:38,787:INFO:self.USI: ceae
2023-04-25 12:52:38,787:INFO:self._variable_keys: {'html_param', '_ml_usecase', 'X_test', 'n_jobs_param', 'exp_name_log', 'memory', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param', 'USI', 'seed', 'X_train', 'X', 'gpu_param', 'pipeline', 'target_param', 'data', 'idx', 'fold_groups_param', 'transform_target_param', 'y_train', 'fold_shuffle_param', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_id'}
2023-04-25 12:52:38,787:INFO:Checking environment
2023-04-25 12:52:38,787:INFO:python_version: 3.9.12
2023-04-25 12:52:38,787:INFO:python_build: ('main', 'Apr  4 2022 05:22:27')
2023-04-25 12:52:38,788:INFO:machine: AMD64
2023-04-25 12:52:38,788:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-25 12:52:38,788:INFO:Memory: svmem(total=8362713088, available=1144754176, percent=86.3, used=7217958912, free=1144754176)
2023-04-25 12:52:38,788:INFO:Physical Core: 4
2023-04-25 12:52:38,788:INFO:Logical Core: 8
2023-04-25 12:52:38,788:INFO:Checking libraries
2023-04-25 12:52:38,788:INFO:System:
2023-04-25 12:52:38,788:INFO:    python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]
2023-04-25 12:52:38,788:INFO:executable: C:\Users\91888\anaconda3\python.exe
2023-04-25 12:52:38,788:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-25 12:52:38,788:INFO:PyCaret required dependencies:
2023-04-25 12:52:38,788:INFO:                 pip: 21.2.4
2023-04-25 12:52:38,788:INFO:          setuptools: 61.2.0
2023-04-25 12:52:38,788:INFO:             pycaret: 3.0.0
2023-04-25 12:52:38,788:INFO:             IPython: 8.2.0
2023-04-25 12:52:38,788:INFO:          ipywidgets: 7.6.5
2023-04-25 12:52:38,788:INFO:                tqdm: 4.64.0
2023-04-25 12:52:38,788:INFO:               numpy: 1.21.5
2023-04-25 12:52:38,788:INFO:              pandas: 1.4.2
2023-04-25 12:52:38,788:INFO:              jinja2: 2.11.3
2023-04-25 12:52:38,788:INFO:               scipy: 1.7.3
2023-04-25 12:52:38,788:INFO:              joblib: 1.2.0
2023-04-25 12:52:38,788:INFO:             sklearn: 1.0.2
2023-04-25 12:52:38,788:INFO:                pyod: 1.0.9
2023-04-25 12:52:38,788:INFO:            imblearn: 0.10.1
2023-04-25 12:52:38,788:INFO:   category_encoders: 2.6.0
2023-04-25 12:52:38,789:INFO:            lightgbm: 3.3.5
2023-04-25 12:52:38,789:INFO:               numba: 0.55.1
2023-04-25 12:52:38,789:INFO:            requests: 2.27.1
2023-04-25 12:52:38,789:INFO:          matplotlib: 3.5.1
2023-04-25 12:52:38,789:INFO:          scikitplot: 0.3.7
2023-04-25 12:52:38,789:INFO:         yellowbrick: 1.5
2023-04-25 12:52:38,789:INFO:              plotly: 5.6.0
2023-04-25 12:52:38,789:INFO:             kaleido: 0.2.1
2023-04-25 12:52:38,789:INFO:         statsmodels: 0.13.2
2023-04-25 12:52:38,789:INFO:              sktime: 0.17.1
2023-04-25 12:52:38,789:INFO:               tbats: 1.1.3
2023-04-25 12:52:38,789:INFO:            pmdarima: 2.0.3
2023-04-25 12:52:38,789:INFO:              psutil: 5.9.5
2023-04-25 12:52:38,789:INFO:PyCaret optional dependencies:
2023-04-25 12:52:38,789:INFO:                shap: Not installed
2023-04-25 12:52:38,789:INFO:           interpret: Not installed
2023-04-25 12:52:38,789:INFO:                umap: Not installed
2023-04-25 12:52:38,789:INFO:    pandas_profiling: 4.1.2
2023-04-25 12:52:38,789:INFO:  explainerdashboard: Not installed
2023-04-25 12:52:38,790:INFO:             autoviz: Not installed
2023-04-25 12:52:38,790:INFO:           fairlearn: Not installed
2023-04-25 12:52:38,790:INFO:             xgboost: Not installed
2023-04-25 12:52:38,790:INFO:            catboost: Not installed
2023-04-25 12:52:38,790:INFO:              kmodes: Not installed
2023-04-25 12:52:38,790:INFO:             mlxtend: Not installed
2023-04-25 12:52:38,790:INFO:       statsforecast: Not installed
2023-04-25 12:52:38,790:INFO:        tune_sklearn: Not installed
2023-04-25 12:52:38,790:INFO:                 ray: Not installed
2023-04-25 12:52:38,790:INFO:            hyperopt: Not installed
2023-04-25 12:52:38,790:INFO:              optuna: Not installed
2023-04-25 12:52:38,790:INFO:               skopt: Not installed
2023-04-25 12:52:38,790:INFO:              mlflow: Not installed
2023-04-25 12:52:38,790:INFO:              gradio: Not installed
2023-04-25 12:52:38,790:INFO:             fastapi: Not installed
2023-04-25 12:52:38,790:INFO:             uvicorn: Not installed
2023-04-25 12:52:38,790:INFO:              m2cgen: Not installed
2023-04-25 12:52:38,790:INFO:           evidently: Not installed
2023-04-25 12:52:38,790:INFO:               fugue: Not installed
2023-04-25 12:52:38,790:INFO:           streamlit: 1.21.0
2023-04-25 12:52:38,790:INFO:             prophet: Not installed
2023-04-25 12:52:38,790:INFO:None
2023-04-25 12:52:38,790:INFO:Set up data.
2023-04-25 12:52:38,793:INFO:Set up train/test split.
2023-04-25 12:52:38,796:INFO:Set up index.
2023-04-25 12:52:38,796:INFO:Set up folding strategy.
2023-04-25 12:52:38,796:INFO:Assigning column types.
2023-04-25 12:52:38,799:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-25 12:52:38,799:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 12:52:38,804:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 12:52:38,811:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 12:52:38,869:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 12:52:38,912:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 12:52:38,912:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:38,913:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:38,913:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 12:52:38,917:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 12:52:38,931:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 12:52:38,995:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 12:52:39,059:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 12:52:39,060:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:39,060:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:39,060:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-25 12:52:39,066:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 12:52:39,070:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 12:52:39,137:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 12:52:39,211:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 12:52:39,212:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:39,212:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:39,219:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 12:52:39,228:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 12:52:39,311:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 12:52:39,354:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 12:52:39,355:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:39,355:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:39,355:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-25 12:52:39,364:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 12:52:39,434:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 12:52:39,489:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 12:52:39,490:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:39,490:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:39,499:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 12:52:39,568:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 12:52:39,623:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 12:52:39,624:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:39,624:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:39,625:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-25 12:52:39,695:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 12:52:39,758:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 12:52:39,759:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:39,759:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:39,878:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 12:52:39,933:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 12:52:39,934:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:39,934:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:39,935:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-25 12:52:40,048:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 12:52:40,117:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:40,117:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:40,195:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 12:52:40,248:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:40,248:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:40,249:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-25 12:52:40,383:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:40,383:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:40,524:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:40,524:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:40,525:INFO:Preparing preprocessing pipeline...
2023-04-25 12:52:40,525:INFO:Set up simple imputation.
2023-04-25 12:52:40,536:INFO:Finished creating preprocessing pipeline.
2023-04-25 12:52:40,542:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\91888\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['TV', 'Radio', 'Newspaper'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-04-25 12:52:40,542:INFO:Creating final display dataframe.
2023-04-25 12:52:40,596:INFO:Setup _display_container:                     Description             Value
0                    Session id              8980
1                        Target             Sales
2                   Target type        Regression
3           Original data shape          (200, 4)
4        Transformed data shape          (200, 4)
5   Transformed train set shape          (140, 4)
6    Transformed test set shape           (60, 4)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              ceae
2023-04-25 12:52:40,806:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:40,807:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:40,984:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:40,985:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 12:52:40,985:INFO:setup() successfully completed in 2.2s...............
2023-04-25 12:52:40,993:INFO:Initializing compare_models()
2023-04-25 12:52:40,993:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF921E5B0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000017CF921E5B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-25 12:52:40,993:INFO:Checking exceptions
2023-04-25 12:52:40,996:INFO:Preparing display monitor
2023-04-25 12:52:41,002:INFO:Initializing Linear Regression
2023-04-25 12:52:41,002:INFO:Total runtime is 0.0 minutes
2023-04-25 12:52:41,002:INFO:SubProcess create_model() called ==================================
2023-04-25 12:52:41,003:INFO:Initializing create_model()
2023-04-25 12:52:41,003:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF921E5B0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF91E6910>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 12:52:41,003:INFO:Checking exceptions
2023-04-25 12:52:41,003:INFO:Importing libraries
2023-04-25 12:52:41,003:INFO:Copying training dataset
2023-04-25 12:52:41,007:INFO:Defining folds
2023-04-25 12:52:41,007:INFO:Declaring metric variables
2023-04-25 12:52:41,007:INFO:Importing untrained model
2023-04-25 12:52:41,007:INFO:Linear Regression Imported successfully
2023-04-25 12:52:41,007:INFO:Starting cross validation
2023-04-25 12:52:41,019:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 12:52:47,270:INFO:Calculating mean and std
2023-04-25 12:52:47,270:INFO:Creating metrics dataframe
2023-04-25 12:52:47,274:INFO:Uploading results into container
2023-04-25 12:52:47,274:INFO:Uploading model into container now
2023-04-25 12:52:47,274:INFO:_master_model_container: 1
2023-04-25 12:52:47,275:INFO:_display_container: 2
2023-04-25 12:52:47,275:INFO:LinearRegression(n_jobs=-1)
2023-04-25 12:52:47,275:INFO:create_model() successfully completed......................................
2023-04-25 12:52:47,451:INFO:SubProcess create_model() end ==================================
2023-04-25 12:52:47,452:INFO:Creating metrics dataframe
2023-04-25 12:52:47,466:INFO:Initializing Lasso Regression
2023-04-25 12:52:47,467:INFO:Total runtime is 0.10775620539983113 minutes
2023-04-25 12:52:47,467:INFO:SubProcess create_model() called ==================================
2023-04-25 12:52:47,468:INFO:Initializing create_model()
2023-04-25 12:52:47,468:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF921E5B0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF91E6910>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 12:52:47,468:INFO:Checking exceptions
2023-04-25 12:52:47,469:INFO:Importing libraries
2023-04-25 12:52:47,469:INFO:Copying training dataset
2023-04-25 12:52:47,477:INFO:Defining folds
2023-04-25 12:52:47,477:INFO:Declaring metric variables
2023-04-25 12:52:47,477:INFO:Importing untrained model
2023-04-25 12:52:47,478:INFO:Lasso Regression Imported successfully
2023-04-25 12:52:47,478:INFO:Starting cross validation
2023-04-25 12:52:47,480:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 12:52:47,641:INFO:Calculating mean and std
2023-04-25 12:52:47,641:INFO:Creating metrics dataframe
2023-04-25 12:52:47,645:INFO:Uploading results into container
2023-04-25 12:52:47,646:INFO:Uploading model into container now
2023-04-25 12:52:47,646:INFO:_master_model_container: 2
2023-04-25 12:52:47,646:INFO:_display_container: 2
2023-04-25 12:52:47,646:INFO:Lasso(random_state=8980)
2023-04-25 12:52:47,646:INFO:create_model() successfully completed......................................
2023-04-25 12:52:47,814:INFO:SubProcess create_model() end ==================================
2023-04-25 12:52:47,814:INFO:Creating metrics dataframe
2023-04-25 12:52:47,818:INFO:Initializing Ridge Regression
2023-04-25 12:52:47,818:INFO:Total runtime is 0.11360400517781576 minutes
2023-04-25 12:52:47,818:INFO:SubProcess create_model() called ==================================
2023-04-25 12:52:47,819:INFO:Initializing create_model()
2023-04-25 12:52:47,819:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF921E5B0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF91E6910>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 12:52:47,819:INFO:Checking exceptions
2023-04-25 12:52:47,819:INFO:Importing libraries
2023-04-25 12:52:47,819:INFO:Copying training dataset
2023-04-25 12:52:47,821:INFO:Defining folds
2023-04-25 12:52:47,821:INFO:Declaring metric variables
2023-04-25 12:52:47,821:INFO:Importing untrained model
2023-04-25 12:52:47,821:INFO:Ridge Regression Imported successfully
2023-04-25 12:52:47,822:INFO:Starting cross validation
2023-04-25 12:52:47,822:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 12:52:47,954:INFO:Calculating mean and std
2023-04-25 12:52:47,955:INFO:Creating metrics dataframe
2023-04-25 12:52:47,961:INFO:Uploading results into container
2023-04-25 12:52:47,961:INFO:Uploading model into container now
2023-04-25 12:52:47,962:INFO:_master_model_container: 3
2023-04-25 12:52:47,962:INFO:_display_container: 2
2023-04-25 12:52:47,963:INFO:Ridge(random_state=8980)
2023-04-25 12:52:47,963:INFO:create_model() successfully completed......................................
2023-04-25 12:52:48,129:INFO:SubProcess create_model() end ==================================
2023-04-25 12:52:48,129:INFO:Creating metrics dataframe
2023-04-25 12:52:48,133:INFO:Initializing Elastic Net
2023-04-25 12:52:48,133:INFO:Total runtime is 0.11885264317194622 minutes
2023-04-25 12:52:48,133:INFO:SubProcess create_model() called ==================================
2023-04-25 12:52:48,133:INFO:Initializing create_model()
2023-04-25 12:52:48,134:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF921E5B0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF91E6910>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 12:52:48,134:INFO:Checking exceptions
2023-04-25 12:52:48,134:INFO:Importing libraries
2023-04-25 12:52:48,134:INFO:Copying training dataset
2023-04-25 12:52:48,136:INFO:Defining folds
2023-04-25 12:52:48,136:INFO:Declaring metric variables
2023-04-25 12:52:48,136:INFO:Importing untrained model
2023-04-25 12:52:48,137:INFO:Elastic Net Imported successfully
2023-04-25 12:52:48,137:INFO:Starting cross validation
2023-04-25 12:52:48,138:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 12:52:48,270:INFO:Calculating mean and std
2023-04-25 12:52:48,270:INFO:Creating metrics dataframe
2023-04-25 12:52:48,274:INFO:Uploading results into container
2023-04-25 12:52:48,274:INFO:Uploading model into container now
2023-04-25 12:52:48,274:INFO:_master_model_container: 4
2023-04-25 12:52:48,274:INFO:_display_container: 2
2023-04-25 12:52:48,275:INFO:ElasticNet(random_state=8980)
2023-04-25 12:52:48,275:INFO:create_model() successfully completed......................................
2023-04-25 12:52:48,427:INFO:SubProcess create_model() end ==================================
2023-04-25 12:52:48,428:INFO:Creating metrics dataframe
2023-04-25 12:52:48,431:INFO:Initializing Least Angle Regression
2023-04-25 12:52:48,431:INFO:Total runtime is 0.1238310734430949 minutes
2023-04-25 12:52:48,431:INFO:SubProcess create_model() called ==================================
2023-04-25 12:52:48,431:INFO:Initializing create_model()
2023-04-25 12:52:48,431:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF921E5B0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF91E6910>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 12:52:48,431:INFO:Checking exceptions
2023-04-25 12:52:48,431:INFO:Importing libraries
2023-04-25 12:52:48,431:INFO:Copying training dataset
2023-04-25 12:52:48,435:INFO:Defining folds
2023-04-25 12:52:48,435:INFO:Declaring metric variables
2023-04-25 12:52:48,435:INFO:Importing untrained model
2023-04-25 12:52:48,436:INFO:Least Angle Regression Imported successfully
2023-04-25 12:52:48,438:INFO:Starting cross validation
2023-04-25 12:52:48,439:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 12:52:48,492:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 12:52:48,507:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 12:52:48,519:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 12:52:48,530:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 12:52:48,539:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 12:52:48,548:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 12:52:48,556:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 12:52:48,562:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 12:52:48,571:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 12:52:48,573:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 12:52:48,583:INFO:Calculating mean and std
2023-04-25 12:52:48,584:INFO:Creating metrics dataframe
2023-04-25 12:52:48,587:INFO:Uploading results into container
2023-04-25 12:52:48,588:INFO:Uploading model into container now
2023-04-25 12:52:48,588:INFO:_master_model_container: 5
2023-04-25 12:52:48,588:INFO:_display_container: 2
2023-04-25 12:52:48,588:INFO:Lars(random_state=8980)
2023-04-25 12:52:48,588:INFO:create_model() successfully completed......................................
2023-04-25 12:52:48,725:INFO:SubProcess create_model() end ==================================
2023-04-25 12:52:48,725:INFO:Creating metrics dataframe
2023-04-25 12:52:48,728:INFO:Initializing Lasso Least Angle Regression
2023-04-25 12:52:48,728:INFO:Total runtime is 0.1287713090578715 minutes
2023-04-25 12:52:48,728:INFO:SubProcess create_model() called ==================================
2023-04-25 12:52:48,729:INFO:Initializing create_model()
2023-04-25 12:52:48,729:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF921E5B0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF91E6910>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 12:52:48,729:INFO:Checking exceptions
2023-04-25 12:52:48,729:INFO:Importing libraries
2023-04-25 12:52:48,729:INFO:Copying training dataset
2023-04-25 12:52:48,731:INFO:Defining folds
2023-04-25 12:52:48,731:INFO:Declaring metric variables
2023-04-25 12:52:48,732:INFO:Importing untrained model
2023-04-25 12:52:48,732:INFO:Lasso Least Angle Regression Imported successfully
2023-04-25 12:52:48,733:INFO:Starting cross validation
2023-04-25 12:52:48,735:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 12:52:48,791:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 12:52:48,795:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 12:52:48,809:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 12:52:48,818:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 12:52:48,829:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 12:52:48,832:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 12:52:48,844:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 12:52:48,850:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 12:52:48,860:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 12:52:48,867:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 12:52:48,878:INFO:Calculating mean and std
2023-04-25 12:52:48,878:INFO:Creating metrics dataframe
2023-04-25 12:52:48,881:INFO:Uploading results into container
2023-04-25 12:52:48,882:INFO:Uploading model into container now
2023-04-25 12:52:48,882:INFO:_master_model_container: 6
2023-04-25 12:52:48,882:INFO:_display_container: 2
2023-04-25 12:52:48,882:INFO:LassoLars(random_state=8980)
2023-04-25 12:52:48,882:INFO:create_model() successfully completed......................................
2023-04-25 12:52:49,026:INFO:SubProcess create_model() end ==================================
2023-04-25 12:52:49,026:INFO:Creating metrics dataframe
2023-04-25 12:52:49,031:INFO:Initializing Orthogonal Matching Pursuit
2023-04-25 12:52:49,031:INFO:Total runtime is 0.1338284969329834 minutes
2023-04-25 12:52:49,031:INFO:SubProcess create_model() called ==================================
2023-04-25 12:52:49,031:INFO:Initializing create_model()
2023-04-25 12:52:49,031:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF921E5B0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF91E6910>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 12:52:49,031:INFO:Checking exceptions
2023-04-25 12:52:49,031:INFO:Importing libraries
2023-04-25 12:52:49,031:INFO:Copying training dataset
2023-04-25 12:52:49,034:INFO:Defining folds
2023-04-25 12:52:49,034:INFO:Declaring metric variables
2023-04-25 12:52:49,035:INFO:Importing untrained model
2023-04-25 12:52:49,035:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-25 12:52:49,035:INFO:Starting cross validation
2023-04-25 12:52:49,036:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 12:52:49,076:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 12:52:49,087:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 12:52:49,121:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 12:52:49,124:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 12:52:49,142:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 12:52:49,148:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 12:52:49,161:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 12:52:49,172:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 12:52:49,183:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 12:52:49,187:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 12:52:49,201:INFO:Calculating mean and std
2023-04-25 12:52:49,201:INFO:Creating metrics dataframe
2023-04-25 12:52:49,208:INFO:Uploading results into container
2023-04-25 12:52:49,209:INFO:Uploading model into container now
2023-04-25 12:52:49,210:INFO:_master_model_container: 7
2023-04-25 12:52:49,210:INFO:_display_container: 2
2023-04-25 12:52:49,211:INFO:OrthogonalMatchingPursuit()
2023-04-25 12:52:49,211:INFO:create_model() successfully completed......................................
2023-04-25 12:52:49,394:INFO:SubProcess create_model() end ==================================
2023-04-25 12:52:49,394:INFO:Creating metrics dataframe
2023-04-25 12:52:49,399:INFO:Initializing Bayesian Ridge
2023-04-25 12:52:49,400:INFO:Total runtime is 0.13994888067245484 minutes
2023-04-25 12:52:49,400:INFO:SubProcess create_model() called ==================================
2023-04-25 12:52:49,400:INFO:Initializing create_model()
2023-04-25 12:52:49,400:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF921E5B0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF91E6910>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 12:52:49,400:INFO:Checking exceptions
2023-04-25 12:52:49,400:INFO:Importing libraries
2023-04-25 12:52:49,400:INFO:Copying training dataset
2023-04-25 12:52:49,402:INFO:Defining folds
2023-04-25 12:52:49,403:INFO:Declaring metric variables
2023-04-25 12:52:49,403:INFO:Importing untrained model
2023-04-25 12:52:49,403:INFO:Bayesian Ridge Imported successfully
2023-04-25 12:52:49,403:INFO:Starting cross validation
2023-04-25 12:52:49,404:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 12:52:49,559:INFO:Calculating mean and std
2023-04-25 12:52:49,559:INFO:Creating metrics dataframe
2023-04-25 12:52:49,564:INFO:Uploading results into container
2023-04-25 12:52:49,564:INFO:Uploading model into container now
2023-04-25 12:52:49,564:INFO:_master_model_container: 8
2023-04-25 12:52:49,564:INFO:_display_container: 2
2023-04-25 12:52:49,565:INFO:BayesianRidge()
2023-04-25 12:52:49,565:INFO:create_model() successfully completed......................................
2023-04-25 12:52:49,737:INFO:SubProcess create_model() end ==================================
2023-04-25 12:52:49,737:INFO:Creating metrics dataframe
2023-04-25 12:52:49,748:INFO:Initializing Passive Aggressive Regressor
2023-04-25 12:52:49,748:INFO:Total runtime is 0.14576749404271444 minutes
2023-04-25 12:52:49,749:INFO:SubProcess create_model() called ==================================
2023-04-25 12:52:49,749:INFO:Initializing create_model()
2023-04-25 12:52:49,749:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF921E5B0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF91E6910>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 12:52:49,749:INFO:Checking exceptions
2023-04-25 12:52:49,750:INFO:Importing libraries
2023-04-25 12:52:49,750:INFO:Copying training dataset
2023-04-25 12:52:49,755:INFO:Defining folds
2023-04-25 12:52:49,755:INFO:Declaring metric variables
2023-04-25 12:52:49,755:INFO:Importing untrained model
2023-04-25 12:52:49,755:INFO:Passive Aggressive Regressor Imported successfully
2023-04-25 12:52:49,756:INFO:Starting cross validation
2023-04-25 12:52:49,757:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 12:52:49,941:INFO:Calculating mean and std
2023-04-25 12:52:49,941:INFO:Creating metrics dataframe
2023-04-25 12:52:49,950:INFO:Uploading results into container
2023-04-25 12:52:49,951:INFO:Uploading model into container now
2023-04-25 12:52:49,951:INFO:_master_model_container: 9
2023-04-25 12:52:49,952:INFO:_display_container: 2
2023-04-25 12:52:49,952:INFO:PassiveAggressiveRegressor(random_state=8980)
2023-04-25 12:52:49,952:INFO:create_model() successfully completed......................................
2023-04-25 12:52:50,122:INFO:SubProcess create_model() end ==================================
2023-04-25 12:52:50,124:INFO:Creating metrics dataframe
2023-04-25 12:52:50,129:INFO:Initializing Huber Regressor
2023-04-25 12:52:50,129:INFO:Total runtime is 0.1521151065826416 minutes
2023-04-25 12:52:50,129:INFO:SubProcess create_model() called ==================================
2023-04-25 12:52:50,130:INFO:Initializing create_model()
2023-04-25 12:52:50,130:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF921E5B0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF91E6910>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 12:52:50,130:INFO:Checking exceptions
2023-04-25 12:52:50,130:INFO:Importing libraries
2023-04-25 12:52:50,130:INFO:Copying training dataset
2023-04-25 12:52:50,135:INFO:Defining folds
2023-04-25 12:52:50,135:INFO:Declaring metric variables
2023-04-25 12:52:50,135:INFO:Importing untrained model
2023-04-25 12:52:50,135:INFO:Huber Regressor Imported successfully
2023-04-25 12:52:50,135:INFO:Starting cross validation
2023-04-25 12:52:50,136:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 12:52:50,342:INFO:Calculating mean and std
2023-04-25 12:52:50,342:INFO:Creating metrics dataframe
2023-04-25 12:52:50,345:INFO:Uploading results into container
2023-04-25 12:52:50,347:INFO:Uploading model into container now
2023-04-25 12:52:50,347:INFO:_master_model_container: 10
2023-04-25 12:52:50,347:INFO:_display_container: 2
2023-04-25 12:52:50,347:INFO:HuberRegressor()
2023-04-25 12:52:50,347:INFO:create_model() successfully completed......................................
2023-04-25 12:52:50,513:INFO:SubProcess create_model() end ==================================
2023-04-25 12:52:50,513:INFO:Creating metrics dataframe
2023-04-25 12:52:50,523:INFO:Initializing K Neighbors Regressor
2023-04-25 12:52:50,523:INFO:Total runtime is 0.15868171056111655 minutes
2023-04-25 12:52:50,523:INFO:SubProcess create_model() called ==================================
2023-04-25 12:52:50,524:INFO:Initializing create_model()
2023-04-25 12:52:50,524:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF921E5B0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF91E6910>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 12:52:50,524:INFO:Checking exceptions
2023-04-25 12:52:50,524:INFO:Importing libraries
2023-04-25 12:52:50,524:INFO:Copying training dataset
2023-04-25 12:52:50,528:INFO:Defining folds
2023-04-25 12:52:50,528:INFO:Declaring metric variables
2023-04-25 12:52:50,528:INFO:Importing untrained model
2023-04-25 12:52:50,528:INFO:K Neighbors Regressor Imported successfully
2023-04-25 12:52:50,529:INFO:Starting cross validation
2023-04-25 12:52:50,530:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 12:52:50,694:INFO:Calculating mean and std
2023-04-25 12:52:50,695:INFO:Creating metrics dataframe
2023-04-25 12:52:50,698:INFO:Uploading results into container
2023-04-25 12:52:50,698:INFO:Uploading model into container now
2023-04-25 12:52:50,699:INFO:_master_model_container: 11
2023-04-25 12:52:50,699:INFO:_display_container: 2
2023-04-25 12:52:50,699:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-25 12:52:50,699:INFO:create_model() successfully completed......................................
2023-04-25 12:52:50,850:INFO:SubProcess create_model() end ==================================
2023-04-25 12:52:50,850:INFO:Creating metrics dataframe
2023-04-25 12:52:50,856:INFO:Initializing Decision Tree Regressor
2023-04-25 12:52:50,856:INFO:Total runtime is 0.16423702637354534 minutes
2023-04-25 12:52:50,856:INFO:SubProcess create_model() called ==================================
2023-04-25 12:52:50,856:INFO:Initializing create_model()
2023-04-25 12:52:50,856:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF921E5B0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF91E6910>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 12:52:50,856:INFO:Checking exceptions
2023-04-25 12:52:50,856:INFO:Importing libraries
2023-04-25 12:52:50,857:INFO:Copying training dataset
2023-04-25 12:52:50,861:INFO:Defining folds
2023-04-25 12:52:50,861:INFO:Declaring metric variables
2023-04-25 12:52:50,861:INFO:Importing untrained model
2023-04-25 12:52:50,861:INFO:Decision Tree Regressor Imported successfully
2023-04-25 12:52:50,862:INFO:Starting cross validation
2023-04-25 12:52:50,863:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 12:52:51,041:INFO:Calculating mean and std
2023-04-25 12:52:51,042:INFO:Creating metrics dataframe
2023-04-25 12:52:51,047:INFO:Uploading results into container
2023-04-25 12:52:51,048:INFO:Uploading model into container now
2023-04-25 12:52:51,049:INFO:_master_model_container: 12
2023-04-25 12:52:51,049:INFO:_display_container: 2
2023-04-25 12:52:51,050:INFO:DecisionTreeRegressor(random_state=8980)
2023-04-25 12:52:51,050:INFO:create_model() successfully completed......................................
2023-04-25 12:52:51,232:INFO:SubProcess create_model() end ==================================
2023-04-25 12:52:51,232:INFO:Creating metrics dataframe
2023-04-25 12:52:51,235:INFO:Initializing Random Forest Regressor
2023-04-25 12:52:51,235:INFO:Total runtime is 0.1705561677614848 minutes
2023-04-25 12:52:51,235:INFO:SubProcess create_model() called ==================================
2023-04-25 12:52:51,235:INFO:Initializing create_model()
2023-04-25 12:52:51,236:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF921E5B0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF91E6910>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 12:52:51,236:INFO:Checking exceptions
2023-04-25 12:52:51,236:INFO:Importing libraries
2023-04-25 12:52:51,236:INFO:Copying training dataset
2023-04-25 12:52:51,238:INFO:Defining folds
2023-04-25 12:52:51,238:INFO:Declaring metric variables
2023-04-25 12:52:51,238:INFO:Importing untrained model
2023-04-25 12:52:51,238:INFO:Random Forest Regressor Imported successfully
2023-04-25 12:52:51,239:INFO:Starting cross validation
2023-04-25 12:52:51,239:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 12:52:52,094:INFO:Calculating mean and std
2023-04-25 12:52:52,096:INFO:Creating metrics dataframe
2023-04-25 12:52:52,118:INFO:Uploading results into container
2023-04-25 12:52:52,120:INFO:Uploading model into container now
2023-04-25 12:52:52,121:INFO:_master_model_container: 13
2023-04-25 12:52:52,121:INFO:_display_container: 2
2023-04-25 12:52:52,122:INFO:RandomForestRegressor(n_jobs=-1, random_state=8980)
2023-04-25 12:52:52,122:INFO:create_model() successfully completed......................................
2023-04-25 12:52:52,278:INFO:SubProcess create_model() end ==================================
2023-04-25 12:52:52,278:INFO:Creating metrics dataframe
2023-04-25 12:52:52,284:INFO:Initializing Extra Trees Regressor
2023-04-25 12:52:52,284:INFO:Total runtime is 0.188034725189209 minutes
2023-04-25 12:52:52,285:INFO:SubProcess create_model() called ==================================
2023-04-25 12:52:52,285:INFO:Initializing create_model()
2023-04-25 12:52:52,285:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF921E5B0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF91E6910>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 12:52:52,285:INFO:Checking exceptions
2023-04-25 12:52:52,285:INFO:Importing libraries
2023-04-25 12:52:52,285:INFO:Copying training dataset
2023-04-25 12:52:52,288:INFO:Defining folds
2023-04-25 12:52:52,288:INFO:Declaring metric variables
2023-04-25 12:52:52,288:INFO:Importing untrained model
2023-04-25 12:52:52,289:INFO:Extra Trees Regressor Imported successfully
2023-04-25 12:52:52,289:INFO:Starting cross validation
2023-04-25 12:52:52,291:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 12:52:52,948:INFO:Calculating mean and std
2023-04-25 12:52:52,949:INFO:Creating metrics dataframe
2023-04-25 12:52:52,979:INFO:Uploading results into container
2023-04-25 12:52:52,981:INFO:Uploading model into container now
2023-04-25 12:52:52,982:INFO:_master_model_container: 14
2023-04-25 12:52:52,982:INFO:_display_container: 2
2023-04-25 12:52:52,983:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=8980)
2023-04-25 12:52:52,983:INFO:create_model() successfully completed......................................
2023-04-25 12:52:53,143:INFO:SubProcess create_model() end ==================================
2023-04-25 12:52:53,143:INFO:Creating metrics dataframe
2023-04-25 12:52:53,148:INFO:Initializing AdaBoost Regressor
2023-04-25 12:52:53,148:INFO:Total runtime is 0.20243612130482994 minutes
2023-04-25 12:52:53,148:INFO:SubProcess create_model() called ==================================
2023-04-25 12:52:53,148:INFO:Initializing create_model()
2023-04-25 12:52:53,148:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF921E5B0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF91E6910>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 12:52:53,148:INFO:Checking exceptions
2023-04-25 12:52:53,148:INFO:Importing libraries
2023-04-25 12:52:53,148:INFO:Copying training dataset
2023-04-25 12:52:53,151:INFO:Defining folds
2023-04-25 12:52:53,151:INFO:Declaring metric variables
2023-04-25 12:52:53,151:INFO:Importing untrained model
2023-04-25 12:52:53,151:INFO:AdaBoost Regressor Imported successfully
2023-04-25 12:52:53,151:INFO:Starting cross validation
2023-04-25 12:52:53,152:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 12:52:53,499:INFO:Calculating mean and std
2023-04-25 12:52:53,500:INFO:Creating metrics dataframe
2023-04-25 12:52:53,524:INFO:Uploading results into container
2023-04-25 12:52:53,525:INFO:Uploading model into container now
2023-04-25 12:52:53,526:INFO:_master_model_container: 15
2023-04-25 12:52:53,526:INFO:_display_container: 2
2023-04-25 12:52:53,527:INFO:AdaBoostRegressor(random_state=8980)
2023-04-25 12:52:53,527:INFO:create_model() successfully completed......................................
2023-04-25 12:52:53,697:INFO:SubProcess create_model() end ==================================
2023-04-25 12:52:53,697:INFO:Creating metrics dataframe
2023-04-25 12:52:53,704:INFO:Initializing Gradient Boosting Regressor
2023-04-25 12:52:53,704:INFO:Total runtime is 0.21170644760131838 minutes
2023-04-25 12:52:53,705:INFO:SubProcess create_model() called ==================================
2023-04-25 12:52:53,705:INFO:Initializing create_model()
2023-04-25 12:52:53,705:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF921E5B0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF91E6910>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 12:52:53,705:INFO:Checking exceptions
2023-04-25 12:52:53,705:INFO:Importing libraries
2023-04-25 12:52:53,706:INFO:Copying training dataset
2023-04-25 12:52:53,713:INFO:Defining folds
2023-04-25 12:52:53,713:INFO:Declaring metric variables
2023-04-25 12:52:53,713:INFO:Importing untrained model
2023-04-25 12:52:53,714:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 12:52:53,714:INFO:Starting cross validation
2023-04-25 12:52:53,716:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 12:52:54,030:INFO:Calculating mean and std
2023-04-25 12:52:54,030:INFO:Creating metrics dataframe
2023-04-25 12:52:54,052:INFO:Uploading results into container
2023-04-25 12:52:54,054:INFO:Uploading model into container now
2023-04-25 12:52:54,055:INFO:_master_model_container: 16
2023-04-25 12:52:54,055:INFO:_display_container: 2
2023-04-25 12:52:54,056:INFO:GradientBoostingRegressor(random_state=8980)
2023-04-25 12:52:54,056:INFO:create_model() successfully completed......................................
2023-04-25 12:52:54,232:INFO:SubProcess create_model() end ==================================
2023-04-25 12:52:54,232:INFO:Creating metrics dataframe
2023-04-25 12:52:54,239:INFO:Initializing Light Gradient Boosting Machine
2023-04-25 12:52:54,239:INFO:Total runtime is 0.2206156929334005 minutes
2023-04-25 12:52:54,240:INFO:SubProcess create_model() called ==================================
2023-04-25 12:52:54,241:INFO:Initializing create_model()
2023-04-25 12:52:54,241:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF921E5B0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF91E6910>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 12:52:54,241:INFO:Checking exceptions
2023-04-25 12:52:54,241:INFO:Importing libraries
2023-04-25 12:52:54,241:INFO:Copying training dataset
2023-04-25 12:52:54,249:INFO:Defining folds
2023-04-25 12:52:54,249:INFO:Declaring metric variables
2023-04-25 12:52:54,250:INFO:Importing untrained model
2023-04-25 12:52:54,251:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 12:52:54,251:INFO:Starting cross validation
2023-04-25 12:52:54,253:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 12:52:55,470:INFO:Calculating mean and std
2023-04-25 12:52:55,472:INFO:Creating metrics dataframe
2023-04-25 12:52:55,484:INFO:Uploading results into container
2023-04-25 12:52:55,485:INFO:Uploading model into container now
2023-04-25 12:52:55,485:INFO:_master_model_container: 17
2023-04-25 12:52:55,486:INFO:_display_container: 2
2023-04-25 12:52:55,486:INFO:LGBMRegressor(random_state=8980)
2023-04-25 12:52:55,486:INFO:create_model() successfully completed......................................
2023-04-25 12:52:55,652:INFO:SubProcess create_model() end ==================================
2023-04-25 12:52:55,652:INFO:Creating metrics dataframe
2023-04-25 12:52:55,656:INFO:Initializing Dummy Regressor
2023-04-25 12:52:55,656:INFO:Total runtime is 0.2442444761594137 minutes
2023-04-25 12:52:55,656:INFO:SubProcess create_model() called ==================================
2023-04-25 12:52:55,656:INFO:Initializing create_model()
2023-04-25 12:52:55,656:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF921E5B0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF91E6910>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 12:52:55,656:INFO:Checking exceptions
2023-04-25 12:52:55,656:INFO:Importing libraries
2023-04-25 12:52:55,656:INFO:Copying training dataset
2023-04-25 12:52:55,660:INFO:Defining folds
2023-04-25 12:52:55,660:INFO:Declaring metric variables
2023-04-25 12:52:55,660:INFO:Importing untrained model
2023-04-25 12:52:55,661:INFO:Dummy Regressor Imported successfully
2023-04-25 12:52:55,662:INFO:Starting cross validation
2023-04-25 12:52:55,664:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 12:52:55,846:INFO:Calculating mean and std
2023-04-25 12:52:55,847:INFO:Creating metrics dataframe
2023-04-25 12:52:55,859:INFO:Uploading results into container
2023-04-25 12:52:55,860:INFO:Uploading model into container now
2023-04-25 12:52:55,860:INFO:_master_model_container: 18
2023-04-25 12:52:55,860:INFO:_display_container: 2
2023-04-25 12:52:55,860:INFO:DummyRegressor()
2023-04-25 12:52:55,860:INFO:create_model() successfully completed......................................
2023-04-25 12:52:56,023:INFO:SubProcess create_model() end ==================================
2023-04-25 12:52:56,023:INFO:Creating metrics dataframe
2023-04-25 12:52:56,029:INFO:Initializing create_model()
2023-04-25 12:52:56,029:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF921E5B0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=8980), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 12:52:56,029:INFO:Checking exceptions
2023-04-25 12:52:56,030:INFO:Importing libraries
2023-04-25 12:52:56,030:INFO:Copying training dataset
2023-04-25 12:52:56,032:INFO:Defining folds
2023-04-25 12:52:56,032:INFO:Declaring metric variables
2023-04-25 12:52:56,033:INFO:Importing untrained model
2023-04-25 12:52:56,033:INFO:Declaring custom model
2023-04-25 12:52:56,033:INFO:Extra Trees Regressor Imported successfully
2023-04-25 12:52:56,034:INFO:Cross validation set to False
2023-04-25 12:52:56,034:INFO:Fitting Model
2023-04-25 12:52:56,139:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=8980)
2023-04-25 12:52:56,139:INFO:create_model() successfully completed......................................
2023-04-25 12:52:56,311:INFO:_master_model_container: 18
2023-04-25 12:52:56,312:INFO:_display_container: 2
2023-04-25 12:52:56,313:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=8980)
2023-04-25 12:52:56,313:INFO:compare_models() successfully completed......................................
2023-04-25 12:52:56,319:INFO:Initializing save_model()
2023-04-25 12:52:56,319:INFO:save_model(model=ExtraTreesRegressor(n_jobs=-1, random_state=8980), model_name=best_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\91888\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['TV', 'Radio', 'Newspaper'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-04-25 12:52:56,319:INFO:Adding model into prep_pipe
2023-04-25 12:52:56,362:INFO:best_model.pkl saved in current working directory
2023-04-25 12:52:56,366:INFO:Pipeline(memory=FastMemory(location=C:\Users\91888\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['TV', 'Radio', 'Newspaper'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('trained_model',
                 ExtraTreesRegressor(n_jobs=-1, random_state=8980))])
2023-04-25 12:52:56,366:INFO:save_model() successfully completed......................................
2023-04-25 13:08:10,702:INFO:PyCaret RegressionExperiment
2023-04-25 13:08:10,703:INFO:Logging name: reg-default-name
2023-04-25 13:08:10,703:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-25 13:08:10,703:INFO:version 3.0.0
2023-04-25 13:08:10,703:INFO:Initializing setup()
2023-04-25 13:08:10,703:INFO:self.USI: cba8
2023-04-25 13:08:10,703:INFO:self._variable_keys: {'html_param', '_ml_usecase', 'X_test', 'n_jobs_param', 'exp_name_log', 'memory', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param', 'USI', 'seed', 'X_train', 'X', 'gpu_param', 'pipeline', 'target_param', 'data', 'idx', 'fold_groups_param', 'transform_target_param', 'y_train', 'fold_shuffle_param', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_id'}
2023-04-25 13:08:10,703:INFO:Checking environment
2023-04-25 13:08:10,703:INFO:python_version: 3.9.12
2023-04-25 13:08:10,703:INFO:python_build: ('main', 'Apr  4 2022 05:22:27')
2023-04-25 13:08:10,703:INFO:machine: AMD64
2023-04-25 13:08:10,703:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-25 13:08:10,703:INFO:Memory: svmem(total=8362713088, available=1087123456, percent=87.0, used=7275589632, free=1087123456)
2023-04-25 13:08:10,703:INFO:Physical Core: 4
2023-04-25 13:08:10,703:INFO:Logical Core: 8
2023-04-25 13:08:10,703:INFO:Checking libraries
2023-04-25 13:08:10,703:INFO:System:
2023-04-25 13:08:10,703:INFO:    python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]
2023-04-25 13:08:10,703:INFO:executable: C:\Users\91888\anaconda3\python.exe
2023-04-25 13:08:10,704:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-25 13:08:10,704:INFO:PyCaret required dependencies:
2023-04-25 13:08:10,704:INFO:                 pip: 21.2.4
2023-04-25 13:08:10,704:INFO:          setuptools: 61.2.0
2023-04-25 13:08:10,704:INFO:             pycaret: 3.0.0
2023-04-25 13:08:10,704:INFO:             IPython: 8.2.0
2023-04-25 13:08:10,704:INFO:          ipywidgets: 7.6.5
2023-04-25 13:08:10,704:INFO:                tqdm: 4.64.0
2023-04-25 13:08:10,704:INFO:               numpy: 1.21.5
2023-04-25 13:08:10,704:INFO:              pandas: 1.4.2
2023-04-25 13:08:10,704:INFO:              jinja2: 2.11.3
2023-04-25 13:08:10,704:INFO:               scipy: 1.7.3
2023-04-25 13:08:10,704:INFO:              joblib: 1.2.0
2023-04-25 13:08:10,704:INFO:             sklearn: 1.0.2
2023-04-25 13:08:10,704:INFO:                pyod: 1.0.9
2023-04-25 13:08:10,704:INFO:            imblearn: 0.10.1
2023-04-25 13:08:10,704:INFO:   category_encoders: 2.6.0
2023-04-25 13:08:10,704:INFO:            lightgbm: 3.3.5
2023-04-25 13:08:10,704:INFO:               numba: 0.55.1
2023-04-25 13:08:10,704:INFO:            requests: 2.27.1
2023-04-25 13:08:10,705:INFO:          matplotlib: 3.5.1
2023-04-25 13:08:10,705:INFO:          scikitplot: 0.3.7
2023-04-25 13:08:10,705:INFO:         yellowbrick: 1.5
2023-04-25 13:08:10,705:INFO:              plotly: 5.6.0
2023-04-25 13:08:10,705:INFO:             kaleido: 0.2.1
2023-04-25 13:08:10,705:INFO:         statsmodels: 0.13.2
2023-04-25 13:08:10,705:INFO:              sktime: 0.17.1
2023-04-25 13:08:10,705:INFO:               tbats: 1.1.3
2023-04-25 13:08:10,705:INFO:            pmdarima: 2.0.3
2023-04-25 13:08:10,705:INFO:              psutil: 5.9.5
2023-04-25 13:08:10,705:INFO:PyCaret optional dependencies:
2023-04-25 13:08:10,705:INFO:                shap: Not installed
2023-04-25 13:08:10,705:INFO:           interpret: Not installed
2023-04-25 13:08:10,705:INFO:                umap: Not installed
2023-04-25 13:08:10,705:INFO:    pandas_profiling: 4.1.2
2023-04-25 13:08:10,705:INFO:  explainerdashboard: Not installed
2023-04-25 13:08:10,705:INFO:             autoviz: Not installed
2023-04-25 13:08:10,705:INFO:           fairlearn: Not installed
2023-04-25 13:08:10,705:INFO:             xgboost: Not installed
2023-04-25 13:08:10,705:INFO:            catboost: Not installed
2023-04-25 13:08:10,705:INFO:              kmodes: Not installed
2023-04-25 13:08:10,705:INFO:             mlxtend: Not installed
2023-04-25 13:08:10,706:INFO:       statsforecast: Not installed
2023-04-25 13:08:10,706:INFO:        tune_sklearn: Not installed
2023-04-25 13:08:10,706:INFO:                 ray: Not installed
2023-04-25 13:08:10,706:INFO:            hyperopt: Not installed
2023-04-25 13:08:10,706:INFO:              optuna: Not installed
2023-04-25 13:08:10,706:INFO:               skopt: Not installed
2023-04-25 13:08:10,706:INFO:              mlflow: Not installed
2023-04-25 13:08:10,706:INFO:              gradio: Not installed
2023-04-25 13:08:10,706:INFO:             fastapi: Not installed
2023-04-25 13:08:10,706:INFO:             uvicorn: Not installed
2023-04-25 13:08:10,706:INFO:              m2cgen: Not installed
2023-04-25 13:08:10,706:INFO:           evidently: Not installed
2023-04-25 13:08:10,706:INFO:               fugue: Not installed
2023-04-25 13:08:10,706:INFO:           streamlit: 1.21.0
2023-04-25 13:08:10,706:INFO:             prophet: Not installed
2023-04-25 13:08:10,706:INFO:None
2023-04-25 13:08:10,706:INFO:Set up data.
2023-04-25 13:08:10,710:INFO:Set up train/test split.
2023-04-25 13:08:10,714:INFO:Set up index.
2023-04-25 13:08:10,714:INFO:Set up folding strategy.
2023-04-25 13:08:10,714:INFO:Assigning column types.
2023-04-25 13:08:10,717:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-25 13:08:10,718:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 13:08:10,723:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 13:08:10,728:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 13:08:10,818:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 13:08:10,896:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 13:08:10,897:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:10,898:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:10,898:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 13:08:10,903:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 13:08:10,907:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 13:08:10,975:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 13:08:11,031:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 13:08:11,032:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:11,032:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:11,032:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-25 13:08:11,037:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 13:08:11,041:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 13:08:11,097:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 13:08:11,178:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 13:08:11,179:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:11,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:11,184:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 13:08:11,188:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 13:08:11,242:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 13:08:11,325:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 13:08:11,325:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:11,325:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:11,326:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-25 13:08:11,340:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 13:08:11,423:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 13:08:11,468:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 13:08:11,470:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:11,470:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:11,480:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 13:08:11,565:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 13:08:11,635:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 13:08:11,636:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:11,636:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:11,637:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-25 13:08:11,701:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 13:08:11,746:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 13:08:11,746:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:11,746:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:11,810:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 13:08:11,853:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 13:08:11,854:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:11,854:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:11,854:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-25 13:08:11,932:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 13:08:12,019:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:12,020:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:12,103:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 13:08:12,147:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:12,148:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:12,148:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-25 13:08:12,290:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:12,290:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:12,459:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:12,459:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:12,460:INFO:Preparing preprocessing pipeline...
2023-04-25 13:08:12,460:INFO:Set up simple imputation.
2023-04-25 13:08:12,471:INFO:Finished creating preprocessing pipeline.
2023-04-25 13:08:12,474:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\91888\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['TV', 'Radio', 'Newspaper'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-04-25 13:08:12,474:INFO:Creating final display dataframe.
2023-04-25 13:08:12,527:INFO:Setup _display_container:                     Description             Value
0                    Session id              6957
1                        Target             Sales
2                   Target type        Regression
3           Original data shape          (200, 4)
4        Transformed data shape          (200, 4)
5   Transformed train set shape          (140, 4)
6    Transformed test set shape           (60, 4)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              cba8
2023-04-25 13:08:12,731:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:12,731:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:12,865:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:12,866:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 13:08:12,866:INFO:setup() successfully completed in 2.17s...............
2023-04-25 13:08:12,870:INFO:Initializing compare_models()
2023-04-25 13:08:12,870:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF72CD610>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000017CF72CD610>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-25 13:08:12,870:INFO:Checking exceptions
2023-04-25 13:08:12,872:INFO:Preparing display monitor
2023-04-25 13:08:12,876:INFO:Initializing Linear Regression
2023-04-25 13:08:12,876:INFO:Total runtime is 0.0 minutes
2023-04-25 13:08:12,877:INFO:SubProcess create_model() called ==================================
2023-04-25 13:08:12,877:INFO:Initializing create_model()
2023-04-25 13:08:12,877:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF72CD610>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF963A580>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 13:08:12,877:INFO:Checking exceptions
2023-04-25 13:08:12,877:INFO:Importing libraries
2023-04-25 13:08:12,877:INFO:Copying training dataset
2023-04-25 13:08:12,880:INFO:Defining folds
2023-04-25 13:08:12,881:INFO:Declaring metric variables
2023-04-25 13:08:12,881:INFO:Importing untrained model
2023-04-25 13:08:12,881:INFO:Linear Regression Imported successfully
2023-04-25 13:08:12,882:INFO:Starting cross validation
2023-04-25 13:08:12,883:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 13:08:19,349:INFO:Calculating mean and std
2023-04-25 13:08:19,350:INFO:Creating metrics dataframe
2023-04-25 13:08:19,364:INFO:Uploading results into container
2023-04-25 13:08:19,364:INFO:Uploading model into container now
2023-04-25 13:08:19,365:INFO:_master_model_container: 1
2023-04-25 13:08:19,365:INFO:_display_container: 2
2023-04-25 13:08:19,365:INFO:LinearRegression(n_jobs=-1)
2023-04-25 13:08:19,365:INFO:create_model() successfully completed......................................
2023-04-25 13:08:19,537:INFO:SubProcess create_model() end ==================================
2023-04-25 13:08:19,537:INFO:Creating metrics dataframe
2023-04-25 13:08:19,542:INFO:Initializing Lasso Regression
2023-04-25 13:08:19,542:INFO:Total runtime is 0.11109385093053183 minutes
2023-04-25 13:08:19,543:INFO:SubProcess create_model() called ==================================
2023-04-25 13:08:19,543:INFO:Initializing create_model()
2023-04-25 13:08:19,543:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF72CD610>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF963A580>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 13:08:19,543:INFO:Checking exceptions
2023-04-25 13:08:19,543:INFO:Importing libraries
2023-04-25 13:08:19,543:INFO:Copying training dataset
2023-04-25 13:08:19,550:INFO:Defining folds
2023-04-25 13:08:19,550:INFO:Declaring metric variables
2023-04-25 13:08:19,550:INFO:Importing untrained model
2023-04-25 13:08:19,551:INFO:Lasso Regression Imported successfully
2023-04-25 13:08:19,552:INFO:Starting cross validation
2023-04-25 13:08:19,553:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 13:08:19,787:INFO:Calculating mean and std
2023-04-25 13:08:19,788:INFO:Creating metrics dataframe
2023-04-25 13:08:19,803:INFO:Uploading results into container
2023-04-25 13:08:19,804:INFO:Uploading model into container now
2023-04-25 13:08:19,804:INFO:_master_model_container: 2
2023-04-25 13:08:19,804:INFO:_display_container: 2
2023-04-25 13:08:19,805:INFO:Lasso(random_state=6957)
2023-04-25 13:08:19,805:INFO:create_model() successfully completed......................................
2023-04-25 13:08:19,974:INFO:SubProcess create_model() end ==================================
2023-04-25 13:08:19,974:INFO:Creating metrics dataframe
2023-04-25 13:08:19,985:INFO:Initializing Ridge Regression
2023-04-25 13:08:19,986:INFO:Total runtime is 0.11850584745407106 minutes
2023-04-25 13:08:19,986:INFO:SubProcess create_model() called ==================================
2023-04-25 13:08:19,987:INFO:Initializing create_model()
2023-04-25 13:08:19,987:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF72CD610>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF963A580>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 13:08:19,987:INFO:Checking exceptions
2023-04-25 13:08:19,988:INFO:Importing libraries
2023-04-25 13:08:19,988:INFO:Copying training dataset
2023-04-25 13:08:19,996:INFO:Defining folds
2023-04-25 13:08:19,996:INFO:Declaring metric variables
2023-04-25 13:08:19,997:INFO:Importing untrained model
2023-04-25 13:08:19,997:INFO:Ridge Regression Imported successfully
2023-04-25 13:08:19,998:INFO:Starting cross validation
2023-04-25 13:08:19,999:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 13:08:20,201:INFO:Calculating mean and std
2023-04-25 13:08:20,202:INFO:Creating metrics dataframe
2023-04-25 13:08:20,232:INFO:Uploading results into container
2023-04-25 13:08:20,232:INFO:Uploading model into container now
2023-04-25 13:08:20,234:INFO:_master_model_container: 3
2023-04-25 13:08:20,234:INFO:_display_container: 2
2023-04-25 13:08:20,235:INFO:Ridge(random_state=6957)
2023-04-25 13:08:20,235:INFO:create_model() successfully completed......................................
2023-04-25 13:08:20,376:INFO:SubProcess create_model() end ==================================
2023-04-25 13:08:20,376:INFO:Creating metrics dataframe
2023-04-25 13:08:20,383:INFO:Initializing Elastic Net
2023-04-25 13:08:20,385:INFO:Total runtime is 0.12514090140660605 minutes
2023-04-25 13:08:20,385:INFO:SubProcess create_model() called ==================================
2023-04-25 13:08:20,385:INFO:Initializing create_model()
2023-04-25 13:08:20,386:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF72CD610>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF963A580>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 13:08:20,386:INFO:Checking exceptions
2023-04-25 13:08:20,386:INFO:Importing libraries
2023-04-25 13:08:20,386:INFO:Copying training dataset
2023-04-25 13:08:20,395:INFO:Defining folds
2023-04-25 13:08:20,395:INFO:Declaring metric variables
2023-04-25 13:08:20,396:INFO:Importing untrained model
2023-04-25 13:08:20,397:INFO:Elastic Net Imported successfully
2023-04-25 13:08:20,397:INFO:Starting cross validation
2023-04-25 13:08:20,399:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 13:08:20,623:INFO:Calculating mean and std
2023-04-25 13:08:20,624:INFO:Creating metrics dataframe
2023-04-25 13:08:20,651:INFO:Uploading results into container
2023-04-25 13:08:20,652:INFO:Uploading model into container now
2023-04-25 13:08:20,652:INFO:_master_model_container: 4
2023-04-25 13:08:20,652:INFO:_display_container: 2
2023-04-25 13:08:20,653:INFO:ElasticNet(random_state=6957)
2023-04-25 13:08:20,653:INFO:create_model() successfully completed......................................
2023-04-25 13:08:20,838:INFO:SubProcess create_model() end ==================================
2023-04-25 13:08:20,838:INFO:Creating metrics dataframe
2023-04-25 13:08:20,843:INFO:Initializing Least Angle Regression
2023-04-25 13:08:20,843:INFO:Total runtime is 0.1327816685040792 minutes
2023-04-25 13:08:20,843:INFO:SubProcess create_model() called ==================================
2023-04-25 13:08:20,843:INFO:Initializing create_model()
2023-04-25 13:08:20,843:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF72CD610>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF963A580>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 13:08:20,843:INFO:Checking exceptions
2023-04-25 13:08:20,843:INFO:Importing libraries
2023-04-25 13:08:20,843:INFO:Copying training dataset
2023-04-25 13:08:20,846:INFO:Defining folds
2023-04-25 13:08:20,846:INFO:Declaring metric variables
2023-04-25 13:08:20,846:INFO:Importing untrained model
2023-04-25 13:08:20,846:INFO:Least Angle Regression Imported successfully
2023-04-25 13:08:20,846:INFO:Starting cross validation
2023-04-25 13:08:20,847:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 13:08:20,884:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 13:08:20,902:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 13:08:20,913:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 13:08:20,920:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 13:08:20,931:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 13:08:20,941:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 13:08:20,952:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 13:08:20,962:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 13:08:20,972:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 13:08:20,977:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 13:08:21,026:INFO:Calculating mean and std
2023-04-25 13:08:21,026:INFO:Creating metrics dataframe
2023-04-25 13:08:21,056:INFO:Uploading results into container
2023-04-25 13:08:21,058:INFO:Uploading model into container now
2023-04-25 13:08:21,058:INFO:_master_model_container: 5
2023-04-25 13:08:21,058:INFO:_display_container: 2
2023-04-25 13:08:21,059:INFO:Lars(random_state=6957)
2023-04-25 13:08:21,059:INFO:create_model() successfully completed......................................
2023-04-25 13:08:21,203:INFO:SubProcess create_model() end ==================================
2023-04-25 13:08:21,203:INFO:Creating metrics dataframe
2023-04-25 13:08:21,215:INFO:Initializing Lasso Least Angle Regression
2023-04-25 13:08:21,215:INFO:Total runtime is 0.1389896313349406 minutes
2023-04-25 13:08:21,215:INFO:SubProcess create_model() called ==================================
2023-04-25 13:08:21,216:INFO:Initializing create_model()
2023-04-25 13:08:21,216:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF72CD610>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF963A580>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 13:08:21,216:INFO:Checking exceptions
2023-04-25 13:08:21,216:INFO:Importing libraries
2023-04-25 13:08:21,216:INFO:Copying training dataset
2023-04-25 13:08:21,222:INFO:Defining folds
2023-04-25 13:08:21,222:INFO:Declaring metric variables
2023-04-25 13:08:21,223:INFO:Importing untrained model
2023-04-25 13:08:21,223:INFO:Lasso Least Angle Regression Imported successfully
2023-04-25 13:08:21,224:INFO:Starting cross validation
2023-04-25 13:08:21,225:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 13:08:21,275:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 13:08:21,285:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 13:08:21,294:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 13:08:21,302:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 13:08:21,308:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 13:08:21,320:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 13:08:21,328:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 13:08:21,340:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 13:08:21,348:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 13:08:21,357:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 13:08:21,397:INFO:Calculating mean and std
2023-04-25 13:08:21,397:INFO:Creating metrics dataframe
2023-04-25 13:08:21,424:INFO:Uploading results into container
2023-04-25 13:08:21,426:INFO:Uploading model into container now
2023-04-25 13:08:21,427:INFO:_master_model_container: 6
2023-04-25 13:08:21,427:INFO:_display_container: 2
2023-04-25 13:08:21,427:INFO:LassoLars(random_state=6957)
2023-04-25 13:08:21,427:INFO:create_model() successfully completed......................................
2023-04-25 13:08:21,543:INFO:SubProcess create_model() end ==================================
2023-04-25 13:08:21,544:INFO:Creating metrics dataframe
2023-04-25 13:08:21,547:INFO:Initializing Orthogonal Matching Pursuit
2023-04-25 13:08:21,547:INFO:Total runtime is 0.14452653328577678 minutes
2023-04-25 13:08:21,547:INFO:SubProcess create_model() called ==================================
2023-04-25 13:08:21,547:INFO:Initializing create_model()
2023-04-25 13:08:21,547:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF72CD610>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF963A580>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 13:08:21,547:INFO:Checking exceptions
2023-04-25 13:08:21,547:INFO:Importing libraries
2023-04-25 13:08:21,547:INFO:Copying training dataset
2023-04-25 13:08:21,550:INFO:Defining folds
2023-04-25 13:08:21,550:INFO:Declaring metric variables
2023-04-25 13:08:21,550:INFO:Importing untrained model
2023-04-25 13:08:21,550:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-25 13:08:21,550:INFO:Starting cross validation
2023-04-25 13:08:21,550:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 13:08:21,583:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 13:08:21,587:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 13:08:21,596:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 13:08:21,602:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 13:08:21,615:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 13:08:21,624:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 13:08:21,633:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 13:08:21,644:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 13:08:21,651:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 13:08:21,663:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 13:08:21,705:INFO:Calculating mean and std
2023-04-25 13:08:21,706:INFO:Creating metrics dataframe
2023-04-25 13:08:21,717:INFO:Uploading results into container
2023-04-25 13:08:21,718:INFO:Uploading model into container now
2023-04-25 13:08:21,718:INFO:_master_model_container: 7
2023-04-25 13:08:21,718:INFO:_display_container: 2
2023-04-25 13:08:21,718:INFO:OrthogonalMatchingPursuit()
2023-04-25 13:08:21,718:INFO:create_model() successfully completed......................................
2023-04-25 13:08:21,833:INFO:SubProcess create_model() end ==================================
2023-04-25 13:08:21,833:INFO:Creating metrics dataframe
2023-04-25 13:08:21,838:INFO:Initializing Bayesian Ridge
2023-04-25 13:08:21,838:INFO:Total runtime is 0.14937347571055096 minutes
2023-04-25 13:08:21,838:INFO:SubProcess create_model() called ==================================
2023-04-25 13:08:21,838:INFO:Initializing create_model()
2023-04-25 13:08:21,838:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF72CD610>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF963A580>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 13:08:21,838:INFO:Checking exceptions
2023-04-25 13:08:21,838:INFO:Importing libraries
2023-04-25 13:08:21,839:INFO:Copying training dataset
2023-04-25 13:08:21,842:INFO:Defining folds
2023-04-25 13:08:21,842:INFO:Declaring metric variables
2023-04-25 13:08:21,842:INFO:Importing untrained model
2023-04-25 13:08:21,842:INFO:Bayesian Ridge Imported successfully
2023-04-25 13:08:21,843:INFO:Starting cross validation
2023-04-25 13:08:21,843:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 13:08:22,009:INFO:Calculating mean and std
2023-04-25 13:08:22,009:INFO:Creating metrics dataframe
2023-04-25 13:08:22,020:INFO:Uploading results into container
2023-04-25 13:08:22,020:INFO:Uploading model into container now
2023-04-25 13:08:22,021:INFO:_master_model_container: 8
2023-04-25 13:08:22,021:INFO:_display_container: 2
2023-04-25 13:08:22,021:INFO:BayesianRidge()
2023-04-25 13:08:22,021:INFO:create_model() successfully completed......................................
2023-04-25 13:08:22,136:INFO:SubProcess create_model() end ==================================
2023-04-25 13:08:22,136:INFO:Creating metrics dataframe
2023-04-25 13:08:22,140:INFO:Initializing Passive Aggressive Regressor
2023-04-25 13:08:22,140:INFO:Total runtime is 0.15439369281133017 minutes
2023-04-25 13:08:22,140:INFO:SubProcess create_model() called ==================================
2023-04-25 13:08:22,140:INFO:Initializing create_model()
2023-04-25 13:08:22,140:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF72CD610>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF963A580>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 13:08:22,140:INFO:Checking exceptions
2023-04-25 13:08:22,140:INFO:Importing libraries
2023-04-25 13:08:22,140:INFO:Copying training dataset
2023-04-25 13:08:22,142:INFO:Defining folds
2023-04-25 13:08:22,142:INFO:Declaring metric variables
2023-04-25 13:08:22,142:INFO:Importing untrained model
2023-04-25 13:08:22,142:INFO:Passive Aggressive Regressor Imported successfully
2023-04-25 13:08:22,143:INFO:Starting cross validation
2023-04-25 13:08:22,143:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 13:08:22,279:INFO:Calculating mean and std
2023-04-25 13:08:22,280:INFO:Creating metrics dataframe
2023-04-25 13:08:22,289:INFO:Uploading results into container
2023-04-25 13:08:22,290:INFO:Uploading model into container now
2023-04-25 13:08:22,290:INFO:_master_model_container: 9
2023-04-25 13:08:22,290:INFO:_display_container: 2
2023-04-25 13:08:22,290:INFO:PassiveAggressiveRegressor(random_state=6957)
2023-04-25 13:08:22,290:INFO:create_model() successfully completed......................................
2023-04-25 13:08:22,398:INFO:SubProcess create_model() end ==================================
2023-04-25 13:08:22,398:INFO:Creating metrics dataframe
2023-04-25 13:08:22,401:INFO:Initializing Huber Regressor
2023-04-25 13:08:22,401:INFO:Total runtime is 0.15875608523686727 minutes
2023-04-25 13:08:22,401:INFO:SubProcess create_model() called ==================================
2023-04-25 13:08:22,402:INFO:Initializing create_model()
2023-04-25 13:08:22,402:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF72CD610>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF963A580>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 13:08:22,402:INFO:Checking exceptions
2023-04-25 13:08:22,402:INFO:Importing libraries
2023-04-25 13:08:22,402:INFO:Copying training dataset
2023-04-25 13:08:22,404:INFO:Defining folds
2023-04-25 13:08:22,404:INFO:Declaring metric variables
2023-04-25 13:08:22,404:INFO:Importing untrained model
2023-04-25 13:08:22,404:INFO:Huber Regressor Imported successfully
2023-04-25 13:08:22,404:INFO:Starting cross validation
2023-04-25 13:08:22,404:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 13:08:22,552:INFO:Calculating mean and std
2023-04-25 13:08:22,553:INFO:Creating metrics dataframe
2023-04-25 13:08:22,563:INFO:Uploading results into container
2023-04-25 13:08:22,564:INFO:Uploading model into container now
2023-04-25 13:08:22,564:INFO:_master_model_container: 10
2023-04-25 13:08:22,564:INFO:_display_container: 2
2023-04-25 13:08:22,564:INFO:HuberRegressor()
2023-04-25 13:08:22,564:INFO:create_model() successfully completed......................................
2023-04-25 13:08:22,676:INFO:SubProcess create_model() end ==================================
2023-04-25 13:08:22,676:INFO:Creating metrics dataframe
2023-04-25 13:08:22,680:INFO:Initializing K Neighbors Regressor
2023-04-25 13:08:22,680:INFO:Total runtime is 0.1634056846300761 minutes
2023-04-25 13:08:22,680:INFO:SubProcess create_model() called ==================================
2023-04-25 13:08:22,681:INFO:Initializing create_model()
2023-04-25 13:08:22,681:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF72CD610>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF963A580>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 13:08:22,681:INFO:Checking exceptions
2023-04-25 13:08:22,681:INFO:Importing libraries
2023-04-25 13:08:22,681:INFO:Copying training dataset
2023-04-25 13:08:22,683:INFO:Defining folds
2023-04-25 13:08:22,683:INFO:Declaring metric variables
2023-04-25 13:08:22,683:INFO:Importing untrained model
2023-04-25 13:08:22,684:INFO:K Neighbors Regressor Imported successfully
2023-04-25 13:08:22,684:INFO:Starting cross validation
2023-04-25 13:08:22,684:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 13:08:22,835:INFO:Calculating mean and std
2023-04-25 13:08:22,836:INFO:Creating metrics dataframe
2023-04-25 13:08:22,845:INFO:Uploading results into container
2023-04-25 13:08:22,846:INFO:Uploading model into container now
2023-04-25 13:08:22,846:INFO:_master_model_container: 11
2023-04-25 13:08:22,846:INFO:_display_container: 2
2023-04-25 13:08:22,846:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-25 13:08:22,847:INFO:create_model() successfully completed......................................
2023-04-25 13:08:22,959:INFO:SubProcess create_model() end ==================================
2023-04-25 13:08:22,959:INFO:Creating metrics dataframe
2023-04-25 13:08:22,963:INFO:Initializing Decision Tree Regressor
2023-04-25 13:08:22,963:INFO:Total runtime is 0.16812520821889243 minutes
2023-04-25 13:08:22,963:INFO:SubProcess create_model() called ==================================
2023-04-25 13:08:22,963:INFO:Initializing create_model()
2023-04-25 13:08:22,963:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF72CD610>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF963A580>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 13:08:22,963:INFO:Checking exceptions
2023-04-25 13:08:22,963:INFO:Importing libraries
2023-04-25 13:08:22,963:INFO:Copying training dataset
2023-04-25 13:08:22,966:INFO:Defining folds
2023-04-25 13:08:22,966:INFO:Declaring metric variables
2023-04-25 13:08:22,966:INFO:Importing untrained model
2023-04-25 13:08:22,967:INFO:Decision Tree Regressor Imported successfully
2023-04-25 13:08:22,967:INFO:Starting cross validation
2023-04-25 13:08:22,967:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 13:08:23,107:INFO:Calculating mean and std
2023-04-25 13:08:23,108:INFO:Creating metrics dataframe
2023-04-25 13:08:23,118:INFO:Uploading results into container
2023-04-25 13:08:23,118:INFO:Uploading model into container now
2023-04-25 13:08:23,118:INFO:_master_model_container: 12
2023-04-25 13:08:23,119:INFO:_display_container: 2
2023-04-25 13:08:23,119:INFO:DecisionTreeRegressor(random_state=6957)
2023-04-25 13:08:23,119:INFO:create_model() successfully completed......................................
2023-04-25 13:08:23,229:INFO:SubProcess create_model() end ==================================
2023-04-25 13:08:23,230:INFO:Creating metrics dataframe
2023-04-25 13:08:23,234:INFO:Initializing Random Forest Regressor
2023-04-25 13:08:23,234:INFO:Total runtime is 0.17262745698293053 minutes
2023-04-25 13:08:23,234:INFO:SubProcess create_model() called ==================================
2023-04-25 13:08:23,234:INFO:Initializing create_model()
2023-04-25 13:08:23,234:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF72CD610>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF963A580>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 13:08:23,234:INFO:Checking exceptions
2023-04-25 13:08:23,235:INFO:Importing libraries
2023-04-25 13:08:23,235:INFO:Copying training dataset
2023-04-25 13:08:23,237:INFO:Defining folds
2023-04-25 13:08:23,237:INFO:Declaring metric variables
2023-04-25 13:08:23,237:INFO:Importing untrained model
2023-04-25 13:08:23,237:INFO:Random Forest Regressor Imported successfully
2023-04-25 13:08:23,237:INFO:Starting cross validation
2023-04-25 13:08:23,238:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 13:08:23,901:INFO:Calculating mean and std
2023-04-25 13:08:23,902:INFO:Creating metrics dataframe
2023-04-25 13:08:23,915:INFO:Uploading results into container
2023-04-25 13:08:23,916:INFO:Uploading model into container now
2023-04-25 13:08:23,916:INFO:_master_model_container: 13
2023-04-25 13:08:23,916:INFO:_display_container: 2
2023-04-25 13:08:23,916:INFO:RandomForestRegressor(n_jobs=-1, random_state=6957)
2023-04-25 13:08:23,916:INFO:create_model() successfully completed......................................
2023-04-25 13:08:24,025:INFO:SubProcess create_model() end ==================================
2023-04-25 13:08:24,026:INFO:Creating metrics dataframe
2023-04-25 13:08:24,029:INFO:Initializing Extra Trees Regressor
2023-04-25 13:08:24,029:INFO:Total runtime is 0.18588605721791587 minutes
2023-04-25 13:08:24,029:INFO:SubProcess create_model() called ==================================
2023-04-25 13:08:24,030:INFO:Initializing create_model()
2023-04-25 13:08:24,030:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF72CD610>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF963A580>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 13:08:24,030:INFO:Checking exceptions
2023-04-25 13:08:24,030:INFO:Importing libraries
2023-04-25 13:08:24,030:INFO:Copying training dataset
2023-04-25 13:08:24,032:INFO:Defining folds
2023-04-25 13:08:24,032:INFO:Declaring metric variables
2023-04-25 13:08:24,032:INFO:Importing untrained model
2023-04-25 13:08:24,032:INFO:Extra Trees Regressor Imported successfully
2023-04-25 13:08:24,032:INFO:Starting cross validation
2023-04-25 13:08:24,033:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 13:08:24,573:INFO:Calculating mean and std
2023-04-25 13:08:24,574:INFO:Creating metrics dataframe
2023-04-25 13:08:24,589:INFO:Uploading results into container
2023-04-25 13:08:24,589:INFO:Uploading model into container now
2023-04-25 13:08:24,590:INFO:_master_model_container: 14
2023-04-25 13:08:24,590:INFO:_display_container: 2
2023-04-25 13:08:24,590:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6957)
2023-04-25 13:08:24,590:INFO:create_model() successfully completed......................................
2023-04-25 13:08:24,698:INFO:SubProcess create_model() end ==================================
2023-04-25 13:08:24,698:INFO:Creating metrics dataframe
2023-04-25 13:08:24,701:INFO:Initializing AdaBoost Regressor
2023-04-25 13:08:24,701:INFO:Total runtime is 0.19708012342453005 minutes
2023-04-25 13:08:24,701:INFO:SubProcess create_model() called ==================================
2023-04-25 13:08:24,701:INFO:Initializing create_model()
2023-04-25 13:08:24,701:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF72CD610>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF963A580>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 13:08:24,701:INFO:Checking exceptions
2023-04-25 13:08:24,701:INFO:Importing libraries
2023-04-25 13:08:24,701:INFO:Copying training dataset
2023-04-25 13:08:24,703:INFO:Defining folds
2023-04-25 13:08:24,703:INFO:Declaring metric variables
2023-04-25 13:08:24,703:INFO:Importing untrained model
2023-04-25 13:08:24,703:INFO:AdaBoost Regressor Imported successfully
2023-04-25 13:08:24,703:INFO:Starting cross validation
2023-04-25 13:08:24,704:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 13:08:24,986:INFO:Calculating mean and std
2023-04-25 13:08:24,987:INFO:Creating metrics dataframe
2023-04-25 13:08:25,003:INFO:Uploading results into container
2023-04-25 13:08:25,004:INFO:Uploading model into container now
2023-04-25 13:08:25,004:INFO:_master_model_container: 15
2023-04-25 13:08:25,004:INFO:_display_container: 2
2023-04-25 13:08:25,004:INFO:AdaBoostRegressor(random_state=6957)
2023-04-25 13:08:25,004:INFO:create_model() successfully completed......................................
2023-04-25 13:08:25,115:INFO:SubProcess create_model() end ==================================
2023-04-25 13:08:25,115:INFO:Creating metrics dataframe
2023-04-25 13:08:25,118:INFO:Initializing Gradient Boosting Regressor
2023-04-25 13:08:25,118:INFO:Total runtime is 0.20402709245681763 minutes
2023-04-25 13:08:25,119:INFO:SubProcess create_model() called ==================================
2023-04-25 13:08:25,119:INFO:Initializing create_model()
2023-04-25 13:08:25,119:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF72CD610>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF963A580>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 13:08:25,119:INFO:Checking exceptions
2023-04-25 13:08:25,119:INFO:Importing libraries
2023-04-25 13:08:25,119:INFO:Copying training dataset
2023-04-25 13:08:25,121:INFO:Defining folds
2023-04-25 13:08:25,121:INFO:Declaring metric variables
2023-04-25 13:08:25,121:INFO:Importing untrained model
2023-04-25 13:08:25,121:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 13:08:25,121:INFO:Starting cross validation
2023-04-25 13:08:25,122:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 13:08:25,372:INFO:Calculating mean and std
2023-04-25 13:08:25,373:INFO:Creating metrics dataframe
2023-04-25 13:08:25,389:INFO:Uploading results into container
2023-04-25 13:08:25,391:INFO:Uploading model into container now
2023-04-25 13:08:25,391:INFO:_master_model_container: 16
2023-04-25 13:08:25,391:INFO:_display_container: 2
2023-04-25 13:08:25,392:INFO:GradientBoostingRegressor(random_state=6957)
2023-04-25 13:08:25,392:INFO:create_model() successfully completed......................................
2023-04-25 13:08:25,503:INFO:SubProcess create_model() end ==================================
2023-04-25 13:08:25,504:INFO:Creating metrics dataframe
2023-04-25 13:08:25,507:INFO:Initializing Light Gradient Boosting Machine
2023-04-25 13:08:25,507:INFO:Total runtime is 0.21051944494247438 minutes
2023-04-25 13:08:25,507:INFO:SubProcess create_model() called ==================================
2023-04-25 13:08:25,507:INFO:Initializing create_model()
2023-04-25 13:08:25,507:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF72CD610>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF963A580>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 13:08:25,507:INFO:Checking exceptions
2023-04-25 13:08:25,507:INFO:Importing libraries
2023-04-25 13:08:25,507:INFO:Copying training dataset
2023-04-25 13:08:25,509:INFO:Defining folds
2023-04-25 13:08:25,509:INFO:Declaring metric variables
2023-04-25 13:08:25,509:INFO:Importing untrained model
2023-04-25 13:08:25,510:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 13:08:25,510:INFO:Starting cross validation
2023-04-25 13:08:25,510:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 13:08:26,658:INFO:Calculating mean and std
2023-04-25 13:08:26,659:INFO:Creating metrics dataframe
2023-04-25 13:08:26,674:INFO:Uploading results into container
2023-04-25 13:08:26,674:INFO:Uploading model into container now
2023-04-25 13:08:26,674:INFO:_master_model_container: 17
2023-04-25 13:08:26,674:INFO:_display_container: 2
2023-04-25 13:08:26,676:INFO:LGBMRegressor(random_state=6957)
2023-04-25 13:08:26,676:INFO:create_model() successfully completed......................................
2023-04-25 13:08:26,788:INFO:SubProcess create_model() end ==================================
2023-04-25 13:08:26,788:INFO:Creating metrics dataframe
2023-04-25 13:08:26,791:INFO:Initializing Dummy Regressor
2023-04-25 13:08:26,791:INFO:Total runtime is 0.23191290696461997 minutes
2023-04-25 13:08:26,791:INFO:SubProcess create_model() called ==================================
2023-04-25 13:08:26,791:INFO:Initializing create_model()
2023-04-25 13:08:26,791:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF72CD610>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF963A580>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 13:08:26,791:INFO:Checking exceptions
2023-04-25 13:08:26,791:INFO:Importing libraries
2023-04-25 13:08:26,791:INFO:Copying training dataset
2023-04-25 13:08:26,793:INFO:Defining folds
2023-04-25 13:08:26,793:INFO:Declaring metric variables
2023-04-25 13:08:26,794:INFO:Importing untrained model
2023-04-25 13:08:26,794:INFO:Dummy Regressor Imported successfully
2023-04-25 13:08:26,794:INFO:Starting cross validation
2023-04-25 13:08:26,794:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 13:08:26,982:INFO:Calculating mean and std
2023-04-25 13:08:26,982:INFO:Creating metrics dataframe
2023-04-25 13:08:27,000:INFO:Uploading results into container
2023-04-25 13:08:27,000:INFO:Uploading model into container now
2023-04-25 13:08:27,002:INFO:_master_model_container: 18
2023-04-25 13:08:27,002:INFO:_display_container: 2
2023-04-25 13:08:27,002:INFO:DummyRegressor()
2023-04-25 13:08:27,002:INFO:create_model() successfully completed......................................
2023-04-25 13:08:27,121:INFO:SubProcess create_model() end ==================================
2023-04-25 13:08:27,121:INFO:Creating metrics dataframe
2023-04-25 13:08:27,126:INFO:Initializing create_model()
2023-04-25 13:08:27,126:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF72CD610>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=6957), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 13:08:27,126:INFO:Checking exceptions
2023-04-25 13:08:27,126:INFO:Importing libraries
2023-04-25 13:08:27,126:INFO:Copying training dataset
2023-04-25 13:08:27,129:INFO:Defining folds
2023-04-25 13:08:27,129:INFO:Declaring metric variables
2023-04-25 13:08:27,129:INFO:Importing untrained model
2023-04-25 13:08:27,129:INFO:Declaring custom model
2023-04-25 13:08:27,130:INFO:Extra Trees Regressor Imported successfully
2023-04-25 13:08:27,130:INFO:Cross validation set to False
2023-04-25 13:08:27,130:INFO:Fitting Model
2023-04-25 13:08:27,210:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6957)
2023-04-25 13:08:27,210:INFO:create_model() successfully completed......................................
2023-04-25 13:08:27,338:INFO:_master_model_container: 18
2023-04-25 13:08:27,338:INFO:_display_container: 2
2023-04-25 13:08:27,338:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6957)
2023-04-25 13:08:27,338:INFO:compare_models() successfully completed......................................
2023-04-25 13:08:27,341:INFO:Initializing save_model()
2023-04-25 13:08:27,341:INFO:save_model(model=ExtraTreesRegressor(n_jobs=-1, random_state=6957), model_name=best_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\91888\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['TV', 'Radio', 'Newspaper'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-04-25 13:08:27,341:INFO:Adding model into prep_pipe
2023-04-25 13:08:27,369:INFO:best_model.pkl saved in current working directory
2023-04-25 13:08:27,372:INFO:Pipeline(memory=FastMemory(location=C:\Users\91888\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['TV', 'Radio', 'Newspaper'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('trained_model',
                 ExtraTreesRegressor(n_jobs=-1, random_state=6957))])
2023-04-25 13:08:27,372:INFO:save_model() successfully completed......................................
2023-04-25 13:37:57,102:INFO:PyCaret ClassificationExperiment
2023-04-25 13:37:57,102:INFO:Logging name: clf-default-name
2023-04-25 13:37:57,102:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-25 13:37:57,102:INFO:version 3.0.0
2023-04-25 13:37:57,102:INFO:Initializing setup()
2023-04-25 13:37:57,102:INFO:self.USI: 0dba
2023-04-25 13:37:57,102:INFO:self._variable_keys: {'html_param', '_ml_usecase', 'X_test', 'n_jobs_param', 'exp_name_log', 'memory', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param', 'USI', 'seed', 'X_train', 'X', 'gpu_param', 'pipeline', 'target_param', 'fix_imbalance', 'data', 'idx', 'fold_groups_param', 'y_train', 'fold_shuffle_param', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_id', 'is_multiclass'}
2023-04-25 13:37:57,102:INFO:Checking environment
2023-04-25 13:37:57,102:INFO:python_version: 3.9.12
2023-04-25 13:37:57,103:INFO:python_build: ('main', 'Apr  4 2022 05:22:27')
2023-04-25 13:37:57,103:INFO:machine: AMD64
2023-04-25 13:37:57,103:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-25 13:37:57,103:INFO:Memory: svmem(total=8362713088, available=1379950592, percent=83.5, used=6982762496, free=1379950592)
2023-04-25 13:37:57,103:INFO:Physical Core: 4
2023-04-25 13:37:57,103:INFO:Logical Core: 8
2023-04-25 13:37:57,103:INFO:Checking libraries
2023-04-25 13:37:57,103:INFO:System:
2023-04-25 13:37:57,103:INFO:    python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]
2023-04-25 13:37:57,103:INFO:executable: C:\Users\91888\anaconda3\python.exe
2023-04-25 13:37:57,103:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-25 13:37:57,103:INFO:PyCaret required dependencies:
2023-04-25 13:37:57,103:INFO:                 pip: 21.2.4
2023-04-25 13:37:57,103:INFO:          setuptools: 61.2.0
2023-04-25 13:37:57,103:INFO:             pycaret: 3.0.0
2023-04-25 13:37:57,103:INFO:             IPython: 8.2.0
2023-04-25 13:37:57,104:INFO:          ipywidgets: 7.6.5
2023-04-25 13:37:57,104:INFO:                tqdm: 4.64.0
2023-04-25 13:37:57,104:INFO:               numpy: 1.21.5
2023-04-25 13:37:57,104:INFO:              pandas: 1.4.2
2023-04-25 13:37:57,104:INFO:              jinja2: 2.11.3
2023-04-25 13:37:57,104:INFO:               scipy: 1.7.3
2023-04-25 13:37:57,104:INFO:              joblib: 1.2.0
2023-04-25 13:37:57,104:INFO:             sklearn: 1.0.2
2023-04-25 13:37:57,104:INFO:                pyod: 1.0.9
2023-04-25 13:37:57,104:INFO:            imblearn: 0.10.1
2023-04-25 13:37:57,104:INFO:   category_encoders: 2.6.0
2023-04-25 13:37:57,104:INFO:            lightgbm: 3.3.5
2023-04-25 13:37:57,104:INFO:               numba: 0.55.1
2023-04-25 13:37:57,104:INFO:            requests: 2.27.1
2023-04-25 13:37:57,104:INFO:          matplotlib: 3.5.1
2023-04-25 13:37:57,104:INFO:          scikitplot: 0.3.7
2023-04-25 13:37:57,104:INFO:         yellowbrick: 1.5
2023-04-25 13:37:57,104:INFO:              plotly: 5.6.0
2023-04-25 13:37:57,104:INFO:             kaleido: 0.2.1
2023-04-25 13:37:57,104:INFO:         statsmodels: 0.13.2
2023-04-25 13:37:57,104:INFO:              sktime: 0.17.1
2023-04-25 13:37:57,104:INFO:               tbats: 1.1.3
2023-04-25 13:37:57,105:INFO:            pmdarima: 2.0.3
2023-04-25 13:37:57,105:INFO:              psutil: 5.9.5
2023-04-25 13:37:57,105:INFO:PyCaret optional dependencies:
2023-04-25 13:37:57,105:INFO:                shap: Not installed
2023-04-25 13:37:57,105:INFO:           interpret: Not installed
2023-04-25 13:37:57,105:INFO:                umap: Not installed
2023-04-25 13:37:57,105:INFO:    pandas_profiling: 4.1.2
2023-04-25 13:37:57,105:INFO:  explainerdashboard: Not installed
2023-04-25 13:37:57,105:INFO:             autoviz: Not installed
2023-04-25 13:37:57,105:INFO:           fairlearn: Not installed
2023-04-25 13:37:57,105:INFO:             xgboost: Not installed
2023-04-25 13:37:57,105:INFO:            catboost: Not installed
2023-04-25 13:37:57,105:INFO:              kmodes: Not installed
2023-04-25 13:37:57,105:INFO:             mlxtend: Not installed
2023-04-25 13:37:57,105:INFO:       statsforecast: Not installed
2023-04-25 13:37:57,105:INFO:        tune_sklearn: Not installed
2023-04-25 13:37:57,105:INFO:                 ray: Not installed
2023-04-25 13:37:57,105:INFO:            hyperopt: Not installed
2023-04-25 13:37:57,105:INFO:              optuna: Not installed
2023-04-25 13:37:57,105:INFO:               skopt: Not installed
2023-04-25 13:37:57,105:INFO:              mlflow: Not installed
2023-04-25 13:37:57,105:INFO:              gradio: Not installed
2023-04-25 13:37:57,106:INFO:             fastapi: Not installed
2023-04-25 13:37:57,106:INFO:             uvicorn: Not installed
2023-04-25 13:37:57,106:INFO:              m2cgen: Not installed
2023-04-25 13:37:57,106:INFO:           evidently: Not installed
2023-04-25 13:37:57,106:INFO:               fugue: Not installed
2023-04-25 13:37:57,106:INFO:           streamlit: 1.21.0
2023-04-25 13:37:57,106:INFO:             prophet: Not installed
2023-04-25 13:37:57,106:INFO:None
2023-04-25 13:37:57,106:INFO:Set up data.
2023-04-25 13:37:57,112:INFO:Set up train/test split.
2023-04-25 15:17:30,878:INFO:PyCaret ClassificationExperiment
2023-04-25 15:17:30,878:INFO:Logging name: clf-default-name
2023-04-25 15:17:30,878:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-25 15:17:30,878:INFO:version 3.0.0
2023-04-25 15:17:30,878:INFO:Initializing setup()
2023-04-25 15:17:30,878:INFO:self.USI: 2ad2
2023-04-25 15:17:30,879:INFO:self._variable_keys: {'html_param', '_ml_usecase', 'X_test', 'n_jobs_param', 'exp_name_log', 'memory', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param', 'USI', 'seed', 'X_train', 'X', 'gpu_param', 'pipeline', 'target_param', 'fix_imbalance', 'data', 'idx', 'fold_groups_param', 'y_train', 'fold_shuffle_param', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_id', 'is_multiclass'}
2023-04-25 15:17:30,879:INFO:Checking environment
2023-04-25 15:17:30,879:INFO:python_version: 3.9.12
2023-04-25 15:17:30,879:INFO:python_build: ('main', 'Apr  4 2022 05:22:27')
2023-04-25 15:17:30,879:INFO:machine: AMD64
2023-04-25 15:17:30,880:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-25 15:17:30,880:INFO:Memory: svmem(total=8362713088, available=941690880, percent=88.7, used=7421022208, free=941690880)
2023-04-25 15:17:30,880:INFO:Physical Core: 4
2023-04-25 15:17:30,880:INFO:Logical Core: 8
2023-04-25 15:17:30,880:INFO:Checking libraries
2023-04-25 15:17:30,880:INFO:System:
2023-04-25 15:17:30,881:INFO:    python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]
2023-04-25 15:17:30,881:INFO:executable: C:\Users\91888\anaconda3\python.exe
2023-04-25 15:17:30,881:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-25 15:17:30,881:INFO:PyCaret required dependencies:
2023-04-25 15:17:30,881:INFO:                 pip: 21.2.4
2023-04-25 15:17:30,881:INFO:          setuptools: 61.2.0
2023-04-25 15:17:30,881:INFO:             pycaret: 3.0.0
2023-04-25 15:17:30,881:INFO:             IPython: 8.2.0
2023-04-25 15:17:30,881:INFO:          ipywidgets: 7.6.5
2023-04-25 15:17:30,882:INFO:                tqdm: 4.64.0
2023-04-25 15:17:30,882:INFO:               numpy: 1.21.5
2023-04-25 15:17:30,882:INFO:              pandas: 1.4.2
2023-04-25 15:17:30,882:INFO:              jinja2: 2.11.3
2023-04-25 15:17:30,882:INFO:               scipy: 1.7.3
2023-04-25 15:17:30,882:INFO:              joblib: 1.2.0
2023-04-25 15:17:30,882:INFO:             sklearn: 1.0.2
2023-04-25 15:17:30,882:INFO:                pyod: 1.0.9
2023-04-25 15:17:30,882:INFO:            imblearn: 0.10.1
2023-04-25 15:17:30,882:INFO:   category_encoders: 2.6.0
2023-04-25 15:17:30,882:INFO:            lightgbm: 3.3.5
2023-04-25 15:17:30,882:INFO:               numba: 0.55.1
2023-04-25 15:17:30,883:INFO:            requests: 2.27.1
2023-04-25 15:17:30,883:INFO:          matplotlib: 3.5.1
2023-04-25 15:17:30,883:INFO:          scikitplot: 0.3.7
2023-04-25 15:17:30,883:INFO:         yellowbrick: 1.5
2023-04-25 15:17:30,883:INFO:              plotly: 5.6.0
2023-04-25 15:17:30,883:INFO:             kaleido: 0.2.1
2023-04-25 15:17:30,883:INFO:         statsmodels: 0.13.2
2023-04-25 15:17:30,883:INFO:              sktime: 0.17.1
2023-04-25 15:17:30,883:INFO:               tbats: 1.1.3
2023-04-25 15:17:30,883:INFO:            pmdarima: 2.0.3
2023-04-25 15:17:30,883:INFO:              psutil: 5.9.5
2023-04-25 15:17:30,883:INFO:PyCaret optional dependencies:
2023-04-25 15:17:30,884:INFO:                shap: Not installed
2023-04-25 15:17:30,884:INFO:           interpret: Not installed
2023-04-25 15:17:30,884:INFO:                umap: Not installed
2023-04-25 15:17:30,884:INFO:    pandas_profiling: 4.1.2
2023-04-25 15:17:30,884:INFO:  explainerdashboard: Not installed
2023-04-25 15:17:30,884:INFO:             autoviz: Not installed
2023-04-25 15:17:30,884:INFO:           fairlearn: Not installed
2023-04-25 15:17:30,884:INFO:             xgboost: Not installed
2023-04-25 15:17:30,884:INFO:            catboost: Not installed
2023-04-25 15:17:30,884:INFO:              kmodes: Not installed
2023-04-25 15:17:30,885:INFO:             mlxtend: Not installed
2023-04-25 15:17:30,885:INFO:       statsforecast: Not installed
2023-04-25 15:17:30,885:INFO:        tune_sklearn: Not installed
2023-04-25 15:17:30,885:INFO:                 ray: Not installed
2023-04-25 15:17:30,885:INFO:            hyperopt: Not installed
2023-04-25 15:17:30,885:INFO:              optuna: Not installed
2023-04-25 15:17:30,885:INFO:               skopt: Not installed
2023-04-25 15:17:30,885:INFO:              mlflow: Not installed
2023-04-25 15:17:30,885:INFO:              gradio: Not installed
2023-04-25 15:17:30,885:INFO:             fastapi: Not installed
2023-04-25 15:17:30,887:INFO:             uvicorn: Not installed
2023-04-25 15:17:30,887:INFO:              m2cgen: Not installed
2023-04-25 15:17:30,887:INFO:           evidently: Not installed
2023-04-25 15:17:30,887:INFO:               fugue: Not installed
2023-04-25 15:17:30,887:INFO:           streamlit: 1.21.0
2023-04-25 15:17:30,887:INFO:             prophet: Not installed
2023-04-25 15:17:30,887:INFO:None
2023-04-25 15:17:30,887:INFO:Set up data.
2023-04-25 15:17:30,894:INFO:Set up train/test split.
2023-04-25 15:19:33,178:INFO:PyCaret ClassificationExperiment
2023-04-25 15:19:33,179:INFO:Logging name: clf-default-name
2023-04-25 15:19:33,179:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-25 15:19:33,179:INFO:version 3.0.0
2023-04-25 15:19:33,180:INFO:Initializing setup()
2023-04-25 15:19:33,180:INFO:self.USI: a132
2023-04-25 15:19:33,180:INFO:self._variable_keys: {'html_param', '_ml_usecase', 'X_test', 'n_jobs_param', 'exp_name_log', 'memory', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param', 'USI', 'seed', 'X_train', 'X', 'gpu_param', 'pipeline', 'target_param', 'fix_imbalance', 'data', 'idx', 'fold_groups_param', 'y_train', 'fold_shuffle_param', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_id', 'is_multiclass'}
2023-04-25 15:19:33,180:INFO:Checking environment
2023-04-25 15:19:33,180:INFO:python_version: 3.9.12
2023-04-25 15:19:33,180:INFO:python_build: ('main', 'Apr  4 2022 05:22:27')
2023-04-25 15:19:33,180:INFO:machine: AMD64
2023-04-25 15:19:33,180:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-25 15:19:33,181:INFO:Memory: svmem(total=8362713088, available=1178660864, percent=85.9, used=7184052224, free=1178660864)
2023-04-25 15:19:33,181:INFO:Physical Core: 4
2023-04-25 15:19:33,181:INFO:Logical Core: 8
2023-04-25 15:19:33,181:INFO:Checking libraries
2023-04-25 15:19:33,181:INFO:System:
2023-04-25 15:19:33,181:INFO:    python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]
2023-04-25 15:19:33,181:INFO:executable: C:\Users\91888\anaconda3\python.exe
2023-04-25 15:19:33,181:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-25 15:19:33,181:INFO:PyCaret required dependencies:
2023-04-25 15:19:33,182:INFO:                 pip: 21.2.4
2023-04-25 15:19:33,182:INFO:          setuptools: 61.2.0
2023-04-25 15:19:33,182:INFO:             pycaret: 3.0.0
2023-04-25 15:19:33,182:INFO:             IPython: 8.2.0
2023-04-25 15:19:33,182:INFO:          ipywidgets: 7.6.5
2023-04-25 15:19:33,182:INFO:                tqdm: 4.64.0
2023-04-25 15:19:33,182:INFO:               numpy: 1.21.5
2023-04-25 15:19:33,182:INFO:              pandas: 1.4.2
2023-04-25 15:19:33,182:INFO:              jinja2: 2.11.3
2023-04-25 15:19:33,182:INFO:               scipy: 1.7.3
2023-04-25 15:19:33,182:INFO:              joblib: 1.2.0
2023-04-25 15:19:33,182:INFO:             sklearn: 1.0.2
2023-04-25 15:19:33,183:INFO:                pyod: 1.0.9
2023-04-25 15:19:33,183:INFO:            imblearn: 0.10.1
2023-04-25 15:19:33,183:INFO:   category_encoders: 2.6.0
2023-04-25 15:19:33,183:INFO:            lightgbm: 3.3.5
2023-04-25 15:19:33,183:INFO:               numba: 0.55.1
2023-04-25 15:19:33,183:INFO:            requests: 2.27.1
2023-04-25 15:19:33,183:INFO:          matplotlib: 3.5.1
2023-04-25 15:19:33,183:INFO:          scikitplot: 0.3.7
2023-04-25 15:19:33,183:INFO:         yellowbrick: 1.5
2023-04-25 15:19:33,183:INFO:              plotly: 5.6.0
2023-04-25 15:19:33,183:INFO:             kaleido: 0.2.1
2023-04-25 15:19:33,183:INFO:         statsmodels: 0.13.2
2023-04-25 15:19:33,184:INFO:              sktime: 0.17.1
2023-04-25 15:19:33,184:INFO:               tbats: 1.1.3
2023-04-25 15:19:33,184:INFO:            pmdarima: 2.0.3
2023-04-25 15:19:33,184:INFO:              psutil: 5.9.5
2023-04-25 15:19:33,184:INFO:PyCaret optional dependencies:
2023-04-25 15:19:33,184:INFO:                shap: Not installed
2023-04-25 15:19:33,184:INFO:           interpret: Not installed
2023-04-25 15:19:33,184:INFO:                umap: Not installed
2023-04-25 15:19:33,184:INFO:    pandas_profiling: 4.1.2
2023-04-25 15:19:33,185:INFO:  explainerdashboard: Not installed
2023-04-25 15:19:33,185:INFO:             autoviz: Not installed
2023-04-25 15:19:33,185:INFO:           fairlearn: Not installed
2023-04-25 15:19:33,185:INFO:             xgboost: Not installed
2023-04-25 15:19:33,185:INFO:            catboost: Not installed
2023-04-25 15:19:33,185:INFO:              kmodes: Not installed
2023-04-25 15:19:33,185:INFO:             mlxtend: Not installed
2023-04-25 15:19:33,185:INFO:       statsforecast: Not installed
2023-04-25 15:19:33,185:INFO:        tune_sklearn: Not installed
2023-04-25 15:19:33,185:INFO:                 ray: Not installed
2023-04-25 15:19:33,185:INFO:            hyperopt: Not installed
2023-04-25 15:19:33,185:INFO:              optuna: Not installed
2023-04-25 15:19:33,186:INFO:               skopt: Not installed
2023-04-25 15:19:33,186:INFO:              mlflow: Not installed
2023-04-25 15:19:33,186:INFO:              gradio: Not installed
2023-04-25 15:19:33,186:INFO:             fastapi: Not installed
2023-04-25 15:19:33,186:INFO:             uvicorn: Not installed
2023-04-25 15:19:33,186:INFO:              m2cgen: Not installed
2023-04-25 15:19:33,186:INFO:           evidently: Not installed
2023-04-25 15:19:33,186:INFO:               fugue: Not installed
2023-04-25 15:19:33,186:INFO:           streamlit: 1.21.0
2023-04-25 15:19:33,186:INFO:             prophet: Not installed
2023-04-25 15:19:33,187:INFO:None
2023-04-25 15:19:33,187:INFO:Set up data.
2023-04-25 15:19:33,236:INFO:Set up train/test split.
2023-04-25 15:19:33,265:INFO:Set up index.
2023-04-25 15:19:33,265:INFO:Set up folding strategy.
2023-04-25 15:19:33,265:INFO:Assigning column types.
2023-04-25 15:19:33,273:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-25 15:19:33,402:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:19:33,426:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-25 15:19:33,503:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:19:33,504:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:19:33,623:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:19:33,626:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-25 15:19:33,699:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:19:33,700:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:19:33,701:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-25 15:19:33,820:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-25 15:19:33,890:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:19:33,890:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:19:34,025:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-25 15:19:34,103:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:19:34,104:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:19:34,105:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-25 15:19:34,297:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:19:34,297:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:19:34,502:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:19:34,502:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:19:34,506:INFO:Preparing preprocessing pipeline...
2023-04-25 15:19:34,519:INFO:Set up label encoding.
2023-04-25 15:19:34,519:INFO:Set up simple imputation.
2023-04-25 15:19:34,531:INFO:Set up encoding of ordinal features.
2023-04-25 15:19:34,552:INFO:Set up encoding of categorical features.
2023-04-25 15:19:35,013:INFO:Finished creating preprocessing pipeline.
2023-04-25 15:19:35,222:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\91888\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'age', 'bp', 'sg', 'al',
                                             'su', 'bgr', 'bu', 'sc', 'sod',
                                             'pot', 'hemo'],
                                    transformer=SimpleImputer(add_ind...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['pcv', 'wc', 'rc'],
                                    transformer=LeaveOneOutEncoder(cols=['pcv',
                                                                         'wc',
                                                                         'rc'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=4250,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0)))],
         verbose=False)
2023-04-25 15:19:35,222:INFO:Creating final display dataframe.
2023-04-25 15:19:36,675:INFO:Setup _display_container:                     Description                        Value
0                    Session id                         4250
1                        Target               classification
2                   Target type                   Multiclass
3                Target mapping  ckd: 0, ckd\t: 1, notckd: 2
4           Original data shape                    (400, 26)
5        Transformed data shape                    (400, 31)
6   Transformed train set shape                    (280, 31)
7    Transformed test set shape                    (120, 31)
8              Ordinal features                            8
9              Numeric features                           12
10         Categorical features                           13
11     Rows with missing values                        60.5%
12                   Preprocess                         True
13              Imputation type                       simple
14           Numeric imputation                         mean
15       Categorical imputation                         mode
16     Maximum one-hot encoding                           25
17              Encoding method                         None
18               Fold Generator              StratifiedKFold
19                  Fold Number                           10
20                     CPU Jobs                           -1
21                      Use GPU                        False
22               Log Experiment                        False
23              Experiment Name             clf-default-name
24                          USI                         a132
2023-04-25 15:19:36,882:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:19:36,883:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:19:37,078:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:19:37,079:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:19:37,080:INFO:setup() successfully completed in 3.93s...............
2023-04-25 15:21:51,206:INFO:PyCaret ClassificationExperiment
2023-04-25 15:21:51,206:INFO:Logging name: clf-default-name
2023-04-25 15:21:51,206:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-25 15:21:51,206:INFO:version 3.0.0
2023-04-25 15:21:51,206:INFO:Initializing setup()
2023-04-25 15:21:51,206:INFO:self.USI: 8989
2023-04-25 15:21:51,206:INFO:self._variable_keys: {'html_param', '_ml_usecase', 'X_test', 'n_jobs_param', 'exp_name_log', 'memory', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param', 'USI', 'seed', 'X_train', 'X', 'gpu_param', 'pipeline', 'target_param', 'fix_imbalance', 'data', 'idx', 'fold_groups_param', 'y_train', 'fold_shuffle_param', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_id', 'is_multiclass'}
2023-04-25 15:21:51,206:INFO:Checking environment
2023-04-25 15:21:51,206:INFO:python_version: 3.9.12
2023-04-25 15:21:51,206:INFO:python_build: ('main', 'Apr  4 2022 05:22:27')
2023-04-25 15:21:51,206:INFO:machine: AMD64
2023-04-25 15:21:51,206:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-25 15:21:51,206:INFO:Memory: svmem(total=8362713088, available=1244205056, percent=85.1, used=7118508032, free=1244205056)
2023-04-25 15:21:51,207:INFO:Physical Core: 4
2023-04-25 15:21:51,207:INFO:Logical Core: 8
2023-04-25 15:21:51,207:INFO:Checking libraries
2023-04-25 15:21:51,208:INFO:System:
2023-04-25 15:21:51,208:INFO:    python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]
2023-04-25 15:21:51,209:INFO:executable: C:\Users\91888\anaconda3\python.exe
2023-04-25 15:21:51,209:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-25 15:21:51,210:INFO:PyCaret required dependencies:
2023-04-25 15:21:51,210:INFO:                 pip: 21.2.4
2023-04-25 15:21:51,211:INFO:          setuptools: 61.2.0
2023-04-25 15:21:51,211:INFO:             pycaret: 3.0.0
2023-04-25 15:21:51,212:INFO:             IPython: 8.2.0
2023-04-25 15:21:51,212:INFO:          ipywidgets: 7.6.5
2023-04-25 15:21:51,212:INFO:                tqdm: 4.64.0
2023-04-25 15:21:51,212:INFO:               numpy: 1.21.5
2023-04-25 15:21:51,213:INFO:              pandas: 1.4.2
2023-04-25 15:21:51,213:INFO:              jinja2: 2.11.3
2023-04-25 15:21:51,214:INFO:               scipy: 1.7.3
2023-04-25 15:21:51,214:INFO:              joblib: 1.2.0
2023-04-25 15:21:51,215:INFO:             sklearn: 1.0.2
2023-04-25 15:21:51,215:INFO:                pyod: 1.0.9
2023-04-25 15:21:51,216:INFO:            imblearn: 0.10.1
2023-04-25 15:21:51,216:INFO:   category_encoders: 2.6.0
2023-04-25 15:21:51,216:INFO:            lightgbm: 3.3.5
2023-04-25 15:21:51,217:INFO:               numba: 0.55.1
2023-04-25 15:21:51,217:INFO:            requests: 2.27.1
2023-04-25 15:21:51,218:INFO:          matplotlib: 3.5.1
2023-04-25 15:21:51,218:INFO:          scikitplot: 0.3.7
2023-04-25 15:21:51,218:INFO:         yellowbrick: 1.5
2023-04-25 15:21:51,220:INFO:              plotly: 5.6.0
2023-04-25 15:21:51,220:INFO:             kaleido: 0.2.1
2023-04-25 15:21:51,221:INFO:         statsmodels: 0.13.2
2023-04-25 15:21:51,221:INFO:              sktime: 0.17.1
2023-04-25 15:21:51,222:INFO:               tbats: 1.1.3
2023-04-25 15:21:51,222:INFO:            pmdarima: 2.0.3
2023-04-25 15:21:51,222:INFO:              psutil: 5.9.5
2023-04-25 15:21:51,223:INFO:PyCaret optional dependencies:
2023-04-25 15:21:51,223:INFO:                shap: Not installed
2023-04-25 15:21:51,223:INFO:           interpret: Not installed
2023-04-25 15:21:51,223:INFO:                umap: Not installed
2023-04-25 15:21:51,223:INFO:    pandas_profiling: 4.1.2
2023-04-25 15:21:51,223:INFO:  explainerdashboard: Not installed
2023-04-25 15:21:51,224:INFO:             autoviz: Not installed
2023-04-25 15:21:51,224:INFO:           fairlearn: Not installed
2023-04-25 15:21:51,224:INFO:             xgboost: Not installed
2023-04-25 15:21:51,225:INFO:            catboost: Not installed
2023-04-25 15:21:51,226:INFO:              kmodes: Not installed
2023-04-25 15:21:51,226:INFO:             mlxtend: Not installed
2023-04-25 15:21:51,227:INFO:       statsforecast: Not installed
2023-04-25 15:21:51,227:INFO:        tune_sklearn: Not installed
2023-04-25 15:21:51,228:INFO:                 ray: Not installed
2023-04-25 15:21:51,228:INFO:            hyperopt: Not installed
2023-04-25 15:21:51,229:INFO:              optuna: Not installed
2023-04-25 15:21:51,229:INFO:               skopt: Not installed
2023-04-25 15:21:51,229:INFO:              mlflow: Not installed
2023-04-25 15:21:51,229:INFO:              gradio: Not installed
2023-04-25 15:21:51,230:INFO:             fastapi: Not installed
2023-04-25 15:21:51,230:INFO:             uvicorn: Not installed
2023-04-25 15:21:51,230:INFO:              m2cgen: Not installed
2023-04-25 15:21:51,231:INFO:           evidently: Not installed
2023-04-25 15:21:51,231:INFO:               fugue: Not installed
2023-04-25 15:21:51,232:INFO:           streamlit: 1.21.0
2023-04-25 15:21:51,232:INFO:             prophet: Not installed
2023-04-25 15:21:51,232:INFO:None
2023-04-25 15:21:51,232:INFO:Set up data.
2023-04-25 15:21:51,257:INFO:Set up train/test split.
2023-04-25 15:21:51,273:INFO:Set up index.
2023-04-25 15:21:51,273:INFO:Set up folding strategy.
2023-04-25 15:21:51,274:INFO:Assigning column types.
2023-04-25 15:21:51,281:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-25 15:21:51,399:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:21:51,402:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-25 15:21:51,478:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:21:51,479:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:21:51,604:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:21:51,606:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-25 15:21:51,682:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:21:51,683:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:21:51,684:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-25 15:21:51,801:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-25 15:21:51,881:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:21:51,881:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:21:52,009:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-25 15:21:52,082:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:21:52,082:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:21:52,083:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-25 15:21:52,280:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:21:52,281:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:21:52,472:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:21:52,473:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:21:52,474:INFO:Preparing preprocessing pipeline...
2023-04-25 15:21:52,477:INFO:Set up label encoding.
2023-04-25 15:21:52,477:INFO:Set up simple imputation.
2023-04-25 15:21:52,488:INFO:Set up encoding of ordinal features.
2023-04-25 15:21:52,508:INFO:Set up encoding of categorical features.
2023-04-25 15:21:52,921:INFO:Finished creating preprocessing pipeline.
2023-04-25 15:21:53,132:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\91888\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'age', 'bp', 'sg', 'al',
                                             'su', 'bgr', 'bu', 'sc', 'sod',
                                             'pot', 'hemo'],
                                    transformer=SimpleImputer(add_ind...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['pcv', 'wc', 'rc'],
                                    transformer=LeaveOneOutEncoder(cols=['pcv',
                                                                         'wc',
                                                                         'rc'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=747,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0)))],
         verbose=False)
2023-04-25 15:21:53,132:INFO:Creating final display dataframe.
2023-04-25 15:21:54,523:INFO:Setup _display_container:                     Description                        Value
0                    Session id                          747
1                        Target               classification
2                   Target type                   Multiclass
3                Target mapping  ckd: 0, ckd\t: 1, notckd: 2
4           Original data shape                    (400, 26)
5        Transformed data shape                    (400, 31)
6   Transformed train set shape                    (280, 31)
7    Transformed test set shape                    (120, 31)
8              Ordinal features                            8
9              Numeric features                           12
10         Categorical features                           13
11     Rows with missing values                        60.5%
12                   Preprocess                         True
13              Imputation type                       simple
14           Numeric imputation                         mean
15       Categorical imputation                         mode
16     Maximum one-hot encoding                           25
17              Encoding method                         None
18               Fold Generator              StratifiedKFold
19                  Fold Number                           10
20                     CPU Jobs                           -1
21                      Use GPU                        False
22               Log Experiment                        False
23              Experiment Name             clf-default-name
24                          USI                         8989
2023-04-25 15:21:54,739:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:21:54,740:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:21:54,928:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:21:54,929:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:21:54,930:INFO:setup() successfully completed in 3.76s...............
2023-04-25 15:21:54,938:INFO:Initializing compare_models()
2023-04-25 15:21:54,938:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CF2F61640>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000017CF2F61640>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-25 15:21:54,938:INFO:Checking exceptions
2023-04-25 15:21:54,946:INFO:Preparing display monitor
2023-04-25 15:21:54,953:INFO:Initializing Logistic Regression
2023-04-25 15:21:54,953:INFO:Total runtime is 0.0 minutes
2023-04-25 15:21:54,954:INFO:SubProcess create_model() called ==================================
2023-04-25 15:21:54,954:INFO:Initializing create_model()
2023-04-25 15:21:54,954:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CF2F61640>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2DD1940>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:21:54,954:INFO:Checking exceptions
2023-04-25 15:21:54,954:INFO:Importing libraries
2023-04-25 15:21:54,954:INFO:Copying training dataset
2023-04-25 15:21:54,965:INFO:Defining folds
2023-04-25 15:21:54,966:INFO:Declaring metric variables
2023-04-25 15:21:54,966:INFO:Importing untrained model
2023-04-25 15:21:54,967:INFO:Logistic Regression Imported successfully
2023-04-25 15:21:54,967:INFO:Starting cross validation
2023-04-25 15:21:54,971:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:21:54,976:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-04-25 15:22:02,409:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-25 15:22:02,409:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-25 15:22:02,409:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-25 15:22:02,409:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-25 15:22:02,425:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-25 15:22:02,431:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-25 15:22:02,437:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-25 15:22:02,445:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-25 15:22:02,906:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:02,907:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:02,907:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:02,907:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:02,908:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:02,910:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:02,910:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:02,910:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:02,910:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:02,910:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:02,911:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:02,911:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:02,911:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:02,911:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:02,912:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:02,912:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:02,912:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:02,912:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:02,912:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:02,912:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:02,913:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:02,913:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:02,913:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:02,913:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:02,913:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:02,914:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:02,914:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:02,914:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:02,914:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:02,914:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:02,915:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:02,915:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:02,915:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:02,915:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:02,916:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:02,917:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:02,917:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:02,917:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:02,917:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:02,918:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:02,918:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:02,919:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:02,919:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:02,920:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:02,921:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:02,922:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:02,922:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:02,923:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:03,973:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-25 15:22:04,228:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:04,230:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:04,234:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:04,235:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:04,236:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:04,814:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:04,815:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:04,817:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:04,818:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:04,820:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:04,821:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:04,822:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:04,826:INFO:Calculating mean and std
2023-04-25 15:22:04,829:INFO:Creating metrics dataframe
2023-04-25 15:22:04,919:INFO:Uploading results into container
2023-04-25 15:22:04,920:INFO:Uploading model into container now
2023-04-25 15:22:04,921:INFO:_master_model_container: 1
2023-04-25 15:22:04,921:INFO:_display_container: 2
2023-04-25 15:22:04,922:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=747, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-25 15:22:04,923:INFO:create_model() successfully completed......................................
2023-04-25 15:22:05,174:INFO:SubProcess create_model() end ==================================
2023-04-25 15:22:05,174:INFO:Creating metrics dataframe
2023-04-25 15:22:05,183:INFO:Initializing K Neighbors Classifier
2023-04-25 15:22:05,183:INFO:Total runtime is 0.17049678564071655 minutes
2023-04-25 15:22:05,184:INFO:SubProcess create_model() called ==================================
2023-04-25 15:22:05,184:INFO:Initializing create_model()
2023-04-25 15:22:05,184:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CF2F61640>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2DD1940>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:22:05,184:INFO:Checking exceptions
2023-04-25 15:22:05,185:INFO:Importing libraries
2023-04-25 15:22:05,185:INFO:Copying training dataset
2023-04-25 15:22:05,191:INFO:Defining folds
2023-04-25 15:22:05,191:INFO:Declaring metric variables
2023-04-25 15:22:05,192:INFO:Importing untrained model
2023-04-25 15:22:05,193:INFO:K Neighbors Classifier Imported successfully
2023-04-25 15:22:05,193:INFO:Starting cross validation
2023-04-25 15:22:05,198:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:22:05,200:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-04-25 15:22:07,016:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:07,089:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:07,090:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:07,121:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:07,165:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:07,189:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:07,190:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:07,191:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:07,193:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:07,194:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:07,196:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:07,199:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:07,201:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:07,260:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:07,261:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:07,262:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:07,264:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:07,265:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:07,266:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:07,267:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:07,268:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:07,269:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:07,270:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:07,272:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:07,274:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:07,277:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:07,279:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:07,287:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:07,288:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:07,289:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:07,289:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:07,291:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:07,293:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:07,293:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:07,346:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:07,348:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:07,350:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:07,353:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:07,355:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:07,357:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:07,359:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:07,377:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:07,379:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:07,381:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:07,383:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:07,386:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:07,388:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:07,389:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:07,497:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:07,532:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:07,632:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:07,634:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:07,636:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:07,638:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:07,640:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:07,642:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:07,645:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:07,683:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:07,684:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:07,685:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:07,687:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:07,688:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:07,690:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:07,691:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:08,779:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:08,781:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:08,783:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:08,785:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:08,787:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:08,788:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:08,789:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:08,839:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:08,841:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:08,843:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:08,844:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:08,846:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:08,851:INFO:Calculating mean and std
2023-04-25 15:22:08,853:INFO:Creating metrics dataframe
2023-04-25 15:22:08,950:INFO:Uploading results into container
2023-04-25 15:22:08,952:INFO:Uploading model into container now
2023-04-25 15:22:08,953:INFO:_master_model_container: 2
2023-04-25 15:22:08,953:INFO:_display_container: 2
2023-04-25 15:22:08,953:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-25 15:22:08,954:INFO:create_model() successfully completed......................................
2023-04-25 15:22:09,161:INFO:SubProcess create_model() end ==================================
2023-04-25 15:22:09,161:INFO:Creating metrics dataframe
2023-04-25 15:22:09,172:INFO:Initializing Naive Bayes
2023-04-25 15:22:09,172:INFO:Total runtime is 0.23698555628458656 minutes
2023-04-25 15:22:09,172:INFO:SubProcess create_model() called ==================================
2023-04-25 15:22:09,172:INFO:Initializing create_model()
2023-04-25 15:22:09,172:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CF2F61640>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2DD1940>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:22:09,172:INFO:Checking exceptions
2023-04-25 15:22:09,173:INFO:Importing libraries
2023-04-25 15:22:09,173:INFO:Copying training dataset
2023-04-25 15:22:09,182:INFO:Defining folds
2023-04-25 15:22:09,182:INFO:Declaring metric variables
2023-04-25 15:22:09,183:INFO:Importing untrained model
2023-04-25 15:22:09,183:INFO:Naive Bayes Imported successfully
2023-04-25 15:22:09,184:INFO:Starting cross validation
2023-04-25 15:22:09,188:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:22:09,190:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-04-25 15:22:10,999:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:11,019:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:11,027:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:11,070:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:11,100:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:11,102:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:11,103:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:11,121:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:11,123:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:11,124:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:11,125:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:11,125:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:11,127:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:11,128:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:11,128:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:11,129:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:11,130:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:11,130:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:11,132:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

"F-score is", len(true_sum))

2023-04-25 15:22:11,133:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:11,135:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:11,135:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:11,137:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:11,138:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:11,142:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:11,145:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:11,179:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:11,181:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:11,183:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:11,185:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:11,185:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:11,188:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:11,190:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:11,193:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:11,228:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:11,232:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:11,232:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:11,234:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:11,234:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:11,235:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:11,236:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:11,236:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:11,237:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:11,237:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:11,238:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:11,238:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:11,238:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:11,240:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:11,243:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:11,245:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:11,247:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:11,249:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:11,251:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:11,254:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:11,258:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:11,289:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:11,290:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:11,291:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:11,292:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:11,294:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:11,296:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:11,299:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:12,594:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:12,595:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:12,597:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:12,598:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:12,600:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:12,600:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:12,601:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:12,601:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:12,603:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:12,604:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:12,605:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:12,606:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:12,674:INFO:Calculating mean and std
2023-04-25 15:22:12,675:INFO:Creating metrics dataframe
2023-04-25 15:22:12,784:INFO:Uploading results into container
2023-04-25 15:22:12,786:INFO:Uploading model into container now
2023-04-25 15:22:12,787:INFO:_master_model_container: 3
2023-04-25 15:22:12,787:INFO:_display_container: 2
2023-04-25 15:22:12,787:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-25 15:22:12,787:INFO:create_model() successfully completed......................................
2023-04-25 15:22:12,992:INFO:SubProcess create_model() end ==================================
2023-04-25 15:22:12,993:INFO:Creating metrics dataframe
2023-04-25 15:22:13,002:INFO:Initializing Decision Tree Classifier
2023-04-25 15:22:13,002:INFO:Total runtime is 0.300807523727417 minutes
2023-04-25 15:22:13,003:INFO:SubProcess create_model() called ==================================
2023-04-25 15:22:13,003:INFO:Initializing create_model()
2023-04-25 15:22:13,004:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CF2F61640>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2DD1940>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:22:13,004:INFO:Checking exceptions
2023-04-25 15:22:13,004:INFO:Importing libraries
2023-04-25 15:22:13,004:INFO:Copying training dataset
2023-04-25 15:22:13,014:INFO:Defining folds
2023-04-25 15:22:13,014:INFO:Declaring metric variables
2023-04-25 15:22:13,014:INFO:Importing untrained model
2023-04-25 15:22:13,015:INFO:Decision Tree Classifier Imported successfully
2023-04-25 15:22:13,016:INFO:Starting cross validation
2023-04-25 15:22:13,020:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:22:13,023:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-04-25 15:22:14,930:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:14,937:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:14,956:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:14,965:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:14,966:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:14,992:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:15,030:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:15,049:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:15,050:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:15,050:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:15,051:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:15,052:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:15,066:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:15,069:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:15,070:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:15,071:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:15,072:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:15,074:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:15,074:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:15,087:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:15,089:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:15,091:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:15,092:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:15,093:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:15,094:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:15,095:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:15,097:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:15,099:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:15,099:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:15,102:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

lt))

2023-04-25 15:22:15,098:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:15,104:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:15,106:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:15,106:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:15,106:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:15,109:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:15,111:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:15,111:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:15,113:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:15,115:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:15,133:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:15,135:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:15,138:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:15,138:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:15,140:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:15,142:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:15,145:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:15,181:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:15,183:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:15,185:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:15,187:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:15,188:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:15,189:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:15,191:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:16,573:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:16,575:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:16,577:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:16,580:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:16,581:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:16,582:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:16,583:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:16,662:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:16,663:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:16,665:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:16,667:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:16,668:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:16,674:INFO:Calculating mean and std
2023-04-25 15:22:16,675:INFO:Creating metrics dataframe
2023-04-25 15:22:16,780:INFO:Uploading results into container
2023-04-25 15:22:16,782:INFO:Uploading model into container now
2023-04-25 15:22:16,782:INFO:_master_model_container: 4
2023-04-25 15:22:16,783:INFO:_display_container: 2
2023-04-25 15:22:16,784:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=747, splitter='best')
2023-04-25 15:22:16,784:INFO:create_model() successfully completed......................................
2023-04-25 15:22:16,988:INFO:SubProcess create_model() end ==================================
2023-04-25 15:22:16,988:INFO:Creating metrics dataframe
2023-04-25 15:22:16,998:INFO:Initializing SVM - Linear Kernel
2023-04-25 15:22:16,998:INFO:Total runtime is 0.36741758187611895 minutes
2023-04-25 15:22:16,998:INFO:SubProcess create_model() called ==================================
2023-04-25 15:22:16,999:INFO:Initializing create_model()
2023-04-25 15:22:16,999:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CF2F61640>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2DD1940>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:22:16,999:INFO:Checking exceptions
2023-04-25 15:22:16,999:INFO:Importing libraries
2023-04-25 15:22:16,999:INFO:Copying training dataset
2023-04-25 15:22:17,009:INFO:Defining folds
2023-04-25 15:22:17,009:INFO:Declaring metric variables
2023-04-25 15:22:17,009:INFO:Importing untrained model
2023-04-25 15:22:17,010:INFO:SVM - Linear Kernel Imported successfully
2023-04-25 15:22:17,011:INFO:Starting cross validation
2023-04-25 15:22:17,014:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:22:17,018:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-04-25 15:22:18,897:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:18,899:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:18,899:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:18,910:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 15:22:18,910:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 15:22:18,911:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 15:22:18,912:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:18,912:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:18,913:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:18,915:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:18,915:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:18,915:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:18,917:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:18,917:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:18,917:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:18,919:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:18,919:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:18,920:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:18,921:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:18,921:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:18,922:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:18,924:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:18,924:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:18,926:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 15:22:18,928:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:18,930:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:18,931:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:18,933:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:18,936:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:18,938:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:19,025:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:19,034:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 15:22:19,036:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:19,038:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:19,039:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:19,041:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:19,042:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:19,043:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:19,065:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:19,073:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 15:22:19,074:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:19,077:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:19,079:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:19,081:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:19,083:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:19,085:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:19,253:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:19,261:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 15:22:19,263:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:19,266:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:19,268:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:19,270:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:19,272:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:19,274:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:19,371:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:19,382:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 15:22:19,384:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:19,386:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:19,388:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:19,390:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:19,392:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:19,395:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:20,375:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 15:22:20,376:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:20,377:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:20,378:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:20,379:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:20,419:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 15:22:20,421:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:20,423:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:20,424:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:20,425:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:20,426:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:20,428:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:20,451:INFO:Calculating mean and std
2023-04-25 15:22:20,453:INFO:Creating metrics dataframe
2023-04-25 15:22:20,568:INFO:Uploading results into container
2023-04-25 15:22:20,570:INFO:Uploading model into container now
2023-04-25 15:22:20,570:INFO:_master_model_container: 5
2023-04-25 15:22:20,571:INFO:_display_container: 2
2023-04-25 15:22:20,571:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=747, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-25 15:22:20,572:INFO:create_model() successfully completed......................................
2023-04-25 15:22:20,771:INFO:SubProcess create_model() end ==================================
2023-04-25 15:22:20,771:INFO:Creating metrics dataframe
2023-04-25 15:22:20,780:INFO:Initializing Ridge Classifier
2023-04-25 15:22:20,780:INFO:Total runtime is 0.43044526576995845 minutes
2023-04-25 15:22:20,780:INFO:SubProcess create_model() called ==================================
2023-04-25 15:22:20,782:INFO:Initializing create_model()
2023-04-25 15:22:20,782:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CF2F61640>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2DD1940>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:22:20,782:INFO:Checking exceptions
2023-04-25 15:22:20,782:INFO:Importing libraries
2023-04-25 15:22:20,782:INFO:Copying training dataset
2023-04-25 15:22:20,791:INFO:Defining folds
2023-04-25 15:22:20,791:INFO:Declaring metric variables
2023-04-25 15:22:20,791:INFO:Importing untrained model
2023-04-25 15:22:20,792:INFO:Ridge Classifier Imported successfully
2023-04-25 15:22:20,792:INFO:Starting cross validation
2023-04-25 15:22:20,795:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:22:20,799:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-04-25 15:22:22,645:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:22,648:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 15:22:22,649:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:22,649:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:22,650:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:22,651:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:22,653:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:22,655:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:22,667:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:22,673:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 15:22:22,675:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:22,677:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:22,678:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:22,681:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:22,683:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:22,685:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:22,691:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:22,695:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:22,698:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:22,700:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:22,703:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 15:22:22,703:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 15:22:22,704:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:22,705:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:22,706:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:22,706:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 15:22:22,707:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 15:22:22,708:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:22,708:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:22,708:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:22,709:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:22,710:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:22,710:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:22,711:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:22,712:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:22,712:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:22,713:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:22,713:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:22,714:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:22,715:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:22,715:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:22,716:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:22,717:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:22,718:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:22,718:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:22,721:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:22,722:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:22,724:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 15:22:22,725:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:22,726:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:22,729:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:22,730:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:22,731:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:22,735:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:22,738:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:22,738:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 15:22:22,739:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:22,740:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:22,740:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:22,742:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:22,745:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:22,747:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:22,750:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:24,155:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 15:22:24,156:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:24,158:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:24,159:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:24,161:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:24,162:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:24,163:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:24,168:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 15:22:24,170:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:24,172:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:24,175:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:24,177:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:24,253:INFO:Calculating mean and std
2023-04-25 15:22:24,255:INFO:Creating metrics dataframe
2023-04-25 15:22:24,373:INFO:Uploading results into container
2023-04-25 15:22:24,374:INFO:Uploading model into container now
2023-04-25 15:22:24,375:INFO:_master_model_container: 6
2023-04-25 15:22:24,375:INFO:_display_container: 2
2023-04-25 15:22:24,376:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=747, solver='auto', tol=0.001)
2023-04-25 15:22:24,376:INFO:create_model() successfully completed......................................
2023-04-25 15:22:24,592:INFO:SubProcess create_model() end ==================================
2023-04-25 15:22:24,592:INFO:Creating metrics dataframe
2023-04-25 15:22:24,603:INFO:Initializing Random Forest Classifier
2023-04-25 15:22:24,603:INFO:Total runtime is 0.4941616415977478 minutes
2023-04-25 15:22:24,603:INFO:SubProcess create_model() called ==================================
2023-04-25 15:22:24,604:INFO:Initializing create_model()
2023-04-25 15:22:24,604:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CF2F61640>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2DD1940>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:22:24,604:INFO:Checking exceptions
2023-04-25 15:22:24,604:INFO:Importing libraries
2023-04-25 15:22:24,604:INFO:Copying training dataset
2023-04-25 15:22:24,613:INFO:Defining folds
2023-04-25 15:22:24,613:INFO:Declaring metric variables
2023-04-25 15:22:24,613:INFO:Importing untrained model
2023-04-25 15:22:24,614:INFO:Random Forest Classifier Imported successfully
2023-04-25 15:22:24,615:INFO:Starting cross validation
2023-04-25 15:22:24,619:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:22:24,622:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-04-25 15:22:27,824:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:27,880:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:27,895:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:27,915:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:27,922:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:27,941:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:27,965:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:28,175:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:28,334:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:28,336:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:28,338:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:28,339:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:28,341:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:28,342:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:28,342:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:28,343:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:28,343:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:28,344:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:28,346:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:28,346:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:28,346:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:28,348:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:28,348:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:28,348:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:28,350:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:28,351:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:28,351:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:28,353:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:28,353:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:28,353:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:28,355:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:28,356:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:28,357:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:28,358:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:28,360:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:28,360:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:28,366:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:28,366:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:28,367:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:28,368:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:28,370:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:28,372:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:28,374:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:28,374:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:28,376:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:28,376:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:28,379:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:28,382:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:28,386:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:28,387:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:28,392:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:28,394:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:28,396:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:28,399:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:28,401:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:28,403:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:28,404:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:28,626:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:28,627:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:28,627:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:28,628:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:28,630:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:28,632:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:28,633:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:30,759:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:30,815:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:31,026:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:31,027:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:31,030:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:31,032:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:31,034:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:31,095:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:31,097:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:31,099:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:31,101:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:31,104:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:31,106:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:31,108:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:31,135:INFO:Calculating mean and std
2023-04-25 15:22:31,137:INFO:Creating metrics dataframe
2023-04-25 15:22:31,271:INFO:Uploading results into container
2023-04-25 15:22:31,272:INFO:Uploading model into container now
2023-04-25 15:22:31,273:INFO:_master_model_container: 7
2023-04-25 15:22:31,273:INFO:_display_container: 2
2023-04-25 15:22:31,285:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=747, verbose=0, warm_start=False)
2023-04-25 15:22:31,286:INFO:create_model() successfully completed......................................
2023-04-25 15:22:31,503:INFO:SubProcess create_model() end ==================================
2023-04-25 15:22:31,503:INFO:Creating metrics dataframe
2023-04-25 15:22:31,513:INFO:Initializing Quadratic Discriminant Analysis
2023-04-25 15:22:31,513:INFO:Total runtime is 0.6093265533447265 minutes
2023-04-25 15:22:31,514:INFO:SubProcess create_model() called ==================================
2023-04-25 15:22:31,514:INFO:Initializing create_model()
2023-04-25 15:22:31,514:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CF2F61640>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2DD1940>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:22:31,515:INFO:Checking exceptions
2023-04-25 15:22:31,515:INFO:Importing libraries
2023-04-25 15:22:31,515:INFO:Copying training dataset
2023-04-25 15:22:31,524:INFO:Defining folds
2023-04-25 15:22:31,524:INFO:Declaring metric variables
2023-04-25 15:22:31,525:INFO:Importing untrained model
2023-04-25 15:22:31,525:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-25 15:22:31,526:INFO:Starting cross validation
2023-04-25 15:22:31,530:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:22:31,533:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-04-25 15:22:32,400:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 15:22:32,400:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 15:22:32,400:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 15:22:32,400:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 15:22:32,427:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 15:22:32,459:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 15:22:32,463:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 15:22:32,523:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 15:22:33,136:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 15:22:33,212:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 15:22:33,833:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:33,834:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:33,837:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:33,838:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:33,839:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:33,848:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:372: FitFailedWarning: 
9 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\91888\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py", line 869, in fit
    raise ValueError(
ValueError: y has only 1 sample in class 1, covariance is ill defined.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-04-25 15:22:33,849:INFO:Calculating mean and std
2023-04-25 15:22:33,851:INFO:Creating metrics dataframe
2023-04-25 15:22:34,006:INFO:Uploading results into container
2023-04-25 15:22:34,007:INFO:Uploading model into container now
2023-04-25 15:22:34,008:INFO:_master_model_container: 8
2023-04-25 15:22:34,008:INFO:_display_container: 2
2023-04-25 15:22:34,009:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-25 15:22:34,009:INFO:create_model() successfully completed......................................
2023-04-25 15:22:34,222:WARNING:create_model() for QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 15:22:34,235:WARNING:Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

2023-04-25 15:22:34,236:INFO:Initializing create_model()
2023-04-25 15:22:34,236:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CF2F61640>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2DD1940>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:22:34,236:INFO:Checking exceptions
2023-04-25 15:22:34,237:INFO:Importing libraries
2023-04-25 15:22:34,237:INFO:Copying training dataset
2023-04-25 15:22:34,248:INFO:Defining folds
2023-04-25 15:22:34,248:INFO:Declaring metric variables
2023-04-25 15:22:34,248:INFO:Importing untrained model
2023-04-25 15:22:34,248:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-25 15:22:34,249:INFO:Starting cross validation
2023-04-25 15:22:34,251:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:22:34,253:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-04-25 15:22:35,021:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 15:22:35,025:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 15:22:35,090:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 15:22:35,098:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 15:22:35,113:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 15:22:35,126:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 15:22:35,176:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 15:22:35,180:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 15:22:35,693:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 15:22:35,819:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 15:22:35,832:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:35,833:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:35,837:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:35,838:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:35,839:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:35,960:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:372: FitFailedWarning: 
9 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\91888\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py", line 869, in fit
    raise ValueError(
ValueError: y has only 1 sample in class 1, covariance is ill defined.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-04-25 15:22:35,961:INFO:Calculating mean and std
2023-04-25 15:22:35,963:INFO:Creating metrics dataframe
2023-04-25 15:22:36,096:INFO:Uploading results into container
2023-04-25 15:22:36,097:INFO:Uploading model into container now
2023-04-25 15:22:36,098:INFO:_master_model_container: 9
2023-04-25 15:22:36,098:INFO:_display_container: 2
2023-04-25 15:22:36,098:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-25 15:22:36,098:INFO:create_model() successfully completed......................................
2023-04-25 15:22:36,303:ERROR:create_model() for QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) raised an exception or returned all 0.0:
2023-04-25 15:22:36,304:ERROR:Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 812, in compare_models
    assert (
AssertionError

2023-04-25 15:22:36,304:INFO:Initializing Ada Boost Classifier
2023-04-25 15:22:36,304:INFO:Total runtime is 0.689175534248352 minutes
2023-04-25 15:22:36,305:INFO:SubProcess create_model() called ==================================
2023-04-25 15:22:36,305:INFO:Initializing create_model()
2023-04-25 15:22:36,306:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CF2F61640>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2DD1940>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:22:36,306:INFO:Checking exceptions
2023-04-25 15:22:36,306:INFO:Importing libraries
2023-04-25 15:22:36,306:INFO:Copying training dataset
2023-04-25 15:22:36,316:INFO:Defining folds
2023-04-25 15:22:36,317:INFO:Declaring metric variables
2023-04-25 15:22:36,317:INFO:Importing untrained model
2023-04-25 15:22:36,318:INFO:Ada Boost Classifier Imported successfully
2023-04-25 15:22:36,318:INFO:Starting cross validation
2023-04-25 15:22:36,322:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:22:36,325:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-04-25 15:22:38,886:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:38,908:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:38,908:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:38,908:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:38,909:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:38,912:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:38,921:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:39,033:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:39,145:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:39,146:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:39,147:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:39,148:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:39,149:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:39,149:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:39,150:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:39,164:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:39,166:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:39,168:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:39,170:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:39,173:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:39,175:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:39,177:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:39,182:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:39,184:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:39,184:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:39,186:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:39,187:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:39,187:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:39,188:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:39,189:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:39,190:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:39,191:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:39,191:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:39,192:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:39,193:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:39,194:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:39,194:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:39,195:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:39,195:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:39,195:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:39,196:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:39,198:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:39,200:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:39,201:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:39,202:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:39,203:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:39,205:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:39,205:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:39,207:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:39,209:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:39,230:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:39,232:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:39,236:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:39,238:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:39,240:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:39,242:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:39,248:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:39,299:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:39,301:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:39,303:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:39,305:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:39,306:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:39,309:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:39,311:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:40,770:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:40,771:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:40,774:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:40,775:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:40,776:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:41,280:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:41,281:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:41,282:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:41,284:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:41,285:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:41,286:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:41,288:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:41,293:INFO:Calculating mean and std
2023-04-25 15:22:41,295:INFO:Creating metrics dataframe
2023-04-25 15:22:41,475:INFO:Uploading results into container
2023-04-25 15:22:41,476:INFO:Uploading model into container now
2023-04-25 15:22:41,478:INFO:_master_model_container: 10
2023-04-25 15:22:41,478:INFO:_display_container: 2
2023-04-25 15:22:41,478:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=747)
2023-04-25 15:22:41,478:INFO:create_model() successfully completed......................................
2023-04-25 15:22:41,692:INFO:SubProcess create_model() end ==================================
2023-04-25 15:22:41,693:INFO:Creating metrics dataframe
2023-04-25 15:22:41,703:INFO:Initializing Gradient Boosting Classifier
2023-04-25 15:22:41,703:INFO:Total runtime is 0.7791600028673807 minutes
2023-04-25 15:22:41,703:INFO:SubProcess create_model() called ==================================
2023-04-25 15:22:41,704:INFO:Initializing create_model()
2023-04-25 15:22:41,704:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CF2F61640>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2DD1940>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:22:41,705:INFO:Checking exceptions
2023-04-25 15:22:41,705:INFO:Importing libraries
2023-04-25 15:22:41,705:INFO:Copying training dataset
2023-04-25 15:22:41,714:INFO:Defining folds
2023-04-25 15:22:41,714:INFO:Declaring metric variables
2023-04-25 15:22:41,715:INFO:Importing untrained model
2023-04-25 15:22:41,717:INFO:Gradient Boosting Classifier Imported successfully
2023-04-25 15:22:41,717:INFO:Starting cross validation
2023-04-25 15:22:41,721:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:22:41,724:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-04-25 15:22:43,924:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-25 15:22:44,028:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-25 15:22:44,048:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-25 15:22:44,049:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-25 15:22:44,049:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-25 15:22:44,120:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-25 15:22:44,405:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-25 15:22:44,575:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-25 15:22:45,861:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:45,946:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:45,962:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:46,005:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:46,044:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:46,056:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:46,354:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:46,498:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:46,500:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:46,503:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:46,504:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:46,506:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:46,508:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:46,510:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:46,535:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:46,537:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:46,539:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:46,541:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:46,544:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:46,546:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:46,548:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:46,580:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:46,596:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:46,598:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:46,600:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:46,602:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:46,604:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:46,607:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:46,609:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:46,661:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:46,663:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:46,665:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:46,667:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:46,670:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:46,671:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:46,672:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:46,695:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:46,697:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:46,699:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:46,701:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:46,704:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:46,704:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:46,704:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:46,706:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:46,706:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:46,708:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:46,712:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:46,715:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:46,717:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:46,720:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:46,889:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:46,891:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:46,894:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:46,896:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:46,899:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:46,901:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:46,903:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:47,135:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:47,137:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:47,139:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:47,141:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:47,145:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:48,675:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:48,860:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:48,861:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:48,862:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:48,863:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:48,864:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:49,659:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:49,974:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:49,975:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:49,977:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:49,978:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:49,980:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:49,981:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:49,982:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:49,988:INFO:Calculating mean and std
2023-04-25 15:22:49,989:INFO:Creating metrics dataframe
2023-04-25 15:22:50,195:INFO:Uploading results into container
2023-04-25 15:22:50,196:INFO:Uploading model into container now
2023-04-25 15:22:50,197:INFO:_master_model_container: 11
2023-04-25 15:22:50,197:INFO:_display_container: 2
2023-04-25 15:22:50,199:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=747, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-25 15:22:50,199:INFO:create_model() successfully completed......................................
2023-04-25 15:22:50,412:INFO:SubProcess create_model() end ==================================
2023-04-25 15:22:50,412:INFO:Creating metrics dataframe
2023-04-25 15:22:50,422:INFO:Initializing Linear Discriminant Analysis
2023-04-25 15:22:50,422:INFO:Total runtime is 0.9244722922643025 minutes
2023-04-25 15:22:50,423:INFO:SubProcess create_model() called ==================================
2023-04-25 15:22:50,423:INFO:Initializing create_model()
2023-04-25 15:22:50,423:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CF2F61640>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2DD1940>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:22:50,423:INFO:Checking exceptions
2023-04-25 15:22:50,423:INFO:Importing libraries
2023-04-25 15:22:50,424:INFO:Copying training dataset
2023-04-25 15:22:50,437:INFO:Defining folds
2023-04-25 15:22:50,437:INFO:Declaring metric variables
2023-04-25 15:22:50,437:INFO:Importing untrained model
2023-04-25 15:22:50,438:INFO:Linear Discriminant Analysis Imported successfully
2023-04-25 15:22:50,439:INFO:Starting cross validation
2023-04-25 15:22:50,443:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:22:50,446:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-04-25 15:22:52,284:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:52,289:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:52,299:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:52,322:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:52,343:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:52,348:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:52,352:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:52,411:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:52,415:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:52,416:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:52,418:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:52,418:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:52,420:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:52,420:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:52,421:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:52,422:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:52,423:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:52,425:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:52,426:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:52,427:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:52,428:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:52,429:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:52,457:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:52,457:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:52,458:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:52,458:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:52,459:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:52,459:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:52,460:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:52,461:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:52,463:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:52,466:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:52,466:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:52,468:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:52,471:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:52,474:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:52,477:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:52,479:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:52,480:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:52,481:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:52,482:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:52,484:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:52,487:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:52,494:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:52,496:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:52,499:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:52,500:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:52,502:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:52,504:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:52,505:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:52,506:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:52,508:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:52,511:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:52,555:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:52,557:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:52,560:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:52,562:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:52,564:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:52,567:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:52,569:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:54,080:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:54,081:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:54,083:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:54,084:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:54,085:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:54,107:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:54,109:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:54,112:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:54,112:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:54,114:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:54,226:INFO:Calculating mean and std
2023-04-25 15:22:54,228:INFO:Creating metrics dataframe
2023-04-25 15:22:54,410:INFO:Uploading results into container
2023-04-25 15:22:54,411:INFO:Uploading model into container now
2023-04-25 15:22:54,412:INFO:_master_model_container: 12
2023-04-25 15:22:54,412:INFO:_display_container: 2
2023-04-25 15:22:54,413:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-25 15:22:54,413:INFO:create_model() successfully completed......................................
2023-04-25 15:22:54,623:INFO:SubProcess create_model() end ==================================
2023-04-25 15:22:54,624:INFO:Creating metrics dataframe
2023-04-25 15:22:54,643:INFO:Initializing Extra Trees Classifier
2023-04-25 15:22:54,643:INFO:Total runtime is 0.9948319554328917 minutes
2023-04-25 15:22:54,644:INFO:SubProcess create_model() called ==================================
2023-04-25 15:22:54,644:INFO:Initializing create_model()
2023-04-25 15:22:54,645:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CF2F61640>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2DD1940>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:22:54,645:INFO:Checking exceptions
2023-04-25 15:22:54,645:INFO:Importing libraries
2023-04-25 15:22:54,645:INFO:Copying training dataset
2023-04-25 15:22:54,654:INFO:Defining folds
2023-04-25 15:22:54,654:INFO:Declaring metric variables
2023-04-25 15:22:54,655:INFO:Importing untrained model
2023-04-25 15:22:54,655:INFO:Extra Trees Classifier Imported successfully
2023-04-25 15:22:54,655:INFO:Starting cross validation
2023-04-25 15:22:54,659:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:22:54,662:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-04-25 15:22:57,737:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:57,759:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:57,784:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:57,815:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:57,819:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:57,835:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:57,854:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:57,985:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:22:58,217:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:58,217:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:58,219:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:58,219:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:58,221:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:58,222:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:58,223:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:58,223:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:58,226:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:58,226:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:58,228:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:58,228:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:58,230:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:58,231:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:58,236:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:58,237:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:58,237:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:58,239:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:58,239:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:58,240:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:58,240:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:58,241:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:58,242:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:58,242:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:58,244:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:58,244:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:58,246:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:58,247:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:58,321:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:58,322:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:58,325:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:58,326:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:58,327:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:58,330:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:58,330:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:58,331:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:58,333:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:58,334:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:58,336:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:58,337:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:58,338:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:58,338:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:58,340:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:58,340:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:58,342:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:58,345:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:58,345:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:58,347:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:58,349:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:22:58,501:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:22:58,503:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:58,505:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:58,507:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:58,509:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:22:58,512:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:22:58,514:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:23:00,673:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:23:00,738:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:23:00,973:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:23:00,975:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:00,979:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:00,981:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:00,983:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:01,041:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:23:01,043:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:01,046:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:01,049:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:01,051:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:01,053:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:01,054:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:23:01,152:INFO:Calculating mean and std
2023-04-25 15:23:01,154:INFO:Creating metrics dataframe
2023-04-25 15:23:01,365:INFO:Uploading results into container
2023-04-25 15:23:01,366:INFO:Uploading model into container now
2023-04-25 15:23:01,367:INFO:_master_model_container: 13
2023-04-25 15:23:01,367:INFO:_display_container: 2
2023-04-25 15:23:01,368:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=747, verbose=0, warm_start=False)
2023-04-25 15:23:01,368:INFO:create_model() successfully completed......................................
2023-04-25 15:23:01,575:INFO:SubProcess create_model() end ==================================
2023-04-25 15:23:01,576:INFO:Creating metrics dataframe
2023-04-25 15:23:01,585:INFO:Initializing Light Gradient Boosting Machine
2023-04-25 15:23:01,585:INFO:Total runtime is 1.1105224887530007 minutes
2023-04-25 15:23:01,585:INFO:SubProcess create_model() called ==================================
2023-04-25 15:23:01,586:INFO:Initializing create_model()
2023-04-25 15:23:01,586:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CF2F61640>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2DD1940>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:23:01,586:INFO:Checking exceptions
2023-04-25 15:23:01,586:INFO:Importing libraries
2023-04-25 15:23:01,586:INFO:Copying training dataset
2023-04-25 15:23:01,594:INFO:Defining folds
2023-04-25 15:23:01,600:INFO:Declaring metric variables
2023-04-25 15:23:01,600:INFO:Importing untrained model
2023-04-25 15:23:01,600:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 15:23:01,600:INFO:Starting cross validation
2023-04-25 15:23:01,605:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:23:01,609:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-04-25 15:23:05,745:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:23:05,748:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:23:05,761:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:23:05,769:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:23:05,828:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:23:05,865:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:23:05,897:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:23:05,927:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:23:05,929:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:05,932:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:05,934:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:05,935:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:23:05,935:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:05,937:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:05,937:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:05,937:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:23:05,938:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:05,939:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:05,939:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:05,939:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:23:05,941:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:05,941:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:23:05,942:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:05,944:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:05,944:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:23:05,946:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:05,948:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:05,950:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:05,952:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:23:05,984:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:23:05,986:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:05,987:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:05,988:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:05,990:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:05,992:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:05,995:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:23:06,038:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:23:06,039:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:06,040:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:06,041:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:06,041:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:06,043:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:06,046:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:23:06,056:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:23:06,058:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:06,059:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:06,061:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:23:06,062:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:06,063:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:06,064:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:06,065:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:06,067:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:06,067:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:06,069:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:23:06,070:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:06,082:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:06,085:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:23:06,130:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:23:06,132:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:06,134:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:06,136:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:06,139:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:06,141:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:06,144:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:23:07,670:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:23:07,671:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:07,674:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:07,676:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:07,677:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:08,053:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:23:08,054:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:08,055:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:08,056:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:08,058:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:08,059:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:08,060:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:23:08,066:INFO:Calculating mean and std
2023-04-25 15:23:08,068:INFO:Creating metrics dataframe
2023-04-25 15:23:08,320:INFO:Uploading results into container
2023-04-25 15:23:08,321:INFO:Uploading model into container now
2023-04-25 15:23:08,322:INFO:_master_model_container: 14
2023-04-25 15:23:08,322:INFO:_display_container: 2
2023-04-25 15:23:08,323:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=747, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-25 15:23:08,323:INFO:create_model() successfully completed......................................
2023-04-25 15:23:08,523:INFO:SubProcess create_model() end ==================================
2023-04-25 15:23:08,524:INFO:Creating metrics dataframe
2023-04-25 15:23:08,535:INFO:Initializing Dummy Classifier
2023-04-25 15:23:08,536:INFO:Total runtime is 1.2263719479242958 minutes
2023-04-25 15:23:08,536:INFO:SubProcess create_model() called ==================================
2023-04-25 15:23:08,537:INFO:Initializing create_model()
2023-04-25 15:23:08,537:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CF2F61640>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2DD1940>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:23:08,537:INFO:Checking exceptions
2023-04-25 15:23:08,537:INFO:Importing libraries
2023-04-25 15:23:08,537:INFO:Copying training dataset
2023-04-25 15:23:08,547:INFO:Defining folds
2023-04-25 15:23:08,548:INFO:Declaring metric variables
2023-04-25 15:23:08,548:INFO:Importing untrained model
2023-04-25 15:23:08,549:INFO:Dummy Classifier Imported successfully
2023-04-25 15:23:08,549:INFO:Starting cross validation
2023-04-25 15:23:08,553:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:23:08,555:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
  warnings.warn(

2023-04-25 15:23:10,364:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:23:10,373:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:23:10,374:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:23:10,394:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:23:10,405:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:23:10,431:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:23:10,454:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:23:10,489:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:23:10,491:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:10,492:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:23:10,493:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:10,494:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:10,495:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:10,496:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:10,497:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:10,498:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:10,499:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:10,501:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:10,503:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:10,503:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:23:10,504:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:23:10,505:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:23:10,507:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:10,509:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

ns that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:23:10,511:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:10,512:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:10,514:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:10,514:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:10,516:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:10,516:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:10,518:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:10,519:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:23:10,520:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:10,522:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:23:10,523:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:23:10,524:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:10,526:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:10,528:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:10,531:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:10,533:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:10,535:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:23:10,544:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:23:10,546:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:10,547:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:10,549:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:10,551:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:10,552:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:10,553:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:23:10,557:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 15:23:10,595:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:23:10,597:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:10,599:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:10,601:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:10,604:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:10,605:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:10,608:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:23:10,694:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:23:10,696:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:10,699:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:10,701:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:10,703:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:10,705:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:10,707:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:23:12,129:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:23:12,130:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:12,134:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:12,136:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:12,138:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:12,139:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:12,141:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 15:23:12,201:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 15:23:12,202:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:12,204:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:12,206:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 15:23:12,208:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 15:23:12,305:INFO:Calculating mean and std
2023-04-25 15:23:12,307:INFO:Creating metrics dataframe
2023-04-25 15:23:12,535:INFO:Uploading results into container
2023-04-25 15:23:12,537:INFO:Uploading model into container now
2023-04-25 15:23:12,538:INFO:_master_model_container: 15
2023-04-25 15:23:12,538:INFO:_display_container: 2
2023-04-25 15:23:12,538:INFO:DummyClassifier(constant=None, random_state=747, strategy='prior')
2023-04-25 15:23:12,538:INFO:create_model() successfully completed......................................
2023-04-25 15:23:12,750:INFO:SubProcess create_model() end ==================================
2023-04-25 15:23:12,750:INFO:Creating metrics dataframe
2023-04-25 15:23:12,761:INFO:Initializing create_model()
2023-04-25 15:23:12,761:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CF2F61640>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=747, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:23:12,761:INFO:Checking exceptions
2023-04-25 15:23:12,764:INFO:Importing libraries
2023-04-25 15:23:12,764:INFO:Copying training dataset
2023-04-25 15:23:12,773:INFO:Defining folds
2023-04-25 15:23:12,774:INFO:Declaring metric variables
2023-04-25 15:23:12,774:INFO:Importing untrained model
2023-04-25 15:23:12,775:INFO:Declaring custom model
2023-04-25 15:23:12,776:INFO:Random Forest Classifier Imported successfully
2023-04-25 15:23:12,780:INFO:Cross validation set to False
2023-04-25 15:23:12,781:INFO:Fitting Model
2023-04-25 15:23:13,927:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=747, verbose=0, warm_start=False)
2023-04-25 15:23:13,927:INFO:create_model() successfully completed......................................
2023-04-25 15:23:14,158:INFO:_master_model_container: 15
2023-04-25 15:23:14,158:INFO:_display_container: 2
2023-04-25 15:23:14,159:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=747, verbose=0, warm_start=False)
2023-04-25 15:23:14,159:INFO:compare_models() successfully completed......................................
2023-04-25 15:23:14,420:INFO:Initializing save_model()
2023-04-25 15:23:14,420:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=747, verbose=0, warm_start=False), model_name=best_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\91888\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'age', 'bp', 'sg', 'al',
                                             'su', 'bgr', 'bu', 'sc', 'sod',
                                             'pot', 'hemo'],
                                    transformer=SimpleImputer(add_ind...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['pcv', 'wc', 'rc'],
                                    transformer=LeaveOneOutEncoder(cols=['pcv',
                                                                         'wc',
                                                                         'rc'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=747,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-04-25 15:23:14,420:INFO:Adding model into prep_pipe
2023-04-25 15:23:14,531:INFO:best_model.pkl saved in current working directory
2023-04-25 15:23:14,781:INFO:Pipeline(memory=FastMemory(location=C:\Users\91888\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'age', 'bp', 'sg', 'al',
                                             'su', 'bgr', 'bu', 'sc', 'sod',
                                             'pot', 'hemo'],
                                    transformer=SimpleImputer(add_ind...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='auto',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=747,
                                        verbose=0, warm_start=False))],
         verbose=False)
2023-04-25 15:23:14,781:INFO:save_model() successfully completed......................................
2023-04-25 15:29:20,549:INFO:PyCaret RegressionExperiment
2023-04-25 15:29:20,549:INFO:Logging name: reg-default-name
2023-04-25 15:29:20,549:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-25 15:29:20,550:INFO:version 3.0.0
2023-04-25 15:29:20,550:INFO:Initializing setup()
2023-04-25 15:29:20,550:INFO:self.USI: 91a2
2023-04-25 15:29:20,550:INFO:self._variable_keys: {'html_param', '_ml_usecase', 'X_test', 'n_jobs_param', 'exp_name_log', 'memory', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param', 'USI', 'seed', 'X_train', 'X', 'gpu_param', 'pipeline', 'target_param', 'data', 'idx', 'fold_groups_param', 'transform_target_param', 'y_train', 'fold_shuffle_param', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_id'}
2023-04-25 15:29:20,550:INFO:Checking environment
2023-04-25 15:29:20,550:INFO:python_version: 3.9.12
2023-04-25 15:29:20,550:INFO:python_build: ('main', 'Apr  4 2022 05:22:27')
2023-04-25 15:29:20,550:INFO:machine: AMD64
2023-04-25 15:29:20,550:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-25 15:29:20,550:INFO:Memory: svmem(total=8362713088, available=2065440768, percent=75.3, used=6297272320, free=2065440768)
2023-04-25 15:29:20,550:INFO:Physical Core: 4
2023-04-25 15:29:20,551:INFO:Logical Core: 8
2023-04-25 15:29:20,551:INFO:Checking libraries
2023-04-25 15:29:20,551:INFO:System:
2023-04-25 15:29:20,551:INFO:    python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]
2023-04-25 15:29:20,551:INFO:executable: C:\Users\91888\anaconda3\python.exe
2023-04-25 15:29:20,551:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-25 15:29:20,551:INFO:PyCaret required dependencies:
2023-04-25 15:29:20,551:INFO:                 pip: 21.2.4
2023-04-25 15:29:20,551:INFO:          setuptools: 61.2.0
2023-04-25 15:29:20,551:INFO:             pycaret: 3.0.0
2023-04-25 15:29:20,551:INFO:             IPython: 8.2.0
2023-04-25 15:29:20,552:INFO:          ipywidgets: 7.6.5
2023-04-25 15:29:20,552:INFO:                tqdm: 4.64.0
2023-04-25 15:29:20,552:INFO:               numpy: 1.21.5
2023-04-25 15:29:20,552:INFO:              pandas: 1.4.2
2023-04-25 15:29:20,552:INFO:              jinja2: 2.11.3
2023-04-25 15:29:20,552:INFO:               scipy: 1.7.3
2023-04-25 15:29:20,552:INFO:              joblib: 1.2.0
2023-04-25 15:29:20,552:INFO:             sklearn: 1.0.2
2023-04-25 15:29:20,552:INFO:                pyod: 1.0.9
2023-04-25 15:29:20,552:INFO:            imblearn: 0.10.1
2023-04-25 15:29:20,552:INFO:   category_encoders: 2.6.0
2023-04-25 15:29:20,552:INFO:            lightgbm: 3.3.5
2023-04-25 15:29:20,553:INFO:               numba: 0.55.1
2023-04-25 15:29:20,553:INFO:            requests: 2.27.1
2023-04-25 15:29:20,553:INFO:          matplotlib: 3.5.1
2023-04-25 15:29:20,553:INFO:          scikitplot: 0.3.7
2023-04-25 15:29:20,553:INFO:         yellowbrick: 1.5
2023-04-25 15:29:20,553:INFO:              plotly: 5.6.0
2023-04-25 15:29:20,553:INFO:             kaleido: 0.2.1
2023-04-25 15:29:20,553:INFO:         statsmodels: 0.13.2
2023-04-25 15:29:20,553:INFO:              sktime: 0.17.1
2023-04-25 15:29:20,553:INFO:               tbats: 1.1.3
2023-04-25 15:29:20,553:INFO:            pmdarima: 2.0.3
2023-04-25 15:29:20,553:INFO:              psutil: 5.9.5
2023-04-25 15:29:20,553:INFO:PyCaret optional dependencies:
2023-04-25 15:29:20,554:INFO:                shap: Not installed
2023-04-25 15:29:20,554:INFO:           interpret: Not installed
2023-04-25 15:29:20,554:INFO:                umap: Not installed
2023-04-25 15:29:20,554:INFO:    pandas_profiling: 4.1.2
2023-04-25 15:29:20,554:INFO:  explainerdashboard: Not installed
2023-04-25 15:29:20,554:INFO:             autoviz: Not installed
2023-04-25 15:29:20,554:INFO:           fairlearn: Not installed
2023-04-25 15:29:20,554:INFO:             xgboost: Not installed
2023-04-25 15:29:20,554:INFO:            catboost: Not installed
2023-04-25 15:29:20,554:INFO:              kmodes: Not installed
2023-04-25 15:29:20,554:INFO:             mlxtend: Not installed
2023-04-25 15:29:20,555:INFO:       statsforecast: Not installed
2023-04-25 15:29:20,555:INFO:        tune_sklearn: Not installed
2023-04-25 15:29:20,555:INFO:                 ray: Not installed
2023-04-25 15:29:20,555:INFO:            hyperopt: Not installed
2023-04-25 15:29:20,555:INFO:              optuna: Not installed
2023-04-25 15:29:20,555:INFO:               skopt: Not installed
2023-04-25 15:29:20,555:INFO:              mlflow: Not installed
2023-04-25 15:29:20,555:INFO:              gradio: Not installed
2023-04-25 15:29:20,555:INFO:             fastapi: Not installed
2023-04-25 15:29:20,555:INFO:             uvicorn: Not installed
2023-04-25 15:29:20,556:INFO:              m2cgen: Not installed
2023-04-25 15:29:20,556:INFO:           evidently: Not installed
2023-04-25 15:29:20,556:INFO:               fugue: Not installed
2023-04-25 15:29:20,556:INFO:           streamlit: 1.21.0
2023-04-25 15:29:20,556:INFO:             prophet: Not installed
2023-04-25 15:29:20,556:INFO:None
2023-04-25 15:29:20,556:INFO:Set up data.
2023-04-25 15:29:20,562:INFO:Set up train/test split.
2023-04-25 15:29:20,567:INFO:Set up index.
2023-04-25 15:29:20,567:INFO:Set up folding strategy.
2023-04-25 15:29:20,567:INFO:Assigning column types.
2023-04-25 15:29:20,574:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-25 15:29:20,582:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 15:29:20,593:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 15:29:20,604:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 15:29:20,747:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:29:20,869:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:29:20,871:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:20,872:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:20,872:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 15:29:20,884:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 15:29:20,897:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 15:29:21,054:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:29:21,173:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:29:21,174:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:21,175:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:21,175:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-25 15:29:21,188:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 15:29:21,201:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 15:29:21,348:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:29:21,484:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:29:21,485:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:21,486:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:21,501:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 15:29:21,514:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 15:29:21,674:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:29:21,801:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:29:21,802:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:21,802:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:21,803:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-25 15:29:21,831:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 15:29:22,000:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:29:22,129:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:29:22,131:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:22,132:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:22,156:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 15:29:22,327:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:29:22,450:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:29:22,451:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:22,451:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:22,452:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-25 15:29:22,647:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:29:22,773:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:29:22,774:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:22,775:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:22,951:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:29:23,074:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:29:23,076:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:23,077:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:23,077:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-25 15:29:23,264:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:29:23,382:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:23,384:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:23,569:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:29:23,695:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:23,696:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:23,696:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-25 15:29:24,016:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:24,017:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:24,325:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:24,326:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:24,328:INFO:Preparing preprocessing pipeline...
2023-04-25 15:29:24,329:INFO:Set up simple imputation.
2023-04-25 15:29:24,355:INFO:Finished creating preprocessing pipeline.
2023-04-25 15:29:24,363:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\91888\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['TV', 'Radio', 'Newspaper'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-04-25 15:29:24,364:INFO:Creating final display dataframe.
2023-04-25 15:29:24,499:INFO:Setup _display_container:                     Description             Value
0                    Session id              6657
1                        Target             Sales
2                   Target type        Regression
3           Original data shape          (200, 4)
4        Transformed data shape          (200, 4)
5   Transformed train set shape          (140, 4)
6    Transformed test set shape           (60, 4)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              91a2
2023-04-25 15:29:24,810:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:24,811:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:25,102:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:25,103:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:29:25,104:INFO:setup() successfully completed in 4.68s...............
2023-04-25 15:29:25,110:INFO:Initializing compare_models()
2023-04-25 15:29:25,110:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF727E970>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000017CF727E970>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-25 15:29:25,110:INFO:Checking exceptions
2023-04-25 15:29:25,115:INFO:Preparing display monitor
2023-04-25 15:29:25,123:INFO:Initializing Linear Regression
2023-04-25 15:29:25,123:INFO:Total runtime is 0.0 minutes
2023-04-25 15:29:25,124:INFO:SubProcess create_model() called ==================================
2023-04-25 15:29:25,124:INFO:Initializing create_model()
2023-04-25 15:29:25,124:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF727E970>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFD6A62B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:29:25,125:INFO:Checking exceptions
2023-04-25 15:29:25,125:INFO:Importing libraries
2023-04-25 15:29:25,125:INFO:Copying training dataset
2023-04-25 15:29:25,130:INFO:Defining folds
2023-04-25 15:29:25,131:INFO:Declaring metric variables
2023-04-25 15:29:25,131:INFO:Importing untrained model
2023-04-25 15:29:25,132:INFO:Linear Regression Imported successfully
2023-04-25 15:29:25,133:INFO:Starting cross validation
2023-04-25 15:29:25,135:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:29:32,128:INFO:Calculating mean and std
2023-04-25 15:29:32,129:INFO:Creating metrics dataframe
2023-04-25 15:29:32,358:INFO:Uploading results into container
2023-04-25 15:29:32,359:INFO:Uploading model into container now
2023-04-25 15:29:32,361:INFO:_master_model_container: 1
2023-04-25 15:29:32,361:INFO:_display_container: 2
2023-04-25 15:29:32,362:INFO:LinearRegression(n_jobs=-1)
2023-04-25 15:29:32,362:INFO:create_model() successfully completed......................................
2023-04-25 15:29:32,612:INFO:SubProcess create_model() end ==================================
2023-04-25 15:29:32,612:INFO:Creating metrics dataframe
2023-04-25 15:29:32,622:INFO:Initializing Lasso Regression
2023-04-25 15:29:32,623:INFO:Total runtime is 0.125006107489268 minutes
2023-04-25 15:29:32,623:INFO:SubProcess create_model() called ==================================
2023-04-25 15:29:32,624:INFO:Initializing create_model()
2023-04-25 15:29:32,624:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF727E970>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFD6A62B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:29:32,624:INFO:Checking exceptions
2023-04-25 15:29:32,625:INFO:Importing libraries
2023-04-25 15:29:32,625:INFO:Copying training dataset
2023-04-25 15:29:32,633:INFO:Defining folds
2023-04-25 15:29:32,634:INFO:Declaring metric variables
2023-04-25 15:29:32,634:INFO:Importing untrained model
2023-04-25 15:29:32,635:INFO:Lasso Regression Imported successfully
2023-04-25 15:29:32,635:INFO:Starting cross validation
2023-04-25 15:29:32,637:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:29:33,758:INFO:Calculating mean and std
2023-04-25 15:29:33,760:INFO:Creating metrics dataframe
2023-04-25 15:29:33,996:INFO:Uploading results into container
2023-04-25 15:29:33,997:INFO:Uploading model into container now
2023-04-25 15:29:33,998:INFO:_master_model_container: 2
2023-04-25 15:29:33,998:INFO:_display_container: 2
2023-04-25 15:29:33,999:INFO:Lasso(random_state=6657)
2023-04-25 15:29:33,999:INFO:create_model() successfully completed......................................
2023-04-25 15:29:34,216:INFO:SubProcess create_model() end ==================================
2023-04-25 15:29:34,217:INFO:Creating metrics dataframe
2023-04-25 15:29:34,225:INFO:Initializing Ridge Regression
2023-04-25 15:29:34,228:INFO:Total runtime is 0.15176241795221965 minutes
2023-04-25 15:29:34,228:INFO:SubProcess create_model() called ==================================
2023-04-25 15:29:34,229:INFO:Initializing create_model()
2023-04-25 15:29:34,229:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF727E970>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFD6A62B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:29:34,229:INFO:Checking exceptions
2023-04-25 15:29:34,229:INFO:Importing libraries
2023-04-25 15:29:34,229:INFO:Copying training dataset
2023-04-25 15:29:34,235:INFO:Defining folds
2023-04-25 15:29:34,235:INFO:Declaring metric variables
2023-04-25 15:29:34,236:INFO:Importing untrained model
2023-04-25 15:29:34,236:INFO:Ridge Regression Imported successfully
2023-04-25 15:29:34,236:INFO:Starting cross validation
2023-04-25 15:29:34,238:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:29:35,763:INFO:Calculating mean and std
2023-04-25 15:29:35,765:INFO:Creating metrics dataframe
2023-04-25 15:29:36,006:INFO:Uploading results into container
2023-04-25 15:29:36,009:INFO:Uploading model into container now
2023-04-25 15:29:36,010:INFO:_master_model_container: 3
2023-04-25 15:29:36,010:INFO:_display_container: 2
2023-04-25 15:29:36,011:INFO:Ridge(random_state=6657)
2023-04-25 15:29:36,011:INFO:create_model() successfully completed......................................
2023-04-25 15:29:36,220:INFO:SubProcess create_model() end ==================================
2023-04-25 15:29:36,220:INFO:Creating metrics dataframe
2023-04-25 15:29:36,230:INFO:Initializing Elastic Net
2023-04-25 15:29:36,231:INFO:Total runtime is 0.18513060013453164 minutes
2023-04-25 15:29:36,231:INFO:SubProcess create_model() called ==================================
2023-04-25 15:29:36,231:INFO:Initializing create_model()
2023-04-25 15:29:36,231:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF727E970>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFD6A62B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:29:36,231:INFO:Checking exceptions
2023-04-25 15:29:36,231:INFO:Importing libraries
2023-04-25 15:29:36,232:INFO:Copying training dataset
2023-04-25 15:29:36,236:INFO:Defining folds
2023-04-25 15:29:36,236:INFO:Declaring metric variables
2023-04-25 15:29:36,236:INFO:Importing untrained model
2023-04-25 15:29:36,238:INFO:Elastic Net Imported successfully
2023-04-25 15:29:36,238:INFO:Starting cross validation
2023-04-25 15:29:36,240:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:29:37,780:INFO:Calculating mean and std
2023-04-25 15:29:37,781:INFO:Creating metrics dataframe
2023-04-25 15:29:38,020:INFO:Uploading results into container
2023-04-25 15:29:38,021:INFO:Uploading model into container now
2023-04-25 15:29:38,022:INFO:_master_model_container: 4
2023-04-25 15:29:38,022:INFO:_display_container: 2
2023-04-25 15:29:38,023:INFO:ElasticNet(random_state=6657)
2023-04-25 15:29:38,023:INFO:create_model() successfully completed......................................
2023-04-25 15:29:38,230:INFO:SubProcess create_model() end ==================================
2023-04-25 15:29:38,230:INFO:Creating metrics dataframe
2023-04-25 15:29:38,239:INFO:Initializing Least Angle Regression
2023-04-25 15:29:38,239:INFO:Total runtime is 0.21861306031545003 minutes
2023-04-25 15:29:38,239:INFO:SubProcess create_model() called ==================================
2023-04-25 15:29:38,240:INFO:Initializing create_model()
2023-04-25 15:29:38,240:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF727E970>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFD6A62B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:29:38,240:INFO:Checking exceptions
2023-04-25 15:29:38,240:INFO:Importing libraries
2023-04-25 15:29:38,240:INFO:Copying training dataset
2023-04-25 15:29:38,247:INFO:Defining folds
2023-04-25 15:29:38,247:INFO:Declaring metric variables
2023-04-25 15:29:38,247:INFO:Importing untrained model
2023-04-25 15:29:38,248:INFO:Least Angle Regression Imported successfully
2023-04-25 15:29:38,248:INFO:Starting cross validation
2023-04-25 15:29:38,250:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:29:38,343:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:29:38,360:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:29:38,377:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:29:38,404:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:29:38,432:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:29:38,449:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:29:38,486:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:29:38,507:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:29:38,673:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:29:38,733:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:29:39,781:INFO:Calculating mean and std
2023-04-25 15:29:39,782:INFO:Creating metrics dataframe
2023-04-25 15:29:40,016:INFO:Uploading results into container
2023-04-25 15:29:40,018:INFO:Uploading model into container now
2023-04-25 15:29:40,019:INFO:_master_model_container: 5
2023-04-25 15:29:40,019:INFO:_display_container: 2
2023-04-25 15:29:40,020:INFO:Lars(random_state=6657)
2023-04-25 15:29:40,020:INFO:create_model() successfully completed......................................
2023-04-25 15:29:40,236:INFO:SubProcess create_model() end ==================================
2023-04-25 15:29:40,236:INFO:Creating metrics dataframe
2023-04-25 15:29:40,243:INFO:Initializing Lasso Least Angle Regression
2023-04-25 15:29:40,243:INFO:Total runtime is 0.2520063559214274 minutes
2023-04-25 15:29:40,243:INFO:SubProcess create_model() called ==================================
2023-04-25 15:29:40,244:INFO:Initializing create_model()
2023-04-25 15:29:40,244:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF727E970>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFD6A62B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:29:40,244:INFO:Checking exceptions
2023-04-25 15:29:40,244:INFO:Importing libraries
2023-04-25 15:29:40,244:INFO:Copying training dataset
2023-04-25 15:29:40,248:INFO:Defining folds
2023-04-25 15:29:40,248:INFO:Declaring metric variables
2023-04-25 15:29:40,249:INFO:Importing untrained model
2023-04-25 15:29:40,250:INFO:Lasso Least Angle Regression Imported successfully
2023-04-25 15:29:40,251:INFO:Starting cross validation
2023-04-25 15:29:40,252:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:29:40,359:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:29:40,380:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:29:40,398:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:29:40,428:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:29:40,440:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:29:40,469:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:29:40,479:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:29:40,513:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:29:40,720:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:29:40,750:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:29:41,787:INFO:Calculating mean and std
2023-04-25 15:29:41,788:INFO:Creating metrics dataframe
2023-04-25 15:29:42,025:INFO:Uploading results into container
2023-04-25 15:29:42,026:INFO:Uploading model into container now
2023-04-25 15:29:42,027:INFO:_master_model_container: 6
2023-04-25 15:29:42,027:INFO:_display_container: 2
2023-04-25 15:29:42,028:INFO:LassoLars(random_state=6657)
2023-04-25 15:29:42,028:INFO:create_model() successfully completed......................................
2023-04-25 15:29:42,242:INFO:SubProcess create_model() end ==================================
2023-04-25 15:29:42,242:INFO:Creating metrics dataframe
2023-04-25 15:29:42,250:INFO:Initializing Orthogonal Matching Pursuit
2023-04-25 15:29:42,251:INFO:Total runtime is 0.2854672312736511 minutes
2023-04-25 15:29:42,251:INFO:SubProcess create_model() called ==================================
2023-04-25 15:29:42,252:INFO:Initializing create_model()
2023-04-25 15:29:42,252:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF727E970>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFD6A62B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:29:42,252:INFO:Checking exceptions
2023-04-25 15:29:42,252:INFO:Importing libraries
2023-04-25 15:29:42,252:INFO:Copying training dataset
2023-04-25 15:29:42,259:INFO:Defining folds
2023-04-25 15:29:42,259:INFO:Declaring metric variables
2023-04-25 15:29:42,259:INFO:Importing untrained model
2023-04-25 15:29:42,260:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-25 15:29:42,260:INFO:Starting cross validation
2023-04-25 15:29:42,262:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:29:42,355:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:29:42,373:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:29:42,395:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:29:42,413:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:29:42,430:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:29:42,430:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:29:42,464:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:29:42,504:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:29:42,732:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:29:42,750:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:29:43,773:INFO:Calculating mean and std
2023-04-25 15:29:43,775:INFO:Creating metrics dataframe
2023-04-25 15:29:44,007:INFO:Uploading results into container
2023-04-25 15:29:44,009:INFO:Uploading model into container now
2023-04-25 15:29:44,009:INFO:_master_model_container: 7
2023-04-25 15:29:44,010:INFO:_display_container: 2
2023-04-25 15:29:44,010:INFO:OrthogonalMatchingPursuit()
2023-04-25 15:29:44,010:INFO:create_model() successfully completed......................................
2023-04-25 15:29:44,230:INFO:SubProcess create_model() end ==================================
2023-04-25 15:29:44,231:INFO:Creating metrics dataframe
2023-04-25 15:29:44,240:INFO:Initializing Bayesian Ridge
2023-04-25 15:29:44,240:INFO:Total runtime is 0.3186263640721639 minutes
2023-04-25 15:29:44,240:INFO:SubProcess create_model() called ==================================
2023-04-25 15:29:44,240:INFO:Initializing create_model()
2023-04-25 15:29:44,240:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF727E970>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFD6A62B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:29:44,240:INFO:Checking exceptions
2023-04-25 15:29:44,240:INFO:Importing libraries
2023-04-25 15:29:44,240:INFO:Copying training dataset
2023-04-25 15:29:44,243:INFO:Defining folds
2023-04-25 15:29:44,243:INFO:Declaring metric variables
2023-04-25 15:29:44,243:INFO:Importing untrained model
2023-04-25 15:29:44,245:INFO:Bayesian Ridge Imported successfully
2023-04-25 15:29:44,245:INFO:Starting cross validation
2023-04-25 15:29:44,246:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:29:45,751:INFO:Calculating mean and std
2023-04-25 15:29:45,752:INFO:Creating metrics dataframe
2023-04-25 15:29:45,998:INFO:Uploading results into container
2023-04-25 15:29:46,000:INFO:Uploading model into container now
2023-04-25 15:29:46,001:INFO:_master_model_container: 8
2023-04-25 15:29:46,001:INFO:_display_container: 2
2023-04-25 15:29:46,002:INFO:BayesianRidge()
2023-04-25 15:29:46,002:INFO:create_model() successfully completed......................................
2023-04-25 15:29:46,218:INFO:SubProcess create_model() end ==================================
2023-04-25 15:29:46,218:INFO:Creating metrics dataframe
2023-04-25 15:29:46,228:INFO:Initializing Passive Aggressive Regressor
2023-04-25 15:29:46,228:INFO:Total runtime is 0.35174810489018754 minutes
2023-04-25 15:29:46,228:INFO:SubProcess create_model() called ==================================
2023-04-25 15:29:46,229:INFO:Initializing create_model()
2023-04-25 15:29:46,229:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF727E970>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFD6A62B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:29:46,229:INFO:Checking exceptions
2023-04-25 15:29:46,229:INFO:Importing libraries
2023-04-25 15:29:46,229:INFO:Copying training dataset
2023-04-25 15:29:46,235:INFO:Defining folds
2023-04-25 15:29:46,235:INFO:Declaring metric variables
2023-04-25 15:29:46,236:INFO:Importing untrained model
2023-04-25 15:29:46,236:INFO:Passive Aggressive Regressor Imported successfully
2023-04-25 15:29:46,237:INFO:Starting cross validation
2023-04-25 15:29:46,238:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:29:47,706:INFO:Calculating mean and std
2023-04-25 15:29:47,708:INFO:Creating metrics dataframe
2023-04-25 15:29:47,950:INFO:Uploading results into container
2023-04-25 15:29:47,952:INFO:Uploading model into container now
2023-04-25 15:29:47,953:INFO:_master_model_container: 9
2023-04-25 15:29:47,953:INFO:_display_container: 2
2023-04-25 15:29:47,954:INFO:PassiveAggressiveRegressor(random_state=6657)
2023-04-25 15:29:47,954:INFO:create_model() successfully completed......................................
2023-04-25 15:29:48,161:INFO:SubProcess create_model() end ==================================
2023-04-25 15:29:48,161:INFO:Creating metrics dataframe
2023-04-25 15:29:48,171:INFO:Initializing Huber Regressor
2023-04-25 15:29:48,172:INFO:Total runtime is 0.38413929939270014 minutes
2023-04-25 15:29:48,172:INFO:SubProcess create_model() called ==================================
2023-04-25 15:29:48,172:INFO:Initializing create_model()
2023-04-25 15:29:48,172:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF727E970>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFD6A62B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:29:48,173:INFO:Checking exceptions
2023-04-25 15:29:48,173:INFO:Importing libraries
2023-04-25 15:29:48,173:INFO:Copying training dataset
2023-04-25 15:29:48,179:INFO:Defining folds
2023-04-25 15:29:48,179:INFO:Declaring metric variables
2023-04-25 15:29:48,180:INFO:Importing untrained model
2023-04-25 15:29:48,181:INFO:Huber Regressor Imported successfully
2023-04-25 15:29:48,181:INFO:Starting cross validation
2023-04-25 15:29:48,183:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:29:49,736:INFO:Calculating mean and std
2023-04-25 15:29:49,738:INFO:Creating metrics dataframe
2023-04-25 15:29:49,967:INFO:Uploading results into container
2023-04-25 15:29:49,967:INFO:Uploading model into container now
2023-04-25 15:29:49,968:INFO:_master_model_container: 10
2023-04-25 15:29:49,968:INFO:_display_container: 2
2023-04-25 15:29:49,969:INFO:HuberRegressor()
2023-04-25 15:29:49,969:INFO:create_model() successfully completed......................................
2023-04-25 15:29:50,172:INFO:SubProcess create_model() end ==================================
2023-04-25 15:29:50,172:INFO:Creating metrics dataframe
2023-04-25 15:29:50,182:INFO:Initializing K Neighbors Regressor
2023-04-25 15:29:50,183:INFO:Total runtime is 0.4176753441492716 minutes
2023-04-25 15:29:50,183:INFO:SubProcess create_model() called ==================================
2023-04-25 15:29:50,184:INFO:Initializing create_model()
2023-04-25 15:29:50,184:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF727E970>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFD6A62B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:29:50,184:INFO:Checking exceptions
2023-04-25 15:29:50,184:INFO:Importing libraries
2023-04-25 15:29:50,184:INFO:Copying training dataset
2023-04-25 15:29:50,191:INFO:Defining folds
2023-04-25 15:29:50,191:INFO:Declaring metric variables
2023-04-25 15:29:50,191:INFO:Importing untrained model
2023-04-25 15:29:50,192:INFO:K Neighbors Regressor Imported successfully
2023-04-25 15:29:50,193:INFO:Starting cross validation
2023-04-25 15:29:50,194:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:29:51,696:INFO:Calculating mean and std
2023-04-25 15:29:51,697:INFO:Creating metrics dataframe
2023-04-25 15:29:51,918:INFO:Uploading results into container
2023-04-25 15:29:51,919:INFO:Uploading model into container now
2023-04-25 15:29:51,920:INFO:_master_model_container: 11
2023-04-25 15:29:51,920:INFO:_display_container: 2
2023-04-25 15:29:51,921:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-25 15:29:51,921:INFO:create_model() successfully completed......................................
2023-04-25 15:29:52,130:INFO:SubProcess create_model() end ==================================
2023-04-25 15:29:52,130:INFO:Creating metrics dataframe
2023-04-25 15:29:52,140:INFO:Initializing Decision Tree Regressor
2023-04-25 15:29:52,141:INFO:Total runtime is 0.45030676126480096 minutes
2023-04-25 15:29:52,141:INFO:SubProcess create_model() called ==================================
2023-04-25 15:29:52,142:INFO:Initializing create_model()
2023-04-25 15:29:52,142:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF727E970>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFD6A62B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:29:52,142:INFO:Checking exceptions
2023-04-25 15:29:52,142:INFO:Importing libraries
2023-04-25 15:29:52,142:INFO:Copying training dataset
2023-04-25 15:29:52,147:INFO:Defining folds
2023-04-25 15:29:52,148:INFO:Declaring metric variables
2023-04-25 15:29:52,149:INFO:Importing untrained model
2023-04-25 15:29:52,149:INFO:Decision Tree Regressor Imported successfully
2023-04-25 15:29:52,150:INFO:Starting cross validation
2023-04-25 15:29:52,152:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:29:53,672:INFO:Calculating mean and std
2023-04-25 15:29:53,673:INFO:Creating metrics dataframe
2023-04-25 15:29:53,898:INFO:Uploading results into container
2023-04-25 15:29:53,900:INFO:Uploading model into container now
2023-04-25 15:29:53,900:INFO:_master_model_container: 12
2023-04-25 15:29:53,901:INFO:_display_container: 2
2023-04-25 15:29:53,901:INFO:DecisionTreeRegressor(random_state=6657)
2023-04-25 15:29:53,901:INFO:create_model() successfully completed......................................
2023-04-25 15:29:54,112:INFO:SubProcess create_model() end ==================================
2023-04-25 15:29:54,112:INFO:Creating metrics dataframe
2023-04-25 15:29:54,118:INFO:Initializing Random Forest Regressor
2023-04-25 15:29:54,118:INFO:Total runtime is 0.48326189120610547 minutes
2023-04-25 15:29:54,119:INFO:SubProcess create_model() called ==================================
2023-04-25 15:29:54,119:INFO:Initializing create_model()
2023-04-25 15:29:54,119:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF727E970>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFD6A62B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:29:54,119:INFO:Checking exceptions
2023-04-25 15:29:54,119:INFO:Importing libraries
2023-04-25 15:29:54,121:INFO:Copying training dataset
2023-04-25 15:29:54,126:INFO:Defining folds
2023-04-25 15:29:54,126:INFO:Declaring metric variables
2023-04-25 15:29:54,127:INFO:Importing untrained model
2023-04-25 15:29:54,128:INFO:Random Forest Regressor Imported successfully
2023-04-25 15:29:54,128:INFO:Starting cross validation
2023-04-25 15:29:54,129:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:29:56,918:INFO:Calculating mean and std
2023-04-25 15:29:56,920:INFO:Creating metrics dataframe
2023-04-25 15:29:57,155:INFO:Uploading results into container
2023-04-25 15:29:57,156:INFO:Uploading model into container now
2023-04-25 15:29:57,157:INFO:_master_model_container: 13
2023-04-25 15:29:57,158:INFO:_display_container: 2
2023-04-25 15:29:57,158:INFO:RandomForestRegressor(n_jobs=-1, random_state=6657)
2023-04-25 15:29:57,159:INFO:create_model() successfully completed......................................
2023-04-25 15:29:57,361:INFO:SubProcess create_model() end ==================================
2023-04-25 15:29:57,361:INFO:Creating metrics dataframe
2023-04-25 15:29:57,369:INFO:Initializing Extra Trees Regressor
2023-04-25 15:29:57,370:INFO:Total runtime is 0.5374551455179849 minutes
2023-04-25 15:29:57,370:INFO:SubProcess create_model() called ==================================
2023-04-25 15:29:57,371:INFO:Initializing create_model()
2023-04-25 15:29:57,371:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF727E970>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFD6A62B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:29:57,371:INFO:Checking exceptions
2023-04-25 15:29:57,372:INFO:Importing libraries
2023-04-25 15:29:57,372:INFO:Copying training dataset
2023-04-25 15:29:57,379:INFO:Defining folds
2023-04-25 15:29:57,379:INFO:Declaring metric variables
2023-04-25 15:29:57,380:INFO:Importing untrained model
2023-04-25 15:29:57,380:INFO:Extra Trees Regressor Imported successfully
2023-04-25 15:29:57,381:INFO:Starting cross validation
2023-04-25 15:29:57,383:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:30:00,078:INFO:Calculating mean and std
2023-04-25 15:30:00,079:INFO:Creating metrics dataframe
2023-04-25 15:30:00,329:INFO:Uploading results into container
2023-04-25 15:30:00,331:INFO:Uploading model into container now
2023-04-25 15:30:00,331:INFO:_master_model_container: 14
2023-04-25 15:30:00,332:INFO:_display_container: 2
2023-04-25 15:30:00,332:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6657)
2023-04-25 15:30:00,332:INFO:create_model() successfully completed......................................
2023-04-25 15:30:00,541:INFO:SubProcess create_model() end ==================================
2023-04-25 15:30:00,542:INFO:Creating metrics dataframe
2023-04-25 15:30:00,550:INFO:Initializing AdaBoost Regressor
2023-04-25 15:30:00,551:INFO:Total runtime is 0.590464131037394 minutes
2023-04-25 15:30:00,551:INFO:SubProcess create_model() called ==================================
2023-04-25 15:30:00,552:INFO:Initializing create_model()
2023-04-25 15:30:00,552:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF727E970>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFD6A62B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:30:00,552:INFO:Checking exceptions
2023-04-25 15:30:00,552:INFO:Importing libraries
2023-04-25 15:30:00,553:INFO:Copying training dataset
2023-04-25 15:30:00,560:INFO:Defining folds
2023-04-25 15:30:00,560:INFO:Declaring metric variables
2023-04-25 15:30:00,561:INFO:Importing untrained model
2023-04-25 15:30:00,561:INFO:AdaBoost Regressor Imported successfully
2023-04-25 15:30:00,562:INFO:Starting cross validation
2023-04-25 15:30:00,564:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:30:02,816:INFO:Calculating mean and std
2023-04-25 15:30:02,818:INFO:Creating metrics dataframe
2023-04-25 15:30:03,124:INFO:Uploading results into container
2023-04-25 15:30:03,125:INFO:Uploading model into container now
2023-04-25 15:30:03,126:INFO:_master_model_container: 15
2023-04-25 15:30:03,126:INFO:_display_container: 2
2023-04-25 15:30:03,126:INFO:AdaBoostRegressor(random_state=6657)
2023-04-25 15:30:03,127:INFO:create_model() successfully completed......................................
2023-04-25 15:30:03,331:INFO:SubProcess create_model() end ==================================
2023-04-25 15:30:03,331:INFO:Creating metrics dataframe
2023-04-25 15:30:03,339:INFO:Initializing Gradient Boosting Regressor
2023-04-25 15:30:03,339:INFO:Total runtime is 0.6369399706522622 minutes
2023-04-25 15:30:03,340:INFO:SubProcess create_model() called ==================================
2023-04-25 15:30:03,340:INFO:Initializing create_model()
2023-04-25 15:30:03,340:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF727E970>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFD6A62B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:30:03,340:INFO:Checking exceptions
2023-04-25 15:30:03,341:INFO:Importing libraries
2023-04-25 15:30:03,341:INFO:Copying training dataset
2023-04-25 15:30:03,347:INFO:Defining folds
2023-04-25 15:30:03,347:INFO:Declaring metric variables
2023-04-25 15:30:03,347:INFO:Importing untrained model
2023-04-25 15:30:03,348:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 15:30:03,349:INFO:Starting cross validation
2023-04-25 15:30:03,350:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:30:05,241:INFO:Calculating mean and std
2023-04-25 15:30:05,242:INFO:Creating metrics dataframe
2023-04-25 15:30:05,512:INFO:Uploading results into container
2023-04-25 15:30:05,513:INFO:Uploading model into container now
2023-04-25 15:30:05,515:INFO:_master_model_container: 16
2023-04-25 15:30:05,515:INFO:_display_container: 2
2023-04-25 15:30:05,516:INFO:GradientBoostingRegressor(random_state=6657)
2023-04-25 15:30:05,516:INFO:create_model() successfully completed......................................
2023-04-25 15:30:05,724:INFO:SubProcess create_model() end ==================================
2023-04-25 15:30:05,724:INFO:Creating metrics dataframe
2023-04-25 15:30:05,734:INFO:Initializing Light Gradient Boosting Machine
2023-04-25 15:30:05,734:INFO:Total runtime is 0.6768563826878864 minutes
2023-04-25 15:30:05,734:INFO:SubProcess create_model() called ==================================
2023-04-25 15:30:05,735:INFO:Initializing create_model()
2023-04-25 15:30:05,735:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF727E970>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFD6A62B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:30:05,735:INFO:Checking exceptions
2023-04-25 15:30:05,735:INFO:Importing libraries
2023-04-25 15:30:05,735:INFO:Copying training dataset
2023-04-25 15:30:05,739:INFO:Defining folds
2023-04-25 15:30:05,739:INFO:Declaring metric variables
2023-04-25 15:30:05,739:INFO:Importing untrained model
2023-04-25 15:30:05,740:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 15:30:05,740:INFO:Starting cross validation
2023-04-25 15:30:05,741:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:30:09,061:INFO:Calculating mean and std
2023-04-25 15:30:09,062:INFO:Creating metrics dataframe
2023-04-25 15:30:09,314:INFO:Uploading results into container
2023-04-25 15:30:09,315:INFO:Uploading model into container now
2023-04-25 15:30:09,316:INFO:_master_model_container: 17
2023-04-25 15:30:09,316:INFO:_display_container: 2
2023-04-25 15:30:09,317:INFO:LGBMRegressor(random_state=6657)
2023-04-25 15:30:09,317:INFO:create_model() successfully completed......................................
2023-04-25 15:30:09,524:INFO:SubProcess create_model() end ==================================
2023-04-25 15:30:09,524:INFO:Creating metrics dataframe
2023-04-25 15:30:09,534:INFO:Initializing Dummy Regressor
2023-04-25 15:30:09,534:INFO:Total runtime is 0.7401943604151406 minutes
2023-04-25 15:30:09,535:INFO:SubProcess create_model() called ==================================
2023-04-25 15:30:09,535:INFO:Initializing create_model()
2023-04-25 15:30:09,535:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF727E970>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFD6A62B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:30:09,535:INFO:Checking exceptions
2023-04-25 15:30:09,535:INFO:Importing libraries
2023-04-25 15:30:09,535:INFO:Copying training dataset
2023-04-25 15:30:09,541:INFO:Defining folds
2023-04-25 15:30:09,542:INFO:Declaring metric variables
2023-04-25 15:30:09,542:INFO:Importing untrained model
2023-04-25 15:30:09,543:INFO:Dummy Regressor Imported successfully
2023-04-25 15:30:09,544:INFO:Starting cross validation
2023-04-25 15:30:09,545:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:30:11,190:INFO:Calculating mean and std
2023-04-25 15:30:11,191:INFO:Creating metrics dataframe
2023-04-25 15:30:11,423:INFO:Uploading results into container
2023-04-25 15:30:11,425:INFO:Uploading model into container now
2023-04-25 15:30:11,426:INFO:_master_model_container: 18
2023-04-25 15:30:11,426:INFO:_display_container: 2
2023-04-25 15:30:11,427:INFO:DummyRegressor()
2023-04-25 15:30:11,427:INFO:create_model() successfully completed......................................
2023-04-25 15:30:11,638:INFO:SubProcess create_model() end ==================================
2023-04-25 15:30:11,639:INFO:Creating metrics dataframe
2023-04-25 15:30:11,651:INFO:Initializing create_model()
2023-04-25 15:30:11,652:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF727E970>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=6657), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:30:11,652:INFO:Checking exceptions
2023-04-25 15:30:11,654:INFO:Importing libraries
2023-04-25 15:30:11,654:INFO:Copying training dataset
2023-04-25 15:30:11,661:INFO:Defining folds
2023-04-25 15:30:11,661:INFO:Declaring metric variables
2023-04-25 15:30:11,661:INFO:Importing untrained model
2023-04-25 15:30:11,662:INFO:Declaring custom model
2023-04-25 15:30:11,664:INFO:Extra Trees Regressor Imported successfully
2023-04-25 15:30:11,665:INFO:Cross validation set to False
2023-04-25 15:30:11,665:INFO:Fitting Model
2023-04-25 15:30:12,195:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6657)
2023-04-25 15:30:12,195:INFO:create_model() successfully completed......................................
2023-04-25 15:30:12,433:INFO:_master_model_container: 18
2023-04-25 15:30:12,433:INFO:_display_container: 2
2023-04-25 15:30:12,435:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6657)
2023-04-25 15:30:12,435:INFO:compare_models() successfully completed......................................
2023-04-25 15:30:12,448:INFO:Initializing save_model()
2023-04-25 15:30:12,448:INFO:save_model(model=ExtraTreesRegressor(n_jobs=-1, random_state=6657), model_name=best_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\91888\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['TV', 'Radio', 'Newspaper'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-04-25 15:30:12,449:INFO:Adding model into prep_pipe
2023-04-25 15:30:12,536:INFO:best_model.pkl saved in current working directory
2023-04-25 15:30:12,552:INFO:Pipeline(memory=FastMemory(location=C:\Users\91888\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['TV', 'Radio', 'Newspaper'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('trained_model',
                 ExtraTreesRegressor(n_jobs=-1, random_state=6657))])
2023-04-25 15:30:12,552:INFO:save_model() successfully completed......................................
2023-04-25 15:45:55,419:INFO:PyCaret ClassificationExperiment
2023-04-25 15:45:55,420:INFO:Logging name: clf-default-name
2023-04-25 15:45:55,420:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-25 15:45:55,420:INFO:version 3.0.0
2023-04-25 15:45:55,420:INFO:Initializing setup()
2023-04-25 15:45:55,420:INFO:self.USI: 8f11
2023-04-25 15:45:55,420:INFO:self._variable_keys: {'html_param', '_ml_usecase', 'X_test', 'n_jobs_param', 'exp_name_log', 'memory', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param', 'USI', 'seed', 'X_train', 'X', 'gpu_param', 'pipeline', 'target_param', 'fix_imbalance', 'data', 'idx', 'fold_groups_param', 'y_train', 'fold_shuffle_param', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_id', 'is_multiclass'}
2023-04-25 15:45:55,420:INFO:Checking environment
2023-04-25 15:45:55,421:INFO:python_version: 3.9.12
2023-04-25 15:45:55,421:INFO:python_build: ('main', 'Apr  4 2022 05:22:27')
2023-04-25 15:45:55,421:INFO:machine: AMD64
2023-04-25 15:45:55,421:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-25 15:45:55,421:INFO:Memory: svmem(total=8362713088, available=1528107008, percent=81.7, used=6834606080, free=1528107008)
2023-04-25 15:45:55,421:INFO:Physical Core: 4
2023-04-25 15:45:55,421:INFO:Logical Core: 8
2023-04-25 15:45:55,421:INFO:Checking libraries
2023-04-25 15:45:55,421:INFO:System:
2023-04-25 15:45:55,422:INFO:    python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]
2023-04-25 15:45:55,422:INFO:executable: C:\Users\91888\anaconda3\python.exe
2023-04-25 15:45:55,422:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-25 15:45:55,422:INFO:PyCaret required dependencies:
2023-04-25 15:45:55,422:INFO:                 pip: 21.2.4
2023-04-25 15:45:55,422:INFO:          setuptools: 61.2.0
2023-04-25 15:45:55,422:INFO:             pycaret: 3.0.0
2023-04-25 15:45:55,422:INFO:             IPython: 8.2.0
2023-04-25 15:45:55,422:INFO:          ipywidgets: 7.6.5
2023-04-25 15:45:55,422:INFO:                tqdm: 4.64.0
2023-04-25 15:45:55,423:INFO:               numpy: 1.21.5
2023-04-25 15:45:55,423:INFO:              pandas: 1.4.2
2023-04-25 15:45:55,423:INFO:              jinja2: 2.11.3
2023-04-25 15:45:55,423:INFO:               scipy: 1.7.3
2023-04-25 15:45:55,423:INFO:              joblib: 1.2.0
2023-04-25 15:45:55,423:INFO:             sklearn: 1.0.2
2023-04-25 15:45:55,423:INFO:                pyod: 1.0.9
2023-04-25 15:45:55,423:INFO:            imblearn: 0.10.1
2023-04-25 15:45:55,423:INFO:   category_encoders: 2.6.0
2023-04-25 15:45:55,423:INFO:            lightgbm: 3.3.5
2023-04-25 15:45:55,423:INFO:               numba: 0.55.1
2023-04-25 15:45:55,423:INFO:            requests: 2.27.1
2023-04-25 15:45:55,423:INFO:          matplotlib: 3.5.1
2023-04-25 15:45:55,423:INFO:          scikitplot: 0.3.7
2023-04-25 15:45:55,423:INFO:         yellowbrick: 1.5
2023-04-25 15:45:55,423:INFO:              plotly: 5.6.0
2023-04-25 15:45:55,423:INFO:             kaleido: 0.2.1
2023-04-25 15:45:55,423:INFO:         statsmodels: 0.13.2
2023-04-25 15:45:55,424:INFO:              sktime: 0.17.1
2023-04-25 15:45:55,424:INFO:               tbats: 1.1.3
2023-04-25 15:45:55,424:INFO:            pmdarima: 2.0.3
2023-04-25 15:45:55,424:INFO:              psutil: 5.9.5
2023-04-25 15:45:55,424:INFO:PyCaret optional dependencies:
2023-04-25 15:45:55,424:INFO:                shap: Not installed
2023-04-25 15:45:55,424:INFO:           interpret: Not installed
2023-04-25 15:45:55,424:INFO:                umap: Not installed
2023-04-25 15:45:55,424:INFO:    pandas_profiling: 4.1.2
2023-04-25 15:45:55,424:INFO:  explainerdashboard: Not installed
2023-04-25 15:45:55,424:INFO:             autoviz: Not installed
2023-04-25 15:45:55,425:INFO:           fairlearn: Not installed
2023-04-25 15:45:55,425:INFO:             xgboost: Not installed
2023-04-25 15:45:55,425:INFO:            catboost: Not installed
2023-04-25 15:45:55,425:INFO:              kmodes: Not installed
2023-04-25 15:45:55,425:INFO:             mlxtend: Not installed
2023-04-25 15:45:55,425:INFO:       statsforecast: Not installed
2023-04-25 15:45:55,425:INFO:        tune_sklearn: Not installed
2023-04-25 15:45:55,425:INFO:                 ray: Not installed
2023-04-25 15:45:55,425:INFO:            hyperopt: Not installed
2023-04-25 15:45:55,425:INFO:              optuna: Not installed
2023-04-25 15:45:55,425:INFO:               skopt: Not installed
2023-04-25 15:45:55,425:INFO:              mlflow: Not installed
2023-04-25 15:45:55,426:INFO:              gradio: Not installed
2023-04-25 15:45:55,426:INFO:             fastapi: Not installed
2023-04-25 15:45:55,426:INFO:             uvicorn: Not installed
2023-04-25 15:45:55,426:INFO:              m2cgen: Not installed
2023-04-25 15:45:55,426:INFO:           evidently: Not installed
2023-04-25 15:45:55,426:INFO:               fugue: Not installed
2023-04-25 15:45:55,426:INFO:           streamlit: 1.21.0
2023-04-25 15:45:55,426:INFO:             prophet: Not installed
2023-04-25 15:45:55,426:INFO:None
2023-04-25 15:45:55,426:INFO:Set up data.
2023-04-25 15:45:55,434:INFO:Set up train/test split.
2023-04-25 15:46:04,008:INFO:PyCaret RegressionExperiment
2023-04-25 15:46:04,009:INFO:Logging name: reg-default-name
2023-04-25 15:46:04,009:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-25 15:46:04,009:INFO:version 3.0.0
2023-04-25 15:46:04,009:INFO:Initializing setup()
2023-04-25 15:46:04,009:INFO:self.USI: ae75
2023-04-25 15:46:04,009:INFO:self._variable_keys: {'html_param', '_ml_usecase', 'X_test', 'n_jobs_param', 'exp_name_log', 'memory', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param', 'USI', 'seed', 'X_train', 'X', 'gpu_param', 'pipeline', 'target_param', 'data', 'idx', 'fold_groups_param', 'transform_target_param', 'y_train', 'fold_shuffle_param', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_id'}
2023-04-25 15:46:04,009:INFO:Checking environment
2023-04-25 15:46:04,009:INFO:python_version: 3.9.12
2023-04-25 15:46:04,010:INFO:python_build: ('main', 'Apr  4 2022 05:22:27')
2023-04-25 15:46:04,010:INFO:machine: AMD64
2023-04-25 15:46:04,010:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-25 15:46:04,010:INFO:Memory: svmem(total=8362713088, available=1537986560, percent=81.6, used=6824726528, free=1537986560)
2023-04-25 15:46:04,010:INFO:Physical Core: 4
2023-04-25 15:46:04,010:INFO:Logical Core: 8
2023-04-25 15:46:04,010:INFO:Checking libraries
2023-04-25 15:46:04,010:INFO:System:
2023-04-25 15:46:04,010:INFO:    python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]
2023-04-25 15:46:04,010:INFO:executable: C:\Users\91888\anaconda3\python.exe
2023-04-25 15:46:04,012:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-25 15:46:04,012:INFO:PyCaret required dependencies:
2023-04-25 15:46:04,012:INFO:                 pip: 21.2.4
2023-04-25 15:46:04,012:INFO:          setuptools: 61.2.0
2023-04-25 15:46:04,012:INFO:             pycaret: 3.0.0
2023-04-25 15:46:04,012:INFO:             IPython: 8.2.0
2023-04-25 15:46:04,012:INFO:          ipywidgets: 7.6.5
2023-04-25 15:46:04,012:INFO:                tqdm: 4.64.0
2023-04-25 15:46:04,012:INFO:               numpy: 1.21.5
2023-04-25 15:46:04,012:INFO:              pandas: 1.4.2
2023-04-25 15:46:04,013:INFO:              jinja2: 2.11.3
2023-04-25 15:46:04,013:INFO:               scipy: 1.7.3
2023-04-25 15:46:04,013:INFO:              joblib: 1.2.0
2023-04-25 15:46:04,013:INFO:             sklearn: 1.0.2
2023-04-25 15:46:04,013:INFO:                pyod: 1.0.9
2023-04-25 15:46:04,013:INFO:            imblearn: 0.10.1
2023-04-25 15:46:04,013:INFO:   category_encoders: 2.6.0
2023-04-25 15:46:04,013:INFO:            lightgbm: 3.3.5
2023-04-25 15:46:04,013:INFO:               numba: 0.55.1
2023-04-25 15:46:04,013:INFO:            requests: 2.27.1
2023-04-25 15:46:04,013:INFO:          matplotlib: 3.5.1
2023-04-25 15:46:04,013:INFO:          scikitplot: 0.3.7
2023-04-25 15:46:04,014:INFO:         yellowbrick: 1.5
2023-04-25 15:46:04,014:INFO:              plotly: 5.6.0
2023-04-25 15:46:04,014:INFO:             kaleido: 0.2.1
2023-04-25 15:46:04,014:INFO:         statsmodels: 0.13.2
2023-04-25 15:46:04,014:INFO:              sktime: 0.17.1
2023-04-25 15:46:04,014:INFO:               tbats: 1.1.3
2023-04-25 15:46:04,014:INFO:            pmdarima: 2.0.3
2023-04-25 15:46:04,014:INFO:              psutil: 5.9.5
2023-04-25 15:46:04,014:INFO:PyCaret optional dependencies:
2023-04-25 15:46:04,014:INFO:                shap: Not installed
2023-04-25 15:46:04,015:INFO:           interpret: Not installed
2023-04-25 15:46:04,015:INFO:                umap: Not installed
2023-04-25 15:46:04,015:INFO:    pandas_profiling: 4.1.2
2023-04-25 15:46:04,015:INFO:  explainerdashboard: Not installed
2023-04-25 15:46:04,015:INFO:             autoviz: Not installed
2023-04-25 15:46:04,015:INFO:           fairlearn: Not installed
2023-04-25 15:46:04,015:INFO:             xgboost: Not installed
2023-04-25 15:46:04,015:INFO:            catboost: Not installed
2023-04-25 15:46:04,015:INFO:              kmodes: Not installed
2023-04-25 15:46:04,015:INFO:             mlxtend: Not installed
2023-04-25 15:46:04,016:INFO:       statsforecast: Not installed
2023-04-25 15:46:04,016:INFO:        tune_sklearn: Not installed
2023-04-25 15:46:04,016:INFO:                 ray: Not installed
2023-04-25 15:46:04,016:INFO:            hyperopt: Not installed
2023-04-25 15:46:04,016:INFO:              optuna: Not installed
2023-04-25 15:46:04,016:INFO:               skopt: Not installed
2023-04-25 15:46:04,016:INFO:              mlflow: Not installed
2023-04-25 15:46:04,016:INFO:              gradio: Not installed
2023-04-25 15:46:04,016:INFO:             fastapi: Not installed
2023-04-25 15:46:04,016:INFO:             uvicorn: Not installed
2023-04-25 15:46:04,016:INFO:              m2cgen: Not installed
2023-04-25 15:46:04,016:INFO:           evidently: Not installed
2023-04-25 15:46:04,017:INFO:               fugue: Not installed
2023-04-25 15:46:04,017:INFO:           streamlit: 1.21.0
2023-04-25 15:46:04,017:INFO:             prophet: Not installed
2023-04-25 15:46:04,017:INFO:None
2023-04-25 15:46:04,017:INFO:Set up data.
2023-04-25 15:46:04,023:INFO:Set up train/test split.
2023-04-25 15:46:04,028:INFO:Set up index.
2023-04-25 15:46:04,028:INFO:Set up folding strategy.
2023-04-25 15:46:04,028:INFO:Assigning column types.
2023-04-25 15:46:04,035:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-25 15:46:04,035:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 15:46:04,048:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 15:46:04,060:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 15:46:04,208:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:46:04,326:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:46:04,327:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:04,328:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:04,329:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 15:46:04,342:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 15:46:04,357:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 15:46:04,514:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:46:04,635:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:46:04,636:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:04,637:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:04,637:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-25 15:46:04,649:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 15:46:04,661:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 15:46:04,810:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:46:04,929:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:46:04,930:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:04,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:04,944:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 15:46:04,957:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 15:46:05,110:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:46:05,231:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:46:05,232:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:05,233:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:05,233:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-25 15:46:05,251:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 15:46:05,405:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:46:05,530:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:46:05,532:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:05,532:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:05,568:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 15:46:05,720:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:46:05,834:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:46:05,835:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:05,836:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:05,836:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-25 15:46:06,017:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:46:06,143:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:46:06,144:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:06,147:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:06,321:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:46:06,443:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:46:06,445:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:06,445:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:06,446:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-25 15:46:06,624:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:46:06,732:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:06,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:06,903:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:46:07,019:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:07,020:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:07,021:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-25 15:46:07,302:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:07,303:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:07,595:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:07,596:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:07,598:INFO:Preparing preprocessing pipeline...
2023-04-25 15:46:07,598:INFO:Set up simple imputation.
2023-04-25 15:46:07,626:INFO:Finished creating preprocessing pipeline.
2023-04-25 15:46:07,635:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\91888\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['TV', 'Radio', 'Newspaper'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-04-25 15:46:07,635:INFO:Creating final display dataframe.
2023-04-25 15:46:07,756:INFO:Setup _display_container:                     Description             Value
0                    Session id              4915
1                        Target             Sales
2                   Target type        Regression
3           Original data shape          (200, 4)
4        Transformed data shape          (200, 4)
5   Transformed train set shape          (140, 4)
6    Transformed test set shape           (60, 4)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              ae75
2023-04-25 15:46:08,075:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:08,076:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:08,361:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:08,363:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:46:08,364:INFO:setup() successfully completed in 4.51s...............
2023-04-25 15:46:08,371:INFO:Initializing compare_models()
2023-04-25 15:46:08,371:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CFAD73520>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000017CFAD73520>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-25 15:46:08,371:INFO:Checking exceptions
2023-04-25 15:46:08,375:INFO:Preparing display monitor
2023-04-25 15:46:08,382:INFO:Initializing Linear Regression
2023-04-25 15:46:08,383:INFO:Total runtime is 1.6677379608154298e-05 minutes
2023-04-25 15:46:08,383:INFO:SubProcess create_model() called ==================================
2023-04-25 15:46:08,383:INFO:Initializing create_model()
2023-04-25 15:46:08,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CFAD73520>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFA0EAC40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:46:08,385:INFO:Checking exceptions
2023-04-25 15:46:08,385:INFO:Importing libraries
2023-04-25 15:46:08,385:INFO:Copying training dataset
2023-04-25 15:46:08,393:INFO:Defining folds
2023-04-25 15:46:08,394:INFO:Declaring metric variables
2023-04-25 15:46:08,394:INFO:Importing untrained model
2023-04-25 15:46:08,395:INFO:Linear Regression Imported successfully
2023-04-25 15:46:08,395:INFO:Starting cross validation
2023-04-25 15:46:08,397:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:46:14,855:INFO:Calculating mean and std
2023-04-25 15:46:14,857:INFO:Creating metrics dataframe
2023-04-25 15:46:15,129:INFO:Uploading results into container
2023-04-25 15:46:15,130:INFO:Uploading model into container now
2023-04-25 15:46:15,131:INFO:_master_model_container: 1
2023-04-25 15:46:15,132:INFO:_display_container: 2
2023-04-25 15:46:15,132:INFO:LinearRegression(n_jobs=-1)
2023-04-25 15:46:15,132:INFO:create_model() successfully completed......................................
2023-04-25 15:46:15,375:INFO:SubProcess create_model() end ==================================
2023-04-25 15:46:15,376:INFO:Creating metrics dataframe
2023-04-25 15:46:15,384:INFO:Initializing Lasso Regression
2023-04-25 15:46:15,385:INFO:Total runtime is 0.11668685674667359 minutes
2023-04-25 15:46:15,385:INFO:SubProcess create_model() called ==================================
2023-04-25 15:46:15,386:INFO:Initializing create_model()
2023-04-25 15:46:15,386:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CFAD73520>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFA0EAC40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:46:15,386:INFO:Checking exceptions
2023-04-25 15:46:15,386:INFO:Importing libraries
2023-04-25 15:46:15,386:INFO:Copying training dataset
2023-04-25 15:46:15,393:INFO:Defining folds
2023-04-25 15:46:15,393:INFO:Declaring metric variables
2023-04-25 15:46:15,393:INFO:Importing untrained model
2023-04-25 15:46:15,394:INFO:Lasso Regression Imported successfully
2023-04-25 15:46:15,395:INFO:Starting cross validation
2023-04-25 15:46:15,396:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:46:16,762:INFO:Calculating mean and std
2023-04-25 15:46:16,764:INFO:Creating metrics dataframe
2023-04-25 15:46:17,038:INFO:Uploading results into container
2023-04-25 15:46:17,039:INFO:Uploading model into container now
2023-04-25 15:46:17,040:INFO:_master_model_container: 2
2023-04-25 15:46:17,040:INFO:_display_container: 2
2023-04-25 15:46:17,041:INFO:Lasso(random_state=4915)
2023-04-25 15:46:17,041:INFO:create_model() successfully completed......................................
2023-04-25 15:46:17,265:INFO:SubProcess create_model() end ==================================
2023-04-25 15:46:17,269:INFO:Creating metrics dataframe
2023-04-25 15:46:17,274:INFO:Initializing Ridge Regression
2023-04-25 15:46:17,274:INFO:Total runtime is 0.14819379647572836 minutes
2023-04-25 15:46:17,275:INFO:SubProcess create_model() called ==================================
2023-04-25 15:46:17,275:INFO:Initializing create_model()
2023-04-25 15:46:17,275:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CFAD73520>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFA0EAC40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:46:17,275:INFO:Checking exceptions
2023-04-25 15:46:17,275:INFO:Importing libraries
2023-04-25 15:46:17,275:INFO:Copying training dataset
2023-04-25 15:46:17,280:INFO:Defining folds
2023-04-25 15:46:17,281:INFO:Declaring metric variables
2023-04-25 15:46:17,281:INFO:Importing untrained model
2023-04-25 15:46:17,282:INFO:Ridge Regression Imported successfully
2023-04-25 15:46:17,282:INFO:Starting cross validation
2023-04-25 15:46:17,284:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:46:18,968:INFO:Calculating mean and std
2023-04-25 15:46:18,970:INFO:Creating metrics dataframe
2023-04-25 15:46:19,234:INFO:Uploading results into container
2023-04-25 15:46:19,236:INFO:Uploading model into container now
2023-04-25 15:46:19,237:INFO:_master_model_container: 3
2023-04-25 15:46:19,237:INFO:_display_container: 2
2023-04-25 15:46:19,237:INFO:Ridge(random_state=4915)
2023-04-25 15:46:19,237:INFO:create_model() successfully completed......................................
2023-04-25 15:46:19,431:INFO:SubProcess create_model() end ==================================
2023-04-25 15:46:19,431:INFO:Creating metrics dataframe
2023-04-25 15:46:19,440:INFO:Initializing Elastic Net
2023-04-25 15:46:19,440:INFO:Total runtime is 0.18430019219716393 minutes
2023-04-25 15:46:19,442:INFO:SubProcess create_model() called ==================================
2023-04-25 15:46:19,442:INFO:Initializing create_model()
2023-04-25 15:46:19,442:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CFAD73520>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFA0EAC40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:46:19,442:INFO:Checking exceptions
2023-04-25 15:46:19,442:INFO:Importing libraries
2023-04-25 15:46:19,442:INFO:Copying training dataset
2023-04-25 15:46:19,447:INFO:Defining folds
2023-04-25 15:46:19,447:INFO:Declaring metric variables
2023-04-25 15:46:19,448:INFO:Importing untrained model
2023-04-25 15:46:19,448:INFO:Elastic Net Imported successfully
2023-04-25 15:46:19,449:INFO:Starting cross validation
2023-04-25 15:46:19,450:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:46:21,162:INFO:Calculating mean and std
2023-04-25 15:46:21,163:INFO:Creating metrics dataframe
2023-04-25 15:46:21,418:INFO:Uploading results into container
2023-04-25 15:46:21,419:INFO:Uploading model into container now
2023-04-25 15:46:21,420:INFO:_master_model_container: 4
2023-04-25 15:46:21,420:INFO:_display_container: 2
2023-04-25 15:46:21,421:INFO:ElasticNet(random_state=4915)
2023-04-25 15:46:21,421:INFO:create_model() successfully completed......................................
2023-04-25 15:46:21,640:INFO:SubProcess create_model() end ==================================
2023-04-25 15:46:21,640:INFO:Creating metrics dataframe
2023-04-25 15:46:21,650:INFO:Initializing Least Angle Regression
2023-04-25 15:46:21,650:INFO:Total runtime is 0.22112734715143842 minutes
2023-04-25 15:46:21,651:INFO:SubProcess create_model() called ==================================
2023-04-25 15:46:21,651:INFO:Initializing create_model()
2023-04-25 15:46:21,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CFAD73520>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFA0EAC40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:46:21,653:INFO:Checking exceptions
2023-04-25 15:46:21,653:INFO:Importing libraries
2023-04-25 15:46:21,653:INFO:Copying training dataset
2023-04-25 15:46:21,660:INFO:Defining folds
2023-04-25 15:46:21,660:INFO:Declaring metric variables
2023-04-25 15:46:21,661:INFO:Importing untrained model
2023-04-25 15:46:21,661:INFO:Least Angle Regression Imported successfully
2023-04-25 15:46:21,661:INFO:Starting cross validation
2023-04-25 15:46:21,663:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:46:21,764:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:46:21,790:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:46:21,815:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:46:21,819:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:46:21,837:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:46:21,888:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:46:21,910:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:46:21,934:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:46:22,177:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:46:22,197:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:46:23,411:INFO:Calculating mean and std
2023-04-25 15:46:23,413:INFO:Creating metrics dataframe
2023-04-25 15:46:23,695:INFO:Uploading results into container
2023-04-25 15:46:23,695:INFO:Uploading model into container now
2023-04-25 15:46:23,696:INFO:_master_model_container: 5
2023-04-25 15:46:23,696:INFO:_display_container: 2
2023-04-25 15:46:23,696:INFO:Lars(random_state=4915)
2023-04-25 15:46:23,696:INFO:create_model() successfully completed......................................
2023-04-25 15:46:23,914:INFO:SubProcess create_model() end ==================================
2023-04-25 15:46:23,914:INFO:Creating metrics dataframe
2023-04-25 15:46:23,923:INFO:Initializing Lasso Least Angle Regression
2023-04-25 15:46:23,924:INFO:Total runtime is 0.25903066794077556 minutes
2023-04-25 15:46:23,924:INFO:SubProcess create_model() called ==================================
2023-04-25 15:46:23,925:INFO:Initializing create_model()
2023-04-25 15:46:23,925:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CFAD73520>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFA0EAC40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:46:23,925:INFO:Checking exceptions
2023-04-25 15:46:23,925:INFO:Importing libraries
2023-04-25 15:46:23,925:INFO:Copying training dataset
2023-04-25 15:46:23,932:INFO:Defining folds
2023-04-25 15:46:23,932:INFO:Declaring metric variables
2023-04-25 15:46:23,932:INFO:Importing untrained model
2023-04-25 15:46:23,933:INFO:Lasso Least Angle Regression Imported successfully
2023-04-25 15:46:23,934:INFO:Starting cross validation
2023-04-25 15:46:23,935:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:46:24,028:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:46:24,050:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:46:24,085:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:46:24,106:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:46:24,129:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:46:24,167:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:46:24,190:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:46:24,215:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:46:24,419:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:46:24,467:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:46:25,684:INFO:Calculating mean and std
2023-04-25 15:46:25,686:INFO:Creating metrics dataframe
2023-04-25 15:46:25,956:INFO:Uploading results into container
2023-04-25 15:46:25,958:INFO:Uploading model into container now
2023-04-25 15:46:25,959:INFO:_master_model_container: 6
2023-04-25 15:46:25,959:INFO:_display_container: 2
2023-04-25 15:46:25,960:INFO:LassoLars(random_state=4915)
2023-04-25 15:46:25,960:INFO:create_model() successfully completed......................................
2023-04-25 15:46:26,180:INFO:SubProcess create_model() end ==================================
2023-04-25 15:46:26,180:INFO:Creating metrics dataframe
2023-04-25 15:46:26,189:INFO:Initializing Orthogonal Matching Pursuit
2023-04-25 15:46:26,189:INFO:Total runtime is 0.2967787504196167 minutes
2023-04-25 15:46:26,190:INFO:SubProcess create_model() called ==================================
2023-04-25 15:46:26,190:INFO:Initializing create_model()
2023-04-25 15:46:26,191:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CFAD73520>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFA0EAC40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:46:26,191:INFO:Checking exceptions
2023-04-25 15:46:26,193:INFO:Importing libraries
2023-04-25 15:46:26,193:INFO:Copying training dataset
2023-04-25 15:46:26,199:INFO:Defining folds
2023-04-25 15:46:26,199:INFO:Declaring metric variables
2023-04-25 15:46:26,199:INFO:Importing untrained model
2023-04-25 15:46:26,200:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-25 15:46:26,201:INFO:Starting cross validation
2023-04-25 15:46:26,202:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:46:26,296:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:46:26,307:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:46:26,328:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:46:26,355:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:46:26,367:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:46:26,404:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:46:26,426:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:46:26,458:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:46:26,689:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:46:26,716:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:46:27,931:INFO:Calculating mean and std
2023-04-25 15:46:27,932:INFO:Creating metrics dataframe
2023-04-25 15:46:28,212:INFO:Uploading results into container
2023-04-25 15:46:28,214:INFO:Uploading model into container now
2023-04-25 15:46:28,214:INFO:_master_model_container: 7
2023-04-25 15:46:28,215:INFO:_display_container: 2
2023-04-25 15:46:28,215:INFO:OrthogonalMatchingPursuit()
2023-04-25 15:46:28,215:INFO:create_model() successfully completed......................................
2023-04-25 15:46:28,419:INFO:SubProcess create_model() end ==================================
2023-04-25 15:46:28,420:INFO:Creating metrics dataframe
2023-04-25 15:46:28,428:INFO:Initializing Bayesian Ridge
2023-04-25 15:46:28,428:INFO:Total runtime is 0.33409820397694906 minutes
2023-04-25 15:46:28,429:INFO:SubProcess create_model() called ==================================
2023-04-25 15:46:28,429:INFO:Initializing create_model()
2023-04-25 15:46:28,429:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CFAD73520>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFA0EAC40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:46:28,429:INFO:Checking exceptions
2023-04-25 15:46:28,429:INFO:Importing libraries
2023-04-25 15:46:28,430:INFO:Copying training dataset
2023-04-25 15:46:28,438:INFO:Defining folds
2023-04-25 15:46:28,438:INFO:Declaring metric variables
2023-04-25 15:46:28,439:INFO:Importing untrained model
2023-04-25 15:46:28,440:INFO:Bayesian Ridge Imported successfully
2023-04-25 15:46:28,440:INFO:Starting cross validation
2023-04-25 15:46:28,442:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:46:30,199:INFO:Calculating mean and std
2023-04-25 15:46:30,200:INFO:Creating metrics dataframe
2023-04-25 15:46:30,439:INFO:Uploading results into container
2023-04-25 15:46:30,441:INFO:Uploading model into container now
2023-04-25 15:46:30,441:INFO:_master_model_container: 8
2023-04-25 15:46:30,442:INFO:_display_container: 2
2023-04-25 15:46:30,442:INFO:BayesianRidge()
2023-04-25 15:46:30,443:INFO:create_model() successfully completed......................................
2023-04-25 15:46:30,659:INFO:SubProcess create_model() end ==================================
2023-04-25 15:46:30,659:INFO:Creating metrics dataframe
2023-04-25 15:46:30,669:INFO:Initializing Passive Aggressive Regressor
2023-04-25 15:46:30,669:INFO:Total runtime is 0.3714375178019206 minutes
2023-04-25 15:46:30,669:INFO:SubProcess create_model() called ==================================
2023-04-25 15:46:30,670:INFO:Initializing create_model()
2023-04-25 15:46:30,670:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CFAD73520>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFA0EAC40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:46:30,670:INFO:Checking exceptions
2023-04-25 15:46:30,670:INFO:Importing libraries
2023-04-25 15:46:30,670:INFO:Copying training dataset
2023-04-25 15:46:30,676:INFO:Defining folds
2023-04-25 15:46:30,676:INFO:Declaring metric variables
2023-04-25 15:46:30,677:INFO:Importing untrained model
2023-04-25 15:46:30,678:INFO:Passive Aggressive Regressor Imported successfully
2023-04-25 15:46:30,678:INFO:Starting cross validation
2023-04-25 15:46:30,680:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:46:32,435:INFO:Calculating mean and std
2023-04-25 15:46:32,436:INFO:Creating metrics dataframe
2023-04-25 15:46:32,705:INFO:Uploading results into container
2023-04-25 15:46:32,707:INFO:Uploading model into container now
2023-04-25 15:46:32,707:INFO:_master_model_container: 9
2023-04-25 15:46:32,708:INFO:_display_container: 2
2023-04-25 15:46:32,708:INFO:PassiveAggressiveRegressor(random_state=4915)
2023-04-25 15:46:32,709:INFO:create_model() successfully completed......................................
2023-04-25 15:46:32,914:INFO:SubProcess create_model() end ==================================
2023-04-25 15:46:32,914:INFO:Creating metrics dataframe
2023-04-25 15:46:32,924:INFO:Initializing Huber Regressor
2023-04-25 15:46:32,925:INFO:Total runtime is 0.4090439001719157 minutes
2023-04-25 15:46:32,925:INFO:SubProcess create_model() called ==================================
2023-04-25 15:46:32,926:INFO:Initializing create_model()
2023-04-25 15:46:32,926:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CFAD73520>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFA0EAC40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:46:32,926:INFO:Checking exceptions
2023-04-25 15:46:32,926:INFO:Importing libraries
2023-04-25 15:46:32,927:INFO:Copying training dataset
2023-04-25 15:46:32,933:INFO:Defining folds
2023-04-25 15:46:32,933:INFO:Declaring metric variables
2023-04-25 15:46:32,933:INFO:Importing untrained model
2023-04-25 15:46:32,934:INFO:Huber Regressor Imported successfully
2023-04-25 15:46:32,934:INFO:Starting cross validation
2023-04-25 15:46:32,936:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:46:34,666:INFO:Calculating mean and std
2023-04-25 15:46:34,667:INFO:Creating metrics dataframe
2023-04-25 15:46:34,930:INFO:Uploading results into container
2023-04-25 15:46:34,931:INFO:Uploading model into container now
2023-04-25 15:46:34,932:INFO:_master_model_container: 10
2023-04-25 15:46:34,932:INFO:_display_container: 2
2023-04-25 15:46:34,933:INFO:HuberRegressor()
2023-04-25 15:46:34,933:INFO:create_model() successfully completed......................................
2023-04-25 15:46:35,141:INFO:SubProcess create_model() end ==================================
2023-04-25 15:46:35,141:INFO:Creating metrics dataframe
2023-04-25 15:46:35,151:INFO:Initializing K Neighbors Regressor
2023-04-25 15:46:35,151:INFO:Total runtime is 0.4461369792620341 minutes
2023-04-25 15:46:35,151:INFO:SubProcess create_model() called ==================================
2023-04-25 15:46:35,152:INFO:Initializing create_model()
2023-04-25 15:46:35,152:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CFAD73520>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFA0EAC40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:46:35,152:INFO:Checking exceptions
2023-04-25 15:46:35,152:INFO:Importing libraries
2023-04-25 15:46:35,152:INFO:Copying training dataset
2023-04-25 15:46:35,158:INFO:Defining folds
2023-04-25 15:46:35,158:INFO:Declaring metric variables
2023-04-25 15:46:35,158:INFO:Importing untrained model
2023-04-25 15:46:35,159:INFO:K Neighbors Regressor Imported successfully
2023-04-25 15:46:35,160:INFO:Starting cross validation
2023-04-25 15:46:35,161:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:46:36,883:INFO:Calculating mean and std
2023-04-25 15:46:36,885:INFO:Creating metrics dataframe
2023-04-25 15:46:37,163:INFO:Uploading results into container
2023-04-25 15:46:37,164:INFO:Uploading model into container now
2023-04-25 15:46:37,165:INFO:_master_model_container: 11
2023-04-25 15:46:37,165:INFO:_display_container: 2
2023-04-25 15:46:37,165:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-25 15:46:37,165:INFO:create_model() successfully completed......................................
2023-04-25 15:46:37,375:INFO:SubProcess create_model() end ==================================
2023-04-25 15:46:37,375:INFO:Creating metrics dataframe
2023-04-25 15:46:37,383:INFO:Initializing Decision Tree Regressor
2023-04-25 15:46:37,383:INFO:Total runtime is 0.4833466013272604 minutes
2023-04-25 15:46:37,383:INFO:SubProcess create_model() called ==================================
2023-04-25 15:46:37,384:INFO:Initializing create_model()
2023-04-25 15:46:37,384:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CFAD73520>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFA0EAC40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:46:37,384:INFO:Checking exceptions
2023-04-25 15:46:37,384:INFO:Importing libraries
2023-04-25 15:46:37,384:INFO:Copying training dataset
2023-04-25 15:46:37,391:INFO:Defining folds
2023-04-25 15:46:37,391:INFO:Declaring metric variables
2023-04-25 15:46:37,392:INFO:Importing untrained model
2023-04-25 15:46:37,392:INFO:Decision Tree Regressor Imported successfully
2023-04-25 15:46:37,393:INFO:Starting cross validation
2023-04-25 15:46:37,394:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:46:39,166:INFO:Calculating mean and std
2023-04-25 15:46:39,167:INFO:Creating metrics dataframe
2023-04-25 15:46:39,426:INFO:Uploading results into container
2023-04-25 15:46:39,432:INFO:Uploading model into container now
2023-04-25 15:46:39,433:INFO:_master_model_container: 12
2023-04-25 15:46:39,433:INFO:_display_container: 2
2023-04-25 15:46:39,433:INFO:DecisionTreeRegressor(random_state=4915)
2023-04-25 15:46:39,433:INFO:create_model() successfully completed......................................
2023-04-25 15:46:39,649:INFO:SubProcess create_model() end ==================================
2023-04-25 15:46:39,649:INFO:Creating metrics dataframe
2023-04-25 15:46:39,658:INFO:Initializing Random Forest Regressor
2023-04-25 15:46:39,660:INFO:Total runtime is 0.5212883869806926 minutes
2023-04-25 15:46:39,660:INFO:SubProcess create_model() called ==================================
2023-04-25 15:46:39,661:INFO:Initializing create_model()
2023-04-25 15:46:39,661:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CFAD73520>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFA0EAC40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:46:39,661:INFO:Checking exceptions
2023-04-25 15:46:39,661:INFO:Importing libraries
2023-04-25 15:46:39,661:INFO:Copying training dataset
2023-04-25 15:46:39,668:INFO:Defining folds
2023-04-25 15:46:39,668:INFO:Declaring metric variables
2023-04-25 15:46:39,668:INFO:Importing untrained model
2023-04-25 15:46:39,669:INFO:Random Forest Regressor Imported successfully
2023-04-25 15:46:39,670:INFO:Starting cross validation
2023-04-25 15:46:39,671:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:46:42,652:INFO:Calculating mean and std
2023-04-25 15:46:42,654:INFO:Creating metrics dataframe
2023-04-25 15:46:42,943:INFO:Uploading results into container
2023-04-25 15:46:42,944:INFO:Uploading model into container now
2023-04-25 15:46:42,945:INFO:_master_model_container: 13
2023-04-25 15:46:42,945:INFO:_display_container: 2
2023-04-25 15:46:42,945:INFO:RandomForestRegressor(n_jobs=-1, random_state=4915)
2023-04-25 15:46:42,945:INFO:create_model() successfully completed......................................
2023-04-25 15:46:43,153:INFO:SubProcess create_model() end ==================================
2023-04-25 15:46:43,153:INFO:Creating metrics dataframe
2023-04-25 15:46:43,163:INFO:Initializing Extra Trees Regressor
2023-04-25 15:46:43,163:INFO:Total runtime is 0.5796791354815165 minutes
2023-04-25 15:46:43,163:INFO:SubProcess create_model() called ==================================
2023-04-25 15:46:43,164:INFO:Initializing create_model()
2023-04-25 15:46:43,164:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CFAD73520>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFA0EAC40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:46:43,164:INFO:Checking exceptions
2023-04-25 15:46:43,164:INFO:Importing libraries
2023-04-25 15:46:43,164:INFO:Copying training dataset
2023-04-25 15:46:43,171:INFO:Defining folds
2023-04-25 15:46:43,171:INFO:Declaring metric variables
2023-04-25 15:46:43,172:INFO:Importing untrained model
2023-04-25 15:46:43,173:INFO:Extra Trees Regressor Imported successfully
2023-04-25 15:46:43,173:INFO:Starting cross validation
2023-04-25 15:46:43,175:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:46:46,098:INFO:Calculating mean and std
2023-04-25 15:46:46,100:INFO:Creating metrics dataframe
2023-04-25 15:46:46,396:INFO:Uploading results into container
2023-04-25 15:46:46,398:INFO:Uploading model into container now
2023-04-25 15:46:46,399:INFO:_master_model_container: 14
2023-04-25 15:46:46,399:INFO:_display_container: 2
2023-04-25 15:46:46,399:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=4915)
2023-04-25 15:46:46,400:INFO:create_model() successfully completed......................................
2023-04-25 15:46:46,611:INFO:SubProcess create_model() end ==================================
2023-04-25 15:46:46,611:INFO:Creating metrics dataframe
2023-04-25 15:46:46,618:INFO:Initializing AdaBoost Regressor
2023-04-25 15:46:46,619:INFO:Total runtime is 0.637268586953481 minutes
2023-04-25 15:46:46,619:INFO:SubProcess create_model() called ==================================
2023-04-25 15:46:46,619:INFO:Initializing create_model()
2023-04-25 15:46:46,620:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CFAD73520>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFA0EAC40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:46:46,620:INFO:Checking exceptions
2023-04-25 15:46:46,620:INFO:Importing libraries
2023-04-25 15:46:46,620:INFO:Copying training dataset
2023-04-25 15:46:46,626:INFO:Defining folds
2023-04-25 15:46:46,627:INFO:Declaring metric variables
2023-04-25 15:46:46,627:INFO:Importing untrained model
2023-04-25 15:46:46,628:INFO:AdaBoost Regressor Imported successfully
2023-04-25 15:46:46,629:INFO:Starting cross validation
2023-04-25 15:46:46,631:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:46:48,109:INFO:Calculating mean and std
2023-04-25 15:46:48,110:INFO:Creating metrics dataframe
2023-04-25 15:46:48,395:INFO:Uploading results into container
2023-04-25 15:46:48,396:INFO:Uploading model into container now
2023-04-25 15:46:48,397:INFO:_master_model_container: 15
2023-04-25 15:46:48,397:INFO:_display_container: 2
2023-04-25 15:46:48,398:INFO:AdaBoostRegressor(random_state=4915)
2023-04-25 15:46:48,398:INFO:create_model() successfully completed......................................
2023-04-25 15:46:48,604:INFO:SubProcess create_model() end ==================================
2023-04-25 15:46:48,604:INFO:Creating metrics dataframe
2023-04-25 15:46:48,615:INFO:Initializing Gradient Boosting Regressor
2023-04-25 15:46:48,615:INFO:Total runtime is 0.670540722211202 minutes
2023-04-25 15:46:48,616:INFO:SubProcess create_model() called ==================================
2023-04-25 15:46:48,616:INFO:Initializing create_model()
2023-04-25 15:46:48,616:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CFAD73520>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFA0EAC40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:46:48,617:INFO:Checking exceptions
2023-04-25 15:46:48,617:INFO:Importing libraries
2023-04-25 15:46:48,617:INFO:Copying training dataset
2023-04-25 15:46:48,624:INFO:Defining folds
2023-04-25 15:46:48,624:INFO:Declaring metric variables
2023-04-25 15:46:48,624:INFO:Importing untrained model
2023-04-25 15:46:48,626:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 15:46:48,627:INFO:Starting cross validation
2023-04-25 15:46:48,628:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:46:50,685:INFO:Calculating mean and std
2023-04-25 15:46:50,686:INFO:Creating metrics dataframe
2023-04-25 15:46:51,015:INFO:Uploading results into container
2023-04-25 15:46:51,016:INFO:Uploading model into container now
2023-04-25 15:46:51,017:INFO:_master_model_container: 16
2023-04-25 15:46:51,017:INFO:_display_container: 2
2023-04-25 15:46:51,018:INFO:GradientBoostingRegressor(random_state=4915)
2023-04-25 15:46:51,018:INFO:create_model() successfully completed......................................
2023-04-25 15:46:51,227:INFO:SubProcess create_model() end ==================================
2023-04-25 15:46:51,228:INFO:Creating metrics dataframe
2023-04-25 15:46:51,236:INFO:Initializing Light Gradient Boosting Machine
2023-04-25 15:46:51,236:INFO:Total runtime is 0.7142234444618225 minutes
2023-04-25 15:46:51,237:INFO:SubProcess create_model() called ==================================
2023-04-25 15:46:51,237:INFO:Initializing create_model()
2023-04-25 15:46:51,237:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CFAD73520>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFA0EAC40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:46:51,237:INFO:Checking exceptions
2023-04-25 15:46:51,237:INFO:Importing libraries
2023-04-25 15:46:51,237:INFO:Copying training dataset
2023-04-25 15:46:51,240:INFO:Defining folds
2023-04-25 15:46:51,240:INFO:Declaring metric variables
2023-04-25 15:46:51,240:INFO:Importing untrained model
2023-04-25 15:46:51,241:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 15:46:51,241:INFO:Starting cross validation
2023-04-25 15:46:51,243:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:46:54,829:INFO:Calculating mean and std
2023-04-25 15:46:54,831:INFO:Creating metrics dataframe
2023-04-25 15:46:55,132:INFO:Uploading results into container
2023-04-25 15:46:55,134:INFO:Uploading model into container now
2023-04-25 15:46:55,134:INFO:_master_model_container: 17
2023-04-25 15:46:55,136:INFO:_display_container: 2
2023-04-25 15:46:55,136:INFO:LGBMRegressor(random_state=4915)
2023-04-25 15:46:55,137:INFO:create_model() successfully completed......................................
2023-04-25 15:46:55,346:INFO:SubProcess create_model() end ==================================
2023-04-25 15:46:55,346:INFO:Creating metrics dataframe
2023-04-25 15:46:55,356:INFO:Initializing Dummy Regressor
2023-04-25 15:46:55,356:INFO:Total runtime is 0.7828854163487753 minutes
2023-04-25 15:46:55,357:INFO:SubProcess create_model() called ==================================
2023-04-25 15:46:55,357:INFO:Initializing create_model()
2023-04-25 15:46:55,357:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CFAD73520>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFA0EAC40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:46:55,357:INFO:Checking exceptions
2023-04-25 15:46:55,357:INFO:Importing libraries
2023-04-25 15:46:55,357:INFO:Copying training dataset
2023-04-25 15:46:55,364:INFO:Defining folds
2023-04-25 15:46:55,364:INFO:Declaring metric variables
2023-04-25 15:46:55,364:INFO:Importing untrained model
2023-04-25 15:46:55,365:INFO:Dummy Regressor Imported successfully
2023-04-25 15:46:55,365:INFO:Starting cross validation
2023-04-25 15:46:55,367:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:46:57,230:INFO:Calculating mean and std
2023-04-25 15:46:57,232:INFO:Creating metrics dataframe
2023-04-25 15:46:57,510:INFO:Uploading results into container
2023-04-25 15:46:57,511:INFO:Uploading model into container now
2023-04-25 15:46:57,512:INFO:_master_model_container: 18
2023-04-25 15:46:57,512:INFO:_display_container: 2
2023-04-25 15:46:57,513:INFO:DummyRegressor()
2023-04-25 15:46:57,513:INFO:create_model() successfully completed......................................
2023-04-25 15:46:57,716:INFO:SubProcess create_model() end ==================================
2023-04-25 15:46:57,717:INFO:Creating metrics dataframe
2023-04-25 15:46:57,731:INFO:Initializing create_model()
2023-04-25 15:46:57,731:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CFAD73520>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=4915), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:46:57,731:INFO:Checking exceptions
2023-04-25 15:46:57,733:INFO:Importing libraries
2023-04-25 15:46:57,733:INFO:Copying training dataset
2023-04-25 15:46:57,740:INFO:Defining folds
2023-04-25 15:46:57,741:INFO:Declaring metric variables
2023-04-25 15:46:57,741:INFO:Importing untrained model
2023-04-25 15:46:57,741:INFO:Declaring custom model
2023-04-25 15:46:57,743:INFO:Extra Trees Regressor Imported successfully
2023-04-25 15:46:57,744:INFO:Cross validation set to False
2023-04-25 15:46:57,746:INFO:Fitting Model
2023-04-25 15:46:58,314:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=4915)
2023-04-25 15:46:58,314:INFO:create_model() successfully completed......................................
2023-04-25 15:46:58,558:INFO:_master_model_container: 18
2023-04-25 15:46:58,558:INFO:_display_container: 2
2023-04-25 15:46:58,559:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=4915)
2023-04-25 15:46:58,559:INFO:compare_models() successfully completed......................................
2023-04-25 15:46:58,571:INFO:Initializing save_model()
2023-04-25 15:46:58,571:INFO:save_model(model=ExtraTreesRegressor(n_jobs=-1, random_state=4915), model_name=best_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\91888\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['TV', 'Radio', 'Newspaper'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-04-25 15:46:58,571:INFO:Adding model into prep_pipe
2023-04-25 15:46:58,646:INFO:best_model.pkl saved in current working directory
2023-04-25 15:46:58,658:INFO:Pipeline(memory=FastMemory(location=C:\Users\91888\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['TV', 'Radio', 'Newspaper'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('trained_model',
                 ExtraTreesRegressor(n_jobs=-1, random_state=4915))])
2023-04-25 15:46:58,658:INFO:save_model() successfully completed......................................
2023-04-25 15:46:59,042:INFO:Initializing plot_model()
2023-04-25 15:46:59,042:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=4915), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CFAD73520>, system=True)
2023-04-25 15:46:59,042:INFO:Checking exceptions
2023-04-25 15:46:59,079:INFO:Preloading libraries
2023-04-25 15:46:59,110:INFO:Copying training dataset
2023-04-25 15:46:59,111:INFO:Plot type: residuals
2023-04-25 15:46:59,491:INFO:Fitting Model
2023-04-25 15:46:59,496:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2023-04-25 15:46:59,661:INFO:Scoring test/hold-out set
2023-04-25 15:46:59,789:WARNING:C:\Users\91888\anaconda3\lib\site-packages\yellowbrick\base.py:246: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()

2023-04-25 15:46:59,876:INFO:Visual Rendered Successfully
2023-04-25 15:47:00,088:INFO:plot_model() successfully completed......................................
2023-04-25 15:47:00,090:INFO:Initializing plot_model()
2023-04-25 15:47:00,090:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=4915), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CFAD73520>, system=True)
2023-04-25 15:47:00,090:INFO:Checking exceptions
2023-04-25 15:47:00,129:INFO:Preloading libraries
2023-04-25 15:47:00,148:INFO:Copying training dataset
2023-04-25 15:47:00,148:INFO:Plot type: error
2023-04-25 15:47:00,274:INFO:Fitting Model
2023-04-25 15:47:00,274:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2023-04-25 15:47:00,305:INFO:Scoring test/hold-out set
2023-04-25 15:47:00,432:WARNING:C:\Users\91888\anaconda3\lib\site-packages\yellowbrick\base.py:246: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()

2023-04-25 15:47:00,476:INFO:Visual Rendered Successfully
2023-04-25 15:47:00,692:INFO:plot_model() successfully completed......................................
2023-04-25 15:47:00,693:INFO:Initializing plot_model()
2023-04-25 15:47:00,693:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=4915), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CFAD73520>, system=True)
2023-04-25 15:47:00,693:INFO:Checking exceptions
2023-04-25 15:47:00,724:INFO:Preloading libraries
2023-04-25 15:47:00,740:INFO:Copying training dataset
2023-04-25 15:47:00,740:INFO:Plot type: feature
2023-04-25 15:47:00,741:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 15:47:01,513:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:1896: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()

2023-04-25 15:47:01,514:INFO:Visual Rendered Successfully
2023-04-25 15:47:01,732:INFO:plot_model() successfully completed......................................
2023-04-25 15:51:21,146:INFO:PyCaret RegressionExperiment
2023-04-25 15:51:21,146:INFO:Logging name: reg-default-name
2023-04-25 15:51:21,147:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-25 15:51:21,147:INFO:version 3.0.0
2023-04-25 15:51:21,147:INFO:Initializing setup()
2023-04-25 15:51:21,147:INFO:self.USI: b2c2
2023-04-25 15:51:21,147:INFO:self._variable_keys: {'html_param', '_ml_usecase', 'X_test', 'n_jobs_param', 'exp_name_log', 'memory', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param', 'USI', 'seed', 'X_train', 'X', 'gpu_param', 'pipeline', 'target_param', 'data', 'idx', 'fold_groups_param', 'transform_target_param', 'y_train', 'fold_shuffle_param', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_id'}
2023-04-25 15:51:21,147:INFO:Checking environment
2023-04-25 15:51:21,147:INFO:python_version: 3.9.12
2023-04-25 15:51:21,147:INFO:python_build: ('main', 'Apr  4 2022 05:22:27')
2023-04-25 15:51:21,147:INFO:machine: AMD64
2023-04-25 15:51:21,148:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-25 15:51:21,148:INFO:Memory: svmem(total=8362713088, available=511098880, percent=93.9, used=7851614208, free=511098880)
2023-04-25 15:51:21,148:INFO:Physical Core: 4
2023-04-25 15:51:21,148:INFO:Logical Core: 8
2023-04-25 15:51:21,148:INFO:Checking libraries
2023-04-25 15:51:21,148:INFO:System:
2023-04-25 15:51:21,148:INFO:    python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]
2023-04-25 15:51:21,148:INFO:executable: C:\Users\91888\anaconda3\python.exe
2023-04-25 15:51:21,148:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-25 15:51:21,149:INFO:PyCaret required dependencies:
2023-04-25 15:51:21,149:INFO:                 pip: 21.2.4
2023-04-25 15:51:21,149:INFO:          setuptools: 61.2.0
2023-04-25 15:51:21,149:INFO:             pycaret: 3.0.0
2023-04-25 15:51:21,149:INFO:             IPython: 8.2.0
2023-04-25 15:51:21,149:INFO:          ipywidgets: 7.6.5
2023-04-25 15:51:21,149:INFO:                tqdm: 4.64.0
2023-04-25 15:51:21,149:INFO:               numpy: 1.21.5
2023-04-25 15:51:21,149:INFO:              pandas: 1.4.2
2023-04-25 15:51:21,149:INFO:              jinja2: 2.11.3
2023-04-25 15:51:21,150:INFO:               scipy: 1.7.3
2023-04-25 15:51:21,150:INFO:              joblib: 1.2.0
2023-04-25 15:51:21,150:INFO:             sklearn: 1.0.2
2023-04-25 15:51:21,150:INFO:                pyod: 1.0.9
2023-04-25 15:51:21,150:INFO:            imblearn: 0.10.1
2023-04-25 15:51:21,150:INFO:   category_encoders: 2.6.0
2023-04-25 15:51:21,150:INFO:            lightgbm: 3.3.5
2023-04-25 15:51:21,150:INFO:               numba: 0.55.1
2023-04-25 15:51:21,150:INFO:            requests: 2.27.1
2023-04-25 15:51:21,150:INFO:          matplotlib: 3.5.1
2023-04-25 15:51:21,150:INFO:          scikitplot: 0.3.7
2023-04-25 15:51:21,151:INFO:         yellowbrick: 1.5
2023-04-25 15:51:21,151:INFO:              plotly: 5.6.0
2023-04-25 15:51:21,151:INFO:             kaleido: 0.2.1
2023-04-25 15:51:21,151:INFO:         statsmodels: 0.13.2
2023-04-25 15:51:21,151:INFO:              sktime: 0.17.1
2023-04-25 15:51:21,151:INFO:               tbats: 1.1.3
2023-04-25 15:51:21,151:INFO:            pmdarima: 2.0.3
2023-04-25 15:51:21,151:INFO:              psutil: 5.9.5
2023-04-25 15:51:21,151:INFO:PyCaret optional dependencies:
2023-04-25 15:51:21,151:INFO:                shap: Not installed
2023-04-25 15:51:21,152:INFO:           interpret: Not installed
2023-04-25 15:51:21,152:INFO:                umap: Not installed
2023-04-25 15:51:21,152:INFO:    pandas_profiling: 4.1.2
2023-04-25 15:51:21,152:INFO:  explainerdashboard: Not installed
2023-04-25 15:51:21,152:INFO:             autoviz: Not installed
2023-04-25 15:51:21,152:INFO:           fairlearn: Not installed
2023-04-25 15:51:21,152:INFO:             xgboost: Not installed
2023-04-25 15:51:21,152:INFO:            catboost: Not installed
2023-04-25 15:51:21,152:INFO:              kmodes: Not installed
2023-04-25 15:51:21,152:INFO:             mlxtend: Not installed
2023-04-25 15:51:21,152:INFO:       statsforecast: Not installed
2023-04-25 15:51:21,152:INFO:        tune_sklearn: Not installed
2023-04-25 15:51:21,152:INFO:                 ray: Not installed
2023-04-25 15:51:21,152:INFO:            hyperopt: Not installed
2023-04-25 15:51:21,153:INFO:              optuna: Not installed
2023-04-25 15:51:21,153:INFO:               skopt: Not installed
2023-04-25 15:51:21,153:INFO:              mlflow: Not installed
2023-04-25 15:51:21,153:INFO:              gradio: Not installed
2023-04-25 15:51:21,153:INFO:             fastapi: Not installed
2023-04-25 15:51:21,153:INFO:             uvicorn: Not installed
2023-04-25 15:51:21,153:INFO:              m2cgen: Not installed
2023-04-25 15:51:21,153:INFO:           evidently: Not installed
2023-04-25 15:51:21,153:INFO:               fugue: Not installed
2023-04-25 15:51:21,153:INFO:           streamlit: 1.21.0
2023-04-25 15:51:21,153:INFO:             prophet: Not installed
2023-04-25 15:51:21,154:INFO:None
2023-04-25 15:51:21,154:INFO:Set up data.
2023-04-25 15:51:21,161:INFO:Set up train/test split.
2023-04-25 15:51:21,166:INFO:Set up index.
2023-04-25 15:51:21,166:INFO:Set up folding strategy.
2023-04-25 15:51:21,166:INFO:Assigning column types.
2023-04-25 15:51:21,172:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-25 15:51:21,172:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 15:51:21,183:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 15:51:21,195:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 15:51:21,335:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:51:21,448:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:51:21,450:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:21,450:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:21,451:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 15:51:21,464:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 15:51:21,476:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 15:51:21,621:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:51:21,737:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:51:21,738:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:21,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:21,739:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-25 15:51:21,749:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 15:51:21,772:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 15:51:21,914:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:51:22,041:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:51:22,042:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:22,043:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:22,056:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 15:51:22,069:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 15:51:22,213:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:51:22,326:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:51:22,328:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:22,328:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:22,329:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-25 15:51:22,353:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 15:51:22,508:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:51:22,638:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:51:22,638:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:22,639:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:22,663:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 15:51:22,829:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:51:22,945:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:51:22,948:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:22,948:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:22,949:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-25 15:51:23,124:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:51:23,244:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:51:23,246:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:23,247:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:23,420:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:51:23,535:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:51:23,536:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:23,537:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:23,538:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-25 15:51:23,719:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:51:23,834:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:23,835:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:24,018:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:51:24,140:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:24,140:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:24,141:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-25 15:51:24,435:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:24,436:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:24,739:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:24,740:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:24,743:INFO:Preparing preprocessing pipeline...
2023-04-25 15:51:24,743:INFO:Set up simple imputation.
2023-04-25 15:51:24,763:INFO:Finished creating preprocessing pipeline.
2023-04-25 15:51:24,769:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\91888\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Radio', 'Newspaper', 'Sales'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-04-25 15:51:24,769:INFO:Creating final display dataframe.
2023-04-25 15:51:24,893:INFO:Setup _display_container:                     Description             Value
0                    Session id              4711
1                        Target                TV
2                   Target type        Regression
3           Original data shape          (200, 4)
4        Transformed data shape          (200, 4)
5   Transformed train set shape          (140, 4)
6    Transformed test set shape           (60, 4)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              b2c2
2023-04-25 15:51:25,368:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:25,369:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:25,658:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:25,659:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:51:25,660:INFO:setup() successfully completed in 4.69s...............
2023-04-25 15:51:25,664:INFO:Initializing compare_models()
2023-04-25 15:51:25,666:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF2FF2D30>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000017CF2FF2D30>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-25 15:51:25,666:INFO:Checking exceptions
2023-04-25 15:51:25,670:INFO:Preparing display monitor
2023-04-25 15:51:25,677:INFO:Initializing Linear Regression
2023-04-25 15:51:25,677:INFO:Total runtime is 0.0 minutes
2023-04-25 15:51:25,678:INFO:SubProcess create_model() called ==================================
2023-04-25 15:51:25,678:INFO:Initializing create_model()
2023-04-25 15:51:25,678:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF2FF2D30>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2E0F4F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:51:25,678:INFO:Checking exceptions
2023-04-25 15:51:25,678:INFO:Importing libraries
2023-04-25 15:51:25,678:INFO:Copying training dataset
2023-04-25 15:51:25,685:INFO:Defining folds
2023-04-25 15:51:25,685:INFO:Declaring metric variables
2023-04-25 15:51:25,685:INFO:Importing untrained model
2023-04-25 15:51:25,686:INFO:Linear Regression Imported successfully
2023-04-25 15:51:25,687:INFO:Starting cross validation
2023-04-25 15:51:25,690:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:51:27,786:INFO:Calculating mean and std
2023-04-25 15:51:27,799:INFO:Creating metrics dataframe
2023-04-25 15:51:28,109:INFO:Uploading results into container
2023-04-25 15:51:28,111:INFO:Uploading model into container now
2023-04-25 15:51:28,112:INFO:_master_model_container: 1
2023-04-25 15:51:28,112:INFO:_display_container: 2
2023-04-25 15:51:28,113:INFO:LinearRegression(n_jobs=-1)
2023-04-25 15:51:28,113:INFO:create_model() successfully completed......................................
2023-04-25 15:51:28,331:INFO:SubProcess create_model() end ==================================
2023-04-25 15:51:28,331:INFO:Creating metrics dataframe
2023-04-25 15:51:28,341:INFO:Initializing Lasso Regression
2023-04-25 15:51:28,341:INFO:Total runtime is 0.04440008799235026 minutes
2023-04-25 15:51:28,341:INFO:SubProcess create_model() called ==================================
2023-04-25 15:51:28,342:INFO:Initializing create_model()
2023-04-25 15:51:28,342:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF2FF2D30>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2E0F4F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:51:28,342:INFO:Checking exceptions
2023-04-25 15:51:28,342:INFO:Importing libraries
2023-04-25 15:51:28,342:INFO:Copying training dataset
2023-04-25 15:51:28,349:INFO:Defining folds
2023-04-25 15:51:28,351:INFO:Declaring metric variables
2023-04-25 15:51:28,351:INFO:Importing untrained model
2023-04-25 15:51:28,352:INFO:Lasso Regression Imported successfully
2023-04-25 15:51:28,352:INFO:Starting cross validation
2023-04-25 15:51:28,354:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:51:30,379:INFO:Calculating mean and std
2023-04-25 15:51:30,381:INFO:Creating metrics dataframe
2023-04-25 15:51:30,667:INFO:Uploading results into container
2023-04-25 15:51:30,670:INFO:Uploading model into container now
2023-04-25 15:51:30,670:INFO:_master_model_container: 2
2023-04-25 15:51:30,671:INFO:_display_container: 2
2023-04-25 15:51:30,671:INFO:Lasso(random_state=4711)
2023-04-25 15:51:30,671:INFO:create_model() successfully completed......................................
2023-04-25 15:51:30,882:INFO:SubProcess create_model() end ==================================
2023-04-25 15:51:30,883:INFO:Creating metrics dataframe
2023-04-25 15:51:30,894:INFO:Initializing Ridge Regression
2023-04-25 15:51:30,894:INFO:Total runtime is 0.0869534174601237 minutes
2023-04-25 15:51:30,894:INFO:SubProcess create_model() called ==================================
2023-04-25 15:51:30,895:INFO:Initializing create_model()
2023-04-25 15:51:30,895:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF2FF2D30>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2E0F4F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:51:30,895:INFO:Checking exceptions
2023-04-25 15:51:30,896:INFO:Importing libraries
2023-04-25 15:51:30,896:INFO:Copying training dataset
2023-04-25 15:51:30,903:INFO:Defining folds
2023-04-25 15:51:30,903:INFO:Declaring metric variables
2023-04-25 15:51:30,904:INFO:Importing untrained model
2023-04-25 15:51:30,904:INFO:Ridge Regression Imported successfully
2023-04-25 15:51:30,905:INFO:Starting cross validation
2023-04-25 15:51:30,907:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:51:31,776:INFO:Calculating mean and std
2023-04-25 15:51:31,777:INFO:Creating metrics dataframe
2023-04-25 15:51:31,859:INFO:Uploading results into container
2023-04-25 15:51:31,860:INFO:Uploading model into container now
2023-04-25 15:51:31,860:INFO:_master_model_container: 3
2023-04-25 15:51:31,860:INFO:_display_container: 2
2023-04-25 15:51:31,860:INFO:Ridge(random_state=4711)
2023-04-25 15:51:31,860:INFO:create_model() successfully completed......................................
2023-04-25 15:51:31,978:INFO:SubProcess create_model() end ==================================
2023-04-25 15:51:31,978:INFO:Creating metrics dataframe
2023-04-25 15:51:31,981:INFO:Initializing Elastic Net
2023-04-25 15:51:31,981:INFO:Total runtime is 0.10506832997004191 minutes
2023-04-25 15:51:31,982:INFO:SubProcess create_model() called ==================================
2023-04-25 15:51:31,982:INFO:Initializing create_model()
2023-04-25 15:51:31,982:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF2FF2D30>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2E0F4F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:51:31,982:INFO:Checking exceptions
2023-04-25 15:51:31,982:INFO:Importing libraries
2023-04-25 15:51:31,982:INFO:Copying training dataset
2023-04-25 15:51:31,984:INFO:Defining folds
2023-04-25 15:51:31,984:INFO:Declaring metric variables
2023-04-25 15:51:31,984:INFO:Importing untrained model
2023-04-25 15:51:31,985:INFO:Elastic Net Imported successfully
2023-04-25 15:51:31,985:INFO:Starting cross validation
2023-04-25 15:51:31,985:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:51:32,618:INFO:Calculating mean and std
2023-04-25 15:51:32,619:INFO:Creating metrics dataframe
2023-04-25 15:51:32,706:INFO:Uploading results into container
2023-04-25 15:51:32,707:INFO:Uploading model into container now
2023-04-25 15:51:32,707:INFO:_master_model_container: 4
2023-04-25 15:51:32,708:INFO:_display_container: 2
2023-04-25 15:51:32,708:INFO:ElasticNet(random_state=4711)
2023-04-25 15:51:32,708:INFO:create_model() successfully completed......................................
2023-04-25 15:51:32,830:INFO:SubProcess create_model() end ==================================
2023-04-25 15:51:32,830:INFO:Creating metrics dataframe
2023-04-25 15:51:32,833:INFO:Initializing Least Angle Regression
2023-04-25 15:51:32,833:INFO:Total runtime is 0.11926973263422648 minutes
2023-04-25 15:51:32,834:INFO:SubProcess create_model() called ==================================
2023-04-25 15:51:32,834:INFO:Initializing create_model()
2023-04-25 15:51:32,834:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF2FF2D30>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2E0F4F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:51:32,834:INFO:Checking exceptions
2023-04-25 15:51:32,834:INFO:Importing libraries
2023-04-25 15:51:32,834:INFO:Copying training dataset
2023-04-25 15:51:32,836:INFO:Defining folds
2023-04-25 15:51:32,836:INFO:Declaring metric variables
2023-04-25 15:51:32,836:INFO:Importing untrained model
2023-04-25 15:51:32,836:INFO:Least Angle Regression Imported successfully
2023-04-25 15:51:32,836:INFO:Starting cross validation
2023-04-25 15:51:32,837:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:51:32,869:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:51:32,872:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:51:32,887:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:51:32,891:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:51:32,898:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:51:32,907:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:51:32,918:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:51:32,929:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:51:33,026:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:51:33,048:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:51:33,451:INFO:Calculating mean and std
2023-04-25 15:51:33,452:INFO:Creating metrics dataframe
2023-04-25 15:51:33,547:INFO:Uploading results into container
2023-04-25 15:51:33,548:INFO:Uploading model into container now
2023-04-25 15:51:33,548:INFO:_master_model_container: 5
2023-04-25 15:51:33,548:INFO:_display_container: 2
2023-04-25 15:51:33,548:INFO:Lars(random_state=4711)
2023-04-25 15:51:33,548:INFO:create_model() successfully completed......................................
2023-04-25 15:51:33,669:INFO:SubProcess create_model() end ==================================
2023-04-25 15:51:33,669:INFO:Creating metrics dataframe
2023-04-25 15:51:33,673:INFO:Initializing Lasso Least Angle Regression
2023-04-25 15:51:33,673:INFO:Total runtime is 0.1332682689030965 minutes
2023-04-25 15:51:33,674:INFO:SubProcess create_model() called ==================================
2023-04-25 15:51:33,674:INFO:Initializing create_model()
2023-04-25 15:51:33,674:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF2FF2D30>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2E0F4F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:51:33,674:INFO:Checking exceptions
2023-04-25 15:51:33,674:INFO:Importing libraries
2023-04-25 15:51:33,674:INFO:Copying training dataset
2023-04-25 15:51:33,677:INFO:Defining folds
2023-04-25 15:51:33,677:INFO:Declaring metric variables
2023-04-25 15:51:33,677:INFO:Importing untrained model
2023-04-25 15:51:33,677:INFO:Lasso Least Angle Regression Imported successfully
2023-04-25 15:51:33,677:INFO:Starting cross validation
2023-04-25 15:51:33,678:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:51:33,713:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:51:33,718:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:51:33,723:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:51:33,735:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:51:33,747:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:51:33,753:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:51:33,764:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:51:33,774:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:51:33,854:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:51:33,883:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-25 15:51:34,304:INFO:Calculating mean and std
2023-04-25 15:51:34,305:INFO:Creating metrics dataframe
2023-04-25 15:51:34,393:INFO:Uploading results into container
2023-04-25 15:51:34,393:INFO:Uploading model into container now
2023-04-25 15:51:34,394:INFO:_master_model_container: 6
2023-04-25 15:51:34,394:INFO:_display_container: 2
2023-04-25 15:51:34,394:INFO:LassoLars(random_state=4711)
2023-04-25 15:51:34,394:INFO:create_model() successfully completed......................................
2023-04-25 15:51:34,516:INFO:SubProcess create_model() end ==================================
2023-04-25 15:51:34,516:INFO:Creating metrics dataframe
2023-04-25 15:51:34,519:INFO:Initializing Orthogonal Matching Pursuit
2023-04-25 15:51:34,519:INFO:Total runtime is 0.14737116893132526 minutes
2023-04-25 15:51:34,520:INFO:SubProcess create_model() called ==================================
2023-04-25 15:51:34,520:INFO:Initializing create_model()
2023-04-25 15:51:34,520:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF2FF2D30>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2E0F4F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:51:34,520:INFO:Checking exceptions
2023-04-25 15:51:34,520:INFO:Importing libraries
2023-04-25 15:51:34,520:INFO:Copying training dataset
2023-04-25 15:51:34,522:INFO:Defining folds
2023-04-25 15:51:34,523:INFO:Declaring metric variables
2023-04-25 15:51:34,523:INFO:Importing untrained model
2023-04-25 15:51:34,523:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-25 15:51:34,523:INFO:Starting cross validation
2023-04-25 15:51:34,524:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:51:34,557:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:51:34,565:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:51:34,573:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:51:34,583:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:51:34,587:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:51:34,599:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:51:34,610:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:51:34,626:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:51:34,728:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:51:34,735:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 15:51:35,240:INFO:Calculating mean and std
2023-04-25 15:51:35,242:INFO:Creating metrics dataframe
2023-04-25 15:51:35,365:INFO:Uploading results into container
2023-04-25 15:51:35,366:INFO:Uploading model into container now
2023-04-25 15:51:35,366:INFO:_master_model_container: 7
2023-04-25 15:51:35,366:INFO:_display_container: 2
2023-04-25 15:51:35,368:INFO:OrthogonalMatchingPursuit()
2023-04-25 15:51:35,368:INFO:create_model() successfully completed......................................
2023-04-25 15:51:35,496:INFO:SubProcess create_model() end ==================================
2023-04-25 15:51:35,496:INFO:Creating metrics dataframe
2023-04-25 15:51:35,499:INFO:Initializing Bayesian Ridge
2023-04-25 15:51:35,499:INFO:Total runtime is 0.16371246178944904 minutes
2023-04-25 15:51:35,499:INFO:SubProcess create_model() called ==================================
2023-04-25 15:51:35,499:INFO:Initializing create_model()
2023-04-25 15:51:35,499:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF2FF2D30>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2E0F4F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:51:35,499:INFO:Checking exceptions
2023-04-25 15:51:35,500:INFO:Importing libraries
2023-04-25 15:51:35,500:INFO:Copying training dataset
2023-04-25 15:51:35,502:INFO:Defining folds
2023-04-25 15:51:35,502:INFO:Declaring metric variables
2023-04-25 15:51:35,502:INFO:Importing untrained model
2023-04-25 15:51:35,502:INFO:Bayesian Ridge Imported successfully
2023-04-25 15:51:35,502:INFO:Starting cross validation
2023-04-25 15:51:35,503:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:51:36,153:INFO:Calculating mean and std
2023-04-25 15:51:36,153:INFO:Creating metrics dataframe
2023-04-25 15:51:36,234:INFO:Uploading results into container
2023-04-25 15:51:36,235:INFO:Uploading model into container now
2023-04-25 15:51:36,235:INFO:_master_model_container: 8
2023-04-25 15:51:36,235:INFO:_display_container: 2
2023-04-25 15:51:36,235:INFO:BayesianRidge()
2023-04-25 15:51:36,235:INFO:create_model() successfully completed......................................
2023-04-25 15:51:36,356:INFO:SubProcess create_model() end ==================================
2023-04-25 15:51:36,358:INFO:Creating metrics dataframe
2023-04-25 15:51:36,361:INFO:Initializing Passive Aggressive Regressor
2023-04-25 15:51:36,361:INFO:Total runtime is 0.1780725280443827 minutes
2023-04-25 15:51:36,361:INFO:SubProcess create_model() called ==================================
2023-04-25 15:51:36,361:INFO:Initializing create_model()
2023-04-25 15:51:36,361:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF2FF2D30>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2E0F4F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:51:36,361:INFO:Checking exceptions
2023-04-25 15:51:36,361:INFO:Importing libraries
2023-04-25 15:51:36,361:INFO:Copying training dataset
2023-04-25 15:51:36,363:INFO:Defining folds
2023-04-25 15:51:36,363:INFO:Declaring metric variables
2023-04-25 15:51:36,363:INFO:Importing untrained model
2023-04-25 15:51:36,364:INFO:Passive Aggressive Regressor Imported successfully
2023-04-25 15:51:36,364:INFO:Starting cross validation
2023-04-25 15:51:36,364:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:51:36,979:INFO:Calculating mean and std
2023-04-25 15:51:36,980:INFO:Creating metrics dataframe
2023-04-25 15:51:37,069:INFO:Uploading results into container
2023-04-25 15:51:37,070:INFO:Uploading model into container now
2023-04-25 15:51:37,070:INFO:_master_model_container: 9
2023-04-25 15:51:37,070:INFO:_display_container: 2
2023-04-25 15:51:37,071:INFO:PassiveAggressiveRegressor(random_state=4711)
2023-04-25 15:51:37,071:INFO:create_model() successfully completed......................................
2023-04-25 15:51:37,187:INFO:SubProcess create_model() end ==================================
2023-04-25 15:51:37,187:INFO:Creating metrics dataframe
2023-04-25 15:51:37,192:INFO:Initializing Huber Regressor
2023-04-25 15:51:37,192:INFO:Total runtime is 0.19191955327987667 minutes
2023-04-25 15:51:37,192:INFO:SubProcess create_model() called ==================================
2023-04-25 15:51:37,192:INFO:Initializing create_model()
2023-04-25 15:51:37,193:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF2FF2D30>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2E0F4F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:51:37,193:INFO:Checking exceptions
2023-04-25 15:51:37,193:INFO:Importing libraries
2023-04-25 15:51:37,193:INFO:Copying training dataset
2023-04-25 15:51:37,195:INFO:Defining folds
2023-04-25 15:51:37,195:INFO:Declaring metric variables
2023-04-25 15:51:37,195:INFO:Importing untrained model
2023-04-25 15:51:37,195:INFO:Huber Regressor Imported successfully
2023-04-25 15:51:37,195:INFO:Starting cross validation
2023-04-25 15:51:37,196:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:51:37,819:INFO:Calculating mean and std
2023-04-25 15:51:37,820:INFO:Creating metrics dataframe
2023-04-25 15:51:37,919:INFO:Uploading results into container
2023-04-25 15:51:37,920:INFO:Uploading model into container now
2023-04-25 15:51:37,920:INFO:_master_model_container: 10
2023-04-25 15:51:37,920:INFO:_display_container: 2
2023-04-25 15:51:37,920:INFO:HuberRegressor()
2023-04-25 15:51:37,920:INFO:create_model() successfully completed......................................
2023-04-25 15:51:38,039:INFO:SubProcess create_model() end ==================================
2023-04-25 15:51:38,039:INFO:Creating metrics dataframe
2023-04-25 15:51:38,043:INFO:Initializing K Neighbors Regressor
2023-04-25 15:51:38,043:INFO:Total runtime is 0.2061117887496948 minutes
2023-04-25 15:51:38,043:INFO:SubProcess create_model() called ==================================
2023-04-25 15:51:38,043:INFO:Initializing create_model()
2023-04-25 15:51:38,044:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF2FF2D30>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2E0F4F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:51:38,044:INFO:Checking exceptions
2023-04-25 15:51:38,044:INFO:Importing libraries
2023-04-25 15:51:38,044:INFO:Copying training dataset
2023-04-25 15:51:38,047:INFO:Defining folds
2023-04-25 15:51:38,047:INFO:Declaring metric variables
2023-04-25 15:51:38,047:INFO:Importing untrained model
2023-04-25 15:51:38,047:INFO:K Neighbors Regressor Imported successfully
2023-04-25 15:51:38,047:INFO:Starting cross validation
2023-04-25 15:51:38,048:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:51:38,673:INFO:Calculating mean and std
2023-04-25 15:51:38,674:INFO:Creating metrics dataframe
2023-04-25 15:51:38,790:INFO:Uploading results into container
2023-04-25 15:51:38,790:INFO:Uploading model into container now
2023-04-25 15:51:38,790:INFO:_master_model_container: 11
2023-04-25 15:51:38,791:INFO:_display_container: 2
2023-04-25 15:51:38,791:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-25 15:51:38,791:INFO:create_model() successfully completed......................................
2023-04-25 15:51:38,912:INFO:SubProcess create_model() end ==================================
2023-04-25 15:51:38,912:INFO:Creating metrics dataframe
2023-04-25 15:51:38,915:INFO:Initializing Decision Tree Regressor
2023-04-25 15:51:38,915:INFO:Total runtime is 0.2206428527832031 minutes
2023-04-25 15:51:38,915:INFO:SubProcess create_model() called ==================================
2023-04-25 15:51:38,915:INFO:Initializing create_model()
2023-04-25 15:51:38,916:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF2FF2D30>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2E0F4F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:51:38,916:INFO:Checking exceptions
2023-04-25 15:51:38,916:INFO:Importing libraries
2023-04-25 15:51:38,916:INFO:Copying training dataset
2023-04-25 15:51:38,919:INFO:Defining folds
2023-04-25 15:51:38,919:INFO:Declaring metric variables
2023-04-25 15:51:38,919:INFO:Importing untrained model
2023-04-25 15:51:38,920:INFO:Decision Tree Regressor Imported successfully
2023-04-25 15:51:38,920:INFO:Starting cross validation
2023-04-25 15:51:38,921:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:51:39,550:INFO:Calculating mean and std
2023-04-25 15:51:39,551:INFO:Creating metrics dataframe
2023-04-25 15:51:39,645:INFO:Uploading results into container
2023-04-25 15:51:39,646:INFO:Uploading model into container now
2023-04-25 15:51:39,646:INFO:_master_model_container: 12
2023-04-25 15:51:39,646:INFO:_display_container: 2
2023-04-25 15:51:39,646:INFO:DecisionTreeRegressor(random_state=4711)
2023-04-25 15:51:39,646:INFO:create_model() successfully completed......................................
2023-04-25 15:51:39,771:INFO:SubProcess create_model() end ==================================
2023-04-25 15:51:39,771:INFO:Creating metrics dataframe
2023-04-25 15:51:39,775:INFO:Initializing Random Forest Regressor
2023-04-25 15:51:39,775:INFO:Total runtime is 0.23497007290522254 minutes
2023-04-25 15:51:39,775:INFO:SubProcess create_model() called ==================================
2023-04-25 15:51:39,775:INFO:Initializing create_model()
2023-04-25 15:51:39,775:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF2FF2D30>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2E0F4F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:51:39,775:INFO:Checking exceptions
2023-04-25 15:51:39,776:INFO:Importing libraries
2023-04-25 15:51:39,776:INFO:Copying training dataset
2023-04-25 15:51:39,777:INFO:Defining folds
2023-04-25 15:51:39,777:INFO:Declaring metric variables
2023-04-25 15:51:39,778:INFO:Importing untrained model
2023-04-25 15:51:39,778:INFO:Random Forest Regressor Imported successfully
2023-04-25 15:51:39,778:INFO:Starting cross validation
2023-04-25 15:51:39,778:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:51:40,884:INFO:Calculating mean and std
2023-04-25 15:51:40,886:INFO:Creating metrics dataframe
2023-04-25 15:51:40,989:INFO:Uploading results into container
2023-04-25 15:51:40,990:INFO:Uploading model into container now
2023-04-25 15:51:40,990:INFO:_master_model_container: 13
2023-04-25 15:51:40,990:INFO:_display_container: 2
2023-04-25 15:51:40,990:INFO:RandomForestRegressor(n_jobs=-1, random_state=4711)
2023-04-25 15:51:40,990:INFO:create_model() successfully completed......................................
2023-04-25 15:51:41,111:INFO:SubProcess create_model() end ==================================
2023-04-25 15:51:41,112:INFO:Creating metrics dataframe
2023-04-25 15:51:41,115:INFO:Initializing Extra Trees Regressor
2023-04-25 15:51:41,115:INFO:Total runtime is 0.25730872551600137 minutes
2023-04-25 15:51:41,115:INFO:SubProcess create_model() called ==================================
2023-04-25 15:51:41,115:INFO:Initializing create_model()
2023-04-25 15:51:41,115:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF2FF2D30>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2E0F4F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:51:41,115:INFO:Checking exceptions
2023-04-25 15:51:41,115:INFO:Importing libraries
2023-04-25 15:51:41,115:INFO:Copying training dataset
2023-04-25 15:51:41,118:INFO:Defining folds
2023-04-25 15:51:41,118:INFO:Declaring metric variables
2023-04-25 15:51:41,118:INFO:Importing untrained model
2023-04-25 15:51:41,118:INFO:Extra Trees Regressor Imported successfully
2023-04-25 15:51:41,118:INFO:Starting cross validation
2023-04-25 15:51:41,119:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:51:42,078:INFO:Calculating mean and std
2023-04-25 15:51:42,078:INFO:Creating metrics dataframe
2023-04-25 15:51:42,161:INFO:Uploading results into container
2023-04-25 15:51:42,162:INFO:Uploading model into container now
2023-04-25 15:51:42,162:INFO:_master_model_container: 14
2023-04-25 15:51:42,162:INFO:_display_container: 2
2023-04-25 15:51:42,162:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=4711)
2023-04-25 15:51:42,163:INFO:create_model() successfully completed......................................
2023-04-25 15:51:42,280:INFO:SubProcess create_model() end ==================================
2023-04-25 15:51:42,280:INFO:Creating metrics dataframe
2023-04-25 15:51:42,283:INFO:Initializing AdaBoost Regressor
2023-04-25 15:51:42,283:INFO:Total runtime is 0.2767689267794291 minutes
2023-04-25 15:51:42,283:INFO:SubProcess create_model() called ==================================
2023-04-25 15:51:42,283:INFO:Initializing create_model()
2023-04-25 15:51:42,283:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF2FF2D30>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2E0F4F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:51:42,283:INFO:Checking exceptions
2023-04-25 15:51:42,283:INFO:Importing libraries
2023-04-25 15:51:42,283:INFO:Copying training dataset
2023-04-25 15:51:42,286:INFO:Defining folds
2023-04-25 15:51:42,286:INFO:Declaring metric variables
2023-04-25 15:51:42,286:INFO:Importing untrained model
2023-04-25 15:51:42,286:INFO:AdaBoost Regressor Imported successfully
2023-04-25 15:51:42,286:INFO:Starting cross validation
2023-04-25 15:51:42,287:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:51:43,018:INFO:Calculating mean and std
2023-04-25 15:51:43,019:INFO:Creating metrics dataframe
2023-04-25 15:51:43,110:INFO:Uploading results into container
2023-04-25 15:51:43,111:INFO:Uploading model into container now
2023-04-25 15:51:43,112:INFO:_master_model_container: 15
2023-04-25 15:51:43,112:INFO:_display_container: 2
2023-04-25 15:51:43,112:INFO:AdaBoostRegressor(random_state=4711)
2023-04-25 15:51:43,113:INFO:create_model() successfully completed......................................
2023-04-25 15:51:43,237:INFO:SubProcess create_model() end ==================================
2023-04-25 15:51:43,238:INFO:Creating metrics dataframe
2023-04-25 15:51:43,245:INFO:Initializing Gradient Boosting Regressor
2023-04-25 15:51:43,245:INFO:Total runtime is 0.29280077616373695 minutes
2023-04-25 15:51:43,245:INFO:SubProcess create_model() called ==================================
2023-04-25 15:51:43,246:INFO:Initializing create_model()
2023-04-25 15:51:43,246:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF2FF2D30>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2E0F4F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:51:43,246:INFO:Checking exceptions
2023-04-25 15:51:43,246:INFO:Importing libraries
2023-04-25 15:51:43,246:INFO:Copying training dataset
2023-04-25 15:51:43,248:INFO:Defining folds
2023-04-25 15:51:43,249:INFO:Declaring metric variables
2023-04-25 15:51:43,249:INFO:Importing untrained model
2023-04-25 15:51:43,249:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 15:51:43,249:INFO:Starting cross validation
2023-04-25 15:51:43,250:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:51:43,973:INFO:Calculating mean and std
2023-04-25 15:51:43,974:INFO:Creating metrics dataframe
2023-04-25 15:51:44,064:INFO:Uploading results into container
2023-04-25 15:51:44,064:INFO:Uploading model into container now
2023-04-25 15:51:44,065:INFO:_master_model_container: 16
2023-04-25 15:51:44,065:INFO:_display_container: 2
2023-04-25 15:51:44,065:INFO:GradientBoostingRegressor(random_state=4711)
2023-04-25 15:51:44,065:INFO:create_model() successfully completed......................................
2023-04-25 15:51:44,184:INFO:SubProcess create_model() end ==================================
2023-04-25 15:51:44,184:INFO:Creating metrics dataframe
2023-04-25 15:51:44,187:INFO:Initializing Light Gradient Boosting Machine
2023-04-25 15:51:44,187:INFO:Total runtime is 0.30850220123926797 minutes
2023-04-25 15:51:44,187:INFO:SubProcess create_model() called ==================================
2023-04-25 15:51:44,188:INFO:Initializing create_model()
2023-04-25 15:51:44,188:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF2FF2D30>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2E0F4F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:51:44,188:INFO:Checking exceptions
2023-04-25 15:51:44,188:INFO:Importing libraries
2023-04-25 15:51:44,188:INFO:Copying training dataset
2023-04-25 15:51:44,190:INFO:Defining folds
2023-04-25 15:51:44,190:INFO:Declaring metric variables
2023-04-25 15:51:44,190:INFO:Importing untrained model
2023-04-25 15:51:44,191:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 15:51:44,191:INFO:Starting cross validation
2023-04-25 15:51:44,192:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:51:44,863:INFO:Calculating mean and std
2023-04-25 15:51:44,864:INFO:Creating metrics dataframe
2023-04-25 15:51:44,958:INFO:Uploading results into container
2023-04-25 15:51:44,959:INFO:Uploading model into container now
2023-04-25 15:51:44,959:INFO:_master_model_container: 17
2023-04-25 15:51:44,959:INFO:_display_container: 2
2023-04-25 15:51:44,960:INFO:LGBMRegressor(random_state=4711)
2023-04-25 15:51:44,960:INFO:create_model() successfully completed......................................
2023-04-25 15:51:45,080:INFO:SubProcess create_model() end ==================================
2023-04-25 15:51:45,080:INFO:Creating metrics dataframe
2023-04-25 15:51:45,084:INFO:Initializing Dummy Regressor
2023-04-25 15:51:45,084:INFO:Total runtime is 0.3234508593877156 minutes
2023-04-25 15:51:45,084:INFO:SubProcess create_model() called ==================================
2023-04-25 15:51:45,084:INFO:Initializing create_model()
2023-04-25 15:51:45,084:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF2FF2D30>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CF2E0F4F0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:51:45,084:INFO:Checking exceptions
2023-04-25 15:51:45,084:INFO:Importing libraries
2023-04-25 15:51:45,084:INFO:Copying training dataset
2023-04-25 15:51:45,086:INFO:Defining folds
2023-04-25 15:51:45,086:INFO:Declaring metric variables
2023-04-25 15:51:45,086:INFO:Importing untrained model
2023-04-25 15:51:45,086:INFO:Dummy Regressor Imported successfully
2023-04-25 15:51:45,086:INFO:Starting cross validation
2023-04-25 15:51:45,086:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 15:51:45,774:INFO:Calculating mean and std
2023-04-25 15:51:45,775:INFO:Creating metrics dataframe
2023-04-25 15:51:45,858:INFO:Uploading results into container
2023-04-25 15:51:45,858:INFO:Uploading model into container now
2023-04-25 15:51:45,859:INFO:_master_model_container: 18
2023-04-25 15:51:45,859:INFO:_display_container: 2
2023-04-25 15:51:45,859:INFO:DummyRegressor()
2023-04-25 15:51:45,859:INFO:create_model() successfully completed......................................
2023-04-25 15:51:45,980:INFO:SubProcess create_model() end ==================================
2023-04-25 15:51:45,980:INFO:Creating metrics dataframe
2023-04-25 15:51:45,986:INFO:Initializing create_model()
2023-04-25 15:51:45,986:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF2FF2D30>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=4711), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 15:51:45,986:INFO:Checking exceptions
2023-04-25 15:51:45,987:INFO:Importing libraries
2023-04-25 15:51:45,987:INFO:Copying training dataset
2023-04-25 15:51:45,989:INFO:Defining folds
2023-04-25 15:51:45,989:INFO:Declaring metric variables
2023-04-25 15:51:45,989:INFO:Importing untrained model
2023-04-25 15:51:45,989:INFO:Declaring custom model
2023-04-25 15:51:45,989:INFO:Extra Trees Regressor Imported successfully
2023-04-25 15:51:45,990:INFO:Cross validation set to False
2023-04-25 15:51:45,990:INFO:Fitting Model
2023-04-25 15:51:46,121:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=4711)
2023-04-25 15:51:46,121:INFO:create_model() successfully completed......................................
2023-04-25 15:51:46,269:INFO:_master_model_container: 18
2023-04-25 15:51:46,270:INFO:_display_container: 2
2023-04-25 15:51:46,270:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=4711)
2023-04-25 15:51:46,270:INFO:compare_models() successfully completed......................................
2023-04-25 15:51:46,274:INFO:Initializing save_model()
2023-04-25 15:51:46,275:INFO:save_model(model=ExtraTreesRegressor(n_jobs=-1, random_state=4711), model_name=best_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\91888\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Radio', 'Newspaper', 'Sales'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-04-25 15:51:46,275:INFO:Adding model into prep_pipe
2023-04-25 15:51:46,300:INFO:best_model.pkl saved in current working directory
2023-04-25 15:51:46,304:INFO:Pipeline(memory=FastMemory(location=C:\Users\91888\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Radio', 'Newspaper', 'Sales'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('trained_model',
                 ExtraTreesRegressor(n_jobs=-1, random_state=4711))])
2023-04-25 15:51:46,304:INFO:save_model() successfully completed......................................
2023-04-25 15:51:46,491:INFO:Initializing plot_model()
2023-04-25 15:51:46,491:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=4711), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017CF2FF2D30>, system=True)
2023-04-25 15:51:46,491:INFO:Checking exceptions
2023-04-25 15:51:46,502:INFO:Preloading libraries
2023-04-25 15:51:46,508:INFO:Copying training dataset
2023-04-25 15:51:46,508:INFO:Plot type: residuals
2023-04-25 15:51:46,560:INFO:Fitting Model
2023-04-25 15:51:46,560:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2023-04-25 15:51:46,607:INFO:Scoring test/hold-out set
2023-04-25 15:51:46,663:WARNING:C:\Users\91888\anaconda3\lib\site-packages\yellowbrick\base.py:246: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()

2023-04-25 15:51:46,689:INFO:Visual Rendered Successfully
2023-04-25 15:51:46,813:INFO:plot_model() successfully completed......................................
2023-04-25 20:19:12,563:INFO:PyCaret ClassificationExperiment
2023-04-25 20:19:12,563:INFO:Logging name: clf-default-name
2023-04-25 20:19:12,563:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-25 20:19:12,563:INFO:version 3.0.0
2023-04-25 20:19:12,563:INFO:Initializing setup()
2023-04-25 20:19:12,563:INFO:self.USI: 40e1
2023-04-25 20:19:12,563:INFO:self._variable_keys: {'html_param', '_ml_usecase', 'X_test', 'n_jobs_param', 'exp_name_log', 'memory', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param', 'USI', 'seed', 'X_train', 'X', 'gpu_param', 'pipeline', 'target_param', 'fix_imbalance', 'data', 'idx', 'fold_groups_param', 'y_train', 'fold_shuffle_param', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_id', 'is_multiclass'}
2023-04-25 20:19:12,563:INFO:Checking environment
2023-04-25 20:19:12,563:INFO:python_version: 3.9.12
2023-04-25 20:19:12,563:INFO:python_build: ('main', 'Apr  4 2022 05:22:27')
2023-04-25 20:19:12,563:INFO:machine: AMD64
2023-04-25 20:19:12,563:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-25 20:19:12,564:INFO:Memory: svmem(total=8362713088, available=660561920, percent=92.1, used=7702151168, free=660561920)
2023-04-25 20:19:12,564:INFO:Physical Core: 4
2023-04-25 20:19:12,564:INFO:Logical Core: 8
2023-04-25 20:19:12,564:INFO:Checking libraries
2023-04-25 20:19:12,564:INFO:System:
2023-04-25 20:19:12,564:INFO:    python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]
2023-04-25 20:19:12,564:INFO:executable: C:\Users\91888\anaconda3\python.exe
2023-04-25 20:19:12,564:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-25 20:19:12,564:INFO:PyCaret required dependencies:
2023-04-25 20:19:12,565:INFO:                 pip: 21.2.4
2023-04-25 20:19:12,565:INFO:          setuptools: 61.2.0
2023-04-25 20:19:12,565:INFO:             pycaret: 3.0.0
2023-04-25 20:19:12,565:INFO:             IPython: 8.2.0
2023-04-25 20:19:12,565:INFO:          ipywidgets: 7.6.5
2023-04-25 20:19:12,565:INFO:                tqdm: 4.64.0
2023-04-25 20:19:12,565:INFO:               numpy: 1.21.5
2023-04-25 20:19:12,565:INFO:              pandas: 1.4.2
2023-04-25 20:19:12,565:INFO:              jinja2: 2.11.3
2023-04-25 20:19:12,565:INFO:               scipy: 1.7.3
2023-04-25 20:19:12,566:INFO:              joblib: 1.2.0
2023-04-25 20:19:12,566:INFO:             sklearn: 1.0.2
2023-04-25 20:19:12,566:INFO:                pyod: 1.0.9
2023-04-25 20:19:12,566:INFO:            imblearn: 0.10.1
2023-04-25 20:19:12,566:INFO:   category_encoders: 2.6.0
2023-04-25 20:19:12,566:INFO:            lightgbm: 3.3.5
2023-04-25 20:19:12,566:INFO:               numba: 0.55.1
2023-04-25 20:19:12,566:INFO:            requests: 2.27.1
2023-04-25 20:19:12,566:INFO:          matplotlib: 3.5.1
2023-04-25 20:19:12,566:INFO:          scikitplot: 0.3.7
2023-04-25 20:19:12,566:INFO:         yellowbrick: 1.5
2023-04-25 20:19:12,566:INFO:              plotly: 5.6.0
2023-04-25 20:19:12,567:INFO:             kaleido: 0.2.1
2023-04-25 20:19:12,567:INFO:         statsmodels: 0.13.2
2023-04-25 20:19:12,567:INFO:              sktime: 0.17.1
2023-04-25 20:19:12,567:INFO:               tbats: 1.1.3
2023-04-25 20:19:12,567:INFO:            pmdarima: 2.0.3
2023-04-25 20:19:12,567:INFO:              psutil: 5.9.5
2023-04-25 20:19:12,567:INFO:PyCaret optional dependencies:
2023-04-25 20:19:12,567:INFO:                shap: Not installed
2023-04-25 20:19:12,567:INFO:           interpret: Not installed
2023-04-25 20:19:12,567:INFO:                umap: Not installed
2023-04-25 20:19:12,568:INFO:    pandas_profiling: 4.1.2
2023-04-25 20:19:12,568:INFO:  explainerdashboard: Not installed
2023-04-25 20:19:12,568:INFO:             autoviz: Not installed
2023-04-25 20:19:12,568:INFO:           fairlearn: Not installed
2023-04-25 20:19:12,568:INFO:             xgboost: Not installed
2023-04-25 20:19:12,568:INFO:            catboost: Not installed
2023-04-25 20:19:12,568:INFO:              kmodes: Not installed
2023-04-25 20:19:12,568:INFO:             mlxtend: Not installed
2023-04-25 20:19:12,568:INFO:       statsforecast: Not installed
2023-04-25 20:19:12,568:INFO:        tune_sklearn: Not installed
2023-04-25 20:19:12,569:INFO:                 ray: Not installed
2023-04-25 20:19:12,569:INFO:            hyperopt: Not installed
2023-04-25 20:19:12,569:INFO:              optuna: Not installed
2023-04-25 20:19:12,569:INFO:               skopt: Not installed
2023-04-25 20:19:12,569:INFO:              mlflow: Not installed
2023-04-25 20:19:12,569:INFO:              gradio: Not installed
2023-04-25 20:19:12,569:INFO:             fastapi: Not installed
2023-04-25 20:19:12,569:INFO:             uvicorn: Not installed
2023-04-25 20:19:12,569:INFO:              m2cgen: Not installed
2023-04-25 20:19:12,569:INFO:           evidently: Not installed
2023-04-25 20:19:12,569:INFO:               fugue: Not installed
2023-04-25 20:19:12,569:INFO:           streamlit: 1.21.0
2023-04-25 20:19:12,569:INFO:             prophet: Not installed
2023-04-25 20:19:12,569:INFO:None
2023-04-25 20:19:12,569:INFO:Set up data.
2023-04-25 20:19:12,600:INFO:Set up train/test split.
2023-04-25 20:19:23,531:INFO:PyCaret ClassificationExperiment
2023-04-25 20:19:23,531:INFO:Logging name: clf-default-name
2023-04-25 20:19:23,531:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-25 20:19:23,531:INFO:version 3.0.0
2023-04-25 20:19:23,531:INFO:Initializing setup()
2023-04-25 20:19:23,531:INFO:self.USI: 2592
2023-04-25 20:19:23,531:INFO:self._variable_keys: {'html_param', '_ml_usecase', 'X_test', 'n_jobs_param', 'exp_name_log', 'memory', 'gpu_n_jobs_param', '_available_plots', 'log_plots_param', 'USI', 'seed', 'X_train', 'X', 'gpu_param', 'pipeline', 'target_param', 'fix_imbalance', 'data', 'idx', 'fold_groups_param', 'y_train', 'fold_shuffle_param', 'y', 'fold_generator', 'logging_param', 'y_test', 'exp_id', 'is_multiclass'}
2023-04-25 20:19:23,531:INFO:Checking environment
2023-04-25 20:19:23,532:INFO:python_version: 3.9.12
2023-04-25 20:19:23,532:INFO:python_build: ('main', 'Apr  4 2022 05:22:27')
2023-04-25 20:19:23,532:INFO:machine: AMD64
2023-04-25 20:19:23,532:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-25 20:19:23,532:INFO:Memory: svmem(total=8362713088, available=650031104, percent=92.2, used=7712681984, free=650031104)
2023-04-25 20:19:23,532:INFO:Physical Core: 4
2023-04-25 20:19:23,532:INFO:Logical Core: 8
2023-04-25 20:19:23,532:INFO:Checking libraries
2023-04-25 20:19:23,532:INFO:System:
2023-04-25 20:19:23,533:INFO:    python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]
2023-04-25 20:19:23,533:INFO:executable: C:\Users\91888\anaconda3\python.exe
2023-04-25 20:19:23,533:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-25 20:19:23,533:INFO:PyCaret required dependencies:
2023-04-25 20:19:23,533:INFO:                 pip: 21.2.4
2023-04-25 20:19:23,533:INFO:          setuptools: 61.2.0
2023-04-25 20:19:23,533:INFO:             pycaret: 3.0.0
2023-04-25 20:19:23,533:INFO:             IPython: 8.2.0
2023-04-25 20:19:23,533:INFO:          ipywidgets: 7.6.5
2023-04-25 20:19:23,533:INFO:                tqdm: 4.64.0
2023-04-25 20:19:23,533:INFO:               numpy: 1.21.5
2023-04-25 20:19:23,534:INFO:              pandas: 1.4.2
2023-04-25 20:19:23,534:INFO:              jinja2: 2.11.3
2023-04-25 20:19:23,534:INFO:               scipy: 1.7.3
2023-04-25 20:19:23,534:INFO:              joblib: 1.2.0
2023-04-25 20:19:23,534:INFO:             sklearn: 1.0.2
2023-04-25 20:19:23,534:INFO:                pyod: 1.0.9
2023-04-25 20:19:23,534:INFO:            imblearn: 0.10.1
2023-04-25 20:19:23,534:INFO:   category_encoders: 2.6.0
2023-04-25 20:19:23,534:INFO:            lightgbm: 3.3.5
2023-04-25 20:19:23,534:INFO:               numba: 0.55.1
2023-04-25 20:19:23,535:INFO:            requests: 2.27.1
2023-04-25 20:19:23,535:INFO:          matplotlib: 3.5.1
2023-04-25 20:19:23,535:INFO:          scikitplot: 0.3.7
2023-04-25 20:19:23,535:INFO:         yellowbrick: 1.5
2023-04-25 20:19:23,535:INFO:              plotly: 5.6.0
2023-04-25 20:19:23,535:INFO:             kaleido: 0.2.1
2023-04-25 20:19:23,535:INFO:         statsmodels: 0.13.2
2023-04-25 20:19:23,535:INFO:              sktime: 0.17.1
2023-04-25 20:19:23,535:INFO:               tbats: 1.1.3
2023-04-25 20:19:23,535:INFO:            pmdarima: 2.0.3
2023-04-25 20:19:23,535:INFO:              psutil: 5.9.5
2023-04-25 20:19:23,535:INFO:PyCaret optional dependencies:
2023-04-25 20:19:23,536:INFO:                shap: Not installed
2023-04-25 20:19:23,536:INFO:           interpret: Not installed
2023-04-25 20:19:23,536:INFO:                umap: Not installed
2023-04-25 20:19:23,536:INFO:    pandas_profiling: 4.1.2
2023-04-25 20:19:23,536:INFO:  explainerdashboard: Not installed
2023-04-25 20:19:23,536:INFO:             autoviz: Not installed
2023-04-25 20:19:23,536:INFO:           fairlearn: Not installed
2023-04-25 20:19:23,536:INFO:             xgboost: Not installed
2023-04-25 20:19:23,536:INFO:            catboost: Not installed
2023-04-25 20:19:23,537:INFO:              kmodes: Not installed
2023-04-25 20:19:23,537:INFO:             mlxtend: Not installed
2023-04-25 20:19:23,537:INFO:       statsforecast: Not installed
2023-04-25 20:19:23,537:INFO:        tune_sklearn: Not installed
2023-04-25 20:19:23,537:INFO:                 ray: Not installed
2023-04-25 20:19:23,537:INFO:            hyperopt: Not installed
2023-04-25 20:19:23,537:INFO:              optuna: Not installed
2023-04-25 20:19:23,537:INFO:               skopt: Not installed
2023-04-25 20:19:23,537:INFO:              mlflow: Not installed
2023-04-25 20:19:23,537:INFO:              gradio: Not installed
2023-04-25 20:19:23,537:INFO:             fastapi: Not installed
2023-04-25 20:19:23,537:INFO:             uvicorn: Not installed
2023-04-25 20:19:23,537:INFO:              m2cgen: Not installed
2023-04-25 20:19:23,537:INFO:           evidently: Not installed
2023-04-25 20:19:23,538:INFO:               fugue: Not installed
2023-04-25 20:19:23,538:INFO:           streamlit: 1.21.0
2023-04-25 20:19:23,538:INFO:             prophet: Not installed
2023-04-25 20:19:23,538:INFO:None
2023-04-25 20:19:23,538:INFO:Set up data.
2023-04-25 20:19:23,564:INFO:Set up train/test split.
2023-04-25 20:19:23,606:INFO:Set up index.
2023-04-25 20:19:23,607:INFO:Set up folding strategy.
2023-04-25 20:19:23,608:INFO:Assigning column types.
2023-04-25 20:19:23,616:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-25 20:19:23,760:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:19:23,763:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-25 20:19:23,832:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:19:23,832:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:19:24,003:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:19:24,006:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-25 20:19:24,100:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:19:24,101:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:19:24,102:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-25 20:19:24,239:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-25 20:19:24,332:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:19:24,333:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:19:24,479:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-25 20:19:24,569:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:19:24,570:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:19:24,571:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-25 20:19:24,821:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:19:24,822:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:19:25,083:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:19:25,084:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:19:25,088:INFO:Preparing preprocessing pipeline...
2023-04-25 20:19:25,094:INFO:Set up label encoding.
2023-04-25 20:19:25,094:INFO:Set up simple imputation.
2023-04-25 20:19:25,111:INFO:Set up encoding of ordinal features.
2023-04-25 20:19:25,138:INFO:Set up encoding of categorical features.
2023-04-25 20:19:25,912:INFO:Finished creating preprocessing pipeline.
2023-04-25 20:19:26,174:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\91888\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'age', 'bp', 'sg', 'al',
                                             'su', 'bgr', 'bu', 'sc', 'sod',
                                             'pot', 'hemo'],
                                    transformer=SimpleImputer(add_ind...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['pcv', 'wc', 'rc'],
                                    transformer=LeaveOneOutEncoder(cols=['pcv',
                                                                         'wc',
                                                                         'rc'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=4926,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0)))],
         verbose=False)
2023-04-25 20:19:26,176:INFO:Creating final display dataframe.
2023-04-25 20:19:27,758:INFO:Setup _display_container:                     Description                        Value
0                    Session id                         4926
1                        Target               classification
2                   Target type                   Multiclass
3                Target mapping  ckd: 0, ckd\t: 1, notckd: 2
4           Original data shape                    (400, 26)
5        Transformed data shape                    (400, 32)
6   Transformed train set shape                    (280, 32)
7    Transformed test set shape                    (120, 32)
8              Ordinal features                            8
9              Numeric features                           12
10         Categorical features                           13
11     Rows with missing values                        60.5%
12                   Preprocess                         True
13              Imputation type                       simple
14           Numeric imputation                         mean
15       Categorical imputation                         mode
16     Maximum one-hot encoding                           25
17              Encoding method                         None
18               Fold Generator              StratifiedKFold
19                  Fold Number                           10
20                     CPU Jobs                           -1
21                      Use GPU                        False
22               Log Experiment                        False
23              Experiment Name             clf-default-name
24                          USI                         2592
2023-04-25 20:19:27,983:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:19:27,984:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:19:28,194:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:19:28,194:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:19:28,197:INFO:setup() successfully completed in 4.84s...............
2023-04-25 20:19:28,218:INFO:Initializing compare_models()
2023-04-25 20:19:28,218:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CFD260760>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000017CFD260760>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-25 20:19:28,218:INFO:Checking exceptions
2023-04-25 20:19:28,226:INFO:Preparing display monitor
2023-04-25 20:19:28,236:INFO:Initializing Logistic Regression
2023-04-25 20:19:28,237:INFO:Total runtime is 1.6562143961588542e-05 minutes
2023-04-25 20:19:28,238:INFO:SubProcess create_model() called ==================================
2023-04-25 20:19:28,239:INFO:Initializing create_model()
2023-04-25 20:19:28,239:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CFD260760>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFAD73F40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:19:28,240:INFO:Checking exceptions
2023-04-25 20:19:28,240:INFO:Importing libraries
2023-04-25 20:19:28,240:INFO:Copying training dataset
2023-04-25 20:19:28,251:INFO:Defining folds
2023-04-25 20:19:28,251:INFO:Declaring metric variables
2023-04-25 20:19:28,252:INFO:Importing untrained model
2023-04-25 20:19:28,253:INFO:Logistic Regression Imported successfully
2023-04-25 20:19:28,253:INFO:Starting cross validation
2023-04-25 20:19:28,257:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 20:19:28,264:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning:

The least populated class in y has only 1 members, which is less than n_splits=10.


2023-04-25 20:19:36,524:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-25 20:19:36,524:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-25 20:19:36,524:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-25 20:19:36,531:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-25 20:19:36,569:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-25 20:19:36,572:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-25 20:19:36,604:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-25 20:19:36,628:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-25 20:19:37,628:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:37,628:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:37,630:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:37,632:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:37,638:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:37,661:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:37,685:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:37,726:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:37,761:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:37,762:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:37,764:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:37,767:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:37,768:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:37,768:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:37,769:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:37,769:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:37,770:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:37,770:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:37,771:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:37,771:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:37,771:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:37,773:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:37,774:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:37,774:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:37,775:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:37,775:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:37,776:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:37,777:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:37,777:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:37,777:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:37,779:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:37,779:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:37,779:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:37,780:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:37,781:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:37,783:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:37,783:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:37,785:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:37,794:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:37,798:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:37,801:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:37,803:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:37,805:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:37,805:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:37,807:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:37,809:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:37,810:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:37,813:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:37,815:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:37,817:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:37,819:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:37,822:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:37,830:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:37,833:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:37,836:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:37,838:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:37,839:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:37,841:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:37,844:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:39,579:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-04-25 20:19:39,834:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:39,835:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:39,838:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:39,839:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:39,840:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:40,466:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:40,467:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:40,469:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:40,470:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:40,471:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:40,483:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:40,485:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:40,489:INFO:Calculating mean and std
2023-04-25 20:19:40,492:INFO:Creating metrics dataframe
2023-04-25 20:19:40,785:INFO:Uploading results into container
2023-04-25 20:19:40,787:INFO:Uploading model into container now
2023-04-25 20:19:40,788:INFO:_master_model_container: 1
2023-04-25 20:19:40,788:INFO:_display_container: 2
2023-04-25 20:19:40,789:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4926, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-25 20:19:40,790:INFO:create_model() successfully completed......................................
2023-04-25 20:19:41,000:INFO:SubProcess create_model() end ==================================
2023-04-25 20:19:41,001:INFO:Creating metrics dataframe
2023-04-25 20:19:41,010:INFO:Initializing K Neighbors Classifier
2023-04-25 20:19:41,010:INFO:Total runtime is 0.21290359099706013 minutes
2023-04-25 20:19:41,011:INFO:SubProcess create_model() called ==================================
2023-04-25 20:19:41,011:INFO:Initializing create_model()
2023-04-25 20:19:41,011:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CFD260760>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFAD73F40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:19:41,012:INFO:Checking exceptions
2023-04-25 20:19:41,012:INFO:Importing libraries
2023-04-25 20:19:41,012:INFO:Copying training dataset
2023-04-25 20:19:41,022:INFO:Defining folds
2023-04-25 20:19:41,022:INFO:Declaring metric variables
2023-04-25 20:19:41,023:INFO:Importing untrained model
2023-04-25 20:19:41,023:INFO:K Neighbors Classifier Imported successfully
2023-04-25 20:19:41,024:INFO:Starting cross validation
2023-04-25 20:19:41,029:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 20:19:41,032:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning:

The least populated class in y has only 1 members, which is less than n_splits=10.


2023-04-25 20:19:42,845:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:42,871:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:42,876:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:42,881:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:42,900:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:43,028:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:43,028:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:43,029:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:43,030:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:43,031:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:43,033:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:43,033:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:43,035:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:43,036:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:43,037:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:43,038:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:43,039:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:43,040:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:43,040:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:43,043:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:43,043:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:43,045:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:43,045:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:43,047:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:43,048:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:43,049:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:43,050:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:43,051:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:43,053:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:43,053:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:43,055:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:43,056:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:43,059:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:43,086:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:43,088:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:43,088:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:43,089:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:43,090:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:43,090:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:43,092:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:43,092:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:43,094:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:43,095:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:43,096:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:43,096:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:43,097:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:43,098:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:43,140:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:43,185:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:43,378:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:43,381:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:43,382:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:43,383:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:43,384:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:43,385:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:43,386:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:43,387:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:43,388:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:43,389:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:43,390:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:43,391:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:43,392:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:44,856:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:44,857:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:44,860:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:44,861:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:44,863:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:44,875:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:44,876:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:44,879:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:44,880:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:44,881:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:44,882:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:44,884:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:45,241:INFO:Calculating mean and std
2023-04-25 20:19:45,244:INFO:Creating metrics dataframe
2023-04-25 20:19:45,529:INFO:Uploading results into container
2023-04-25 20:19:45,531:INFO:Uploading model into container now
2023-04-25 20:19:45,531:INFO:_master_model_container: 2
2023-04-25 20:19:45,532:INFO:_display_container: 2
2023-04-25 20:19:45,532:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-25 20:19:45,532:INFO:create_model() successfully completed......................................
2023-04-25 20:19:45,745:INFO:SubProcess create_model() end ==================================
2023-04-25 20:19:45,745:INFO:Creating metrics dataframe
2023-04-25 20:19:45,754:INFO:Initializing Naive Bayes
2023-04-25 20:19:45,754:INFO:Total runtime is 0.2919679760932922 minutes
2023-04-25 20:19:45,754:INFO:SubProcess create_model() called ==================================
2023-04-25 20:19:45,755:INFO:Initializing create_model()
2023-04-25 20:19:45,755:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CFD260760>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFAD73F40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:19:45,755:INFO:Checking exceptions
2023-04-25 20:19:45,755:INFO:Importing libraries
2023-04-25 20:19:45,755:INFO:Copying training dataset
2023-04-25 20:19:45,766:INFO:Defining folds
2023-04-25 20:19:45,766:INFO:Declaring metric variables
2023-04-25 20:19:45,766:INFO:Importing untrained model
2023-04-25 20:19:45,767:INFO:Naive Bayes Imported successfully
2023-04-25 20:19:45,767:INFO:Starting cross validation
2023-04-25 20:19:45,771:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 20:19:45,773:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning:

The least populated class in y has only 1 members, which is less than n_splits=10.


2023-04-25 20:19:47,545:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:47,612:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:47,651:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:47,654:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:47,655:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:47,657:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:47,659:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:47,659:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:47,660:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:47,660:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:47,662:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:47,662:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:47,665:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:47,665:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:47,667:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:47,671:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:47,672:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:47,675:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:47,683:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:47,685:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:47,687:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:47,689:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:47,692:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:47,694:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:47,696:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:47,697:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:47,698:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:47,698:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:47,699:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:47,701:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:47,702:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:47,703:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:47,704:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:47,706:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:47,708:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:47,708:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:47,710:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:47,710:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:47,713:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:47,755:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:47,756:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:47,757:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:47,758:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:47,760:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:47,761:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:47,764:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:47,782:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:47,784:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:47,786:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:47,786:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:47,788:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:47,789:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:47,790:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:47,792:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:47,794:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:47,795:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:47,797:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:47,799:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:47,801:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:47,802:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:49,377:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:49,377:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:49,378:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:49,379:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:49,380:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:49,380:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:49,381:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:49,382:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:49,382:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:49,383:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:49,384:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:49,385:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:49,841:INFO:Calculating mean and std
2023-04-25 20:19:49,843:INFO:Creating metrics dataframe
2023-04-25 20:19:50,159:INFO:Uploading results into container
2023-04-25 20:19:50,160:INFO:Uploading model into container now
2023-04-25 20:19:50,161:INFO:_master_model_container: 3
2023-04-25 20:19:50,161:INFO:_display_container: 2
2023-04-25 20:19:50,162:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-25 20:19:50,162:INFO:create_model() successfully completed......................................
2023-04-25 20:19:50,385:INFO:SubProcess create_model() end ==================================
2023-04-25 20:19:50,385:INFO:Creating metrics dataframe
2023-04-25 20:19:50,407:INFO:Initializing Decision Tree Classifier
2023-04-25 20:19:50,407:INFO:Total runtime is 0.36952090660730996 minutes
2023-04-25 20:19:50,408:INFO:SubProcess create_model() called ==================================
2023-04-25 20:19:50,408:INFO:Initializing create_model()
2023-04-25 20:19:50,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CFD260760>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFAD73F40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:19:50,408:INFO:Checking exceptions
2023-04-25 20:19:50,409:INFO:Importing libraries
2023-04-25 20:19:50,409:INFO:Copying training dataset
2023-04-25 20:19:50,419:INFO:Defining folds
2023-04-25 20:19:50,420:INFO:Declaring metric variables
2023-04-25 20:19:50,420:INFO:Importing untrained model
2023-04-25 20:19:50,421:INFO:Decision Tree Classifier Imported successfully
2023-04-25 20:19:50,422:INFO:Starting cross validation
2023-04-25 20:19:50,425:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 20:19:50,430:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning:

The least populated class in y has only 1 members, which is less than n_splits=10.


2023-04-25 20:19:52,191:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:52,198:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:52,217:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:52,222:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:52,223:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:52,237:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:52,240:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:52,280:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:52,316:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:52,317:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:52,319:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:52,320:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:52,321:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:52,322:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:52,323:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:52,325:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:52,326:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:52,326:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:52,327:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:52,327:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:52,329:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:52,331:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:52,348:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:52,351:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:52,351:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:52,353:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:52,353:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:52,355:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:52,356:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:52,358:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:52,359:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:52,361:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:52,361:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:52,363:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:52,363:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:52,365:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:52,366:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:52,367:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:52,370:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:52,371:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:52,374:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:52,374:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:52,375:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:52,376:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:52,376:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:52,377:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:52,379:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:52,379:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:52,380:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:52,381:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:52,382:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:52,383:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:52,384:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:52,385:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:52,385:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:52,386:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:52,388:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:52,389:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:52,389:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:52,390:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:52,393:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:54,339:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:54,339:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:54,340:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:54,342:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:54,344:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:54,347:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:19:54,348:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:54,349:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:54,350:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:54,352:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:54,353:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:54,751:INFO:Calculating mean and std
2023-04-25 20:19:54,753:INFO:Creating metrics dataframe
2023-04-25 20:19:55,127:INFO:Uploading results into container
2023-04-25 20:19:55,128:INFO:Uploading model into container now
2023-04-25 20:19:55,129:INFO:_master_model_container: 4
2023-04-25 20:19:55,129:INFO:_display_container: 2
2023-04-25 20:19:55,130:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4926, splitter='best')
2023-04-25 20:19:55,130:INFO:create_model() successfully completed......................................
2023-04-25 20:19:55,348:INFO:SubProcess create_model() end ==================================
2023-04-25 20:19:55,348:INFO:Creating metrics dataframe
2023-04-25 20:19:55,356:INFO:Initializing SVM - Linear Kernel
2023-04-25 20:19:55,357:INFO:Total runtime is 0.45202182133992513 minutes
2023-04-25 20:19:55,357:INFO:SubProcess create_model() called ==================================
2023-04-25 20:19:55,358:INFO:Initializing create_model()
2023-04-25 20:19:55,358:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CFD260760>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFAD73F40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:19:55,358:INFO:Checking exceptions
2023-04-25 20:19:55,358:INFO:Importing libraries
2023-04-25 20:19:55,358:INFO:Copying training dataset
2023-04-25 20:19:55,367:INFO:Defining folds
2023-04-25 20:19:55,367:INFO:Declaring metric variables
2023-04-25 20:19:55,369:INFO:Importing untrained model
2023-04-25 20:19:55,370:INFO:SVM - Linear Kernel Imported successfully
2023-04-25 20:19:55,370:INFO:Starting cross validation
2023-04-25 20:19:55,373:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 20:19:55,376:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning:

The least populated class in y has only 1 members, which is less than n_splits=10.


2023-04-25 20:19:57,240:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:57,241:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:57,247:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 20:19:57,250:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:57,251:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:57,253:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:57,255:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:57,257:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:57,259:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:57,259:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:57,260:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 20:19:57,262:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:57,268:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:57,270:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:57,272:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 20:19:57,272:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:57,274:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:57,274:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:57,276:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:57,278:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:57,281:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:57,283:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:57,285:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:57,288:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:57,290:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:57,308:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:57,308:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 20:19:57,311:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:57,314:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:57,315:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:57,318:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:57,319:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:57,321:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:57,325:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:57,337:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:57,343:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 20:19:57,345:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 20:19:57,346:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:57,347:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:57,349:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:57,349:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:57,350:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:19:57,351:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:57,351:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:57,353:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:57,354:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:57,355:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:57,355:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:57,357:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:57,358:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:57,364:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 20:19:57,367:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:57,369:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:57,371:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:57,372:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:57,373:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:57,374:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 20:19:57,376:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:57,376:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:57,379:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:57,381:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:57,383:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:57,385:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:57,388:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:59,044:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 20:19:59,046:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:59,048:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:59,049:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:59,051:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:59,052:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:59,054:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:19:59,086:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-25 20:19:59,089:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:59,091:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:59,092:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:19:59,094:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:19:59,635:INFO:Calculating mean and std
2023-04-25 20:19:59,637:INFO:Creating metrics dataframe
2023-04-25 20:19:59,983:INFO:Uploading results into container
2023-04-25 20:19:59,985:INFO:Uploading model into container now
2023-04-25 20:19:59,986:INFO:_master_model_container: 5
2023-04-25 20:19:59,986:INFO:_display_container: 2
2023-04-25 20:19:59,988:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=4926, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-25 20:19:59,988:INFO:create_model() successfully completed......................................
2023-04-25 20:20:00,204:INFO:SubProcess create_model() end ==================================
2023-04-25 20:20:00,205:INFO:Creating metrics dataframe
2023-04-25 20:20:00,214:INFO:Initializing Ridge Classifier
2023-04-25 20:20:00,215:INFO:Total runtime is 0.5329730232556661 minutes
2023-04-25 20:20:00,215:INFO:SubProcess create_model() called ==================================
2023-04-25 20:20:00,216:INFO:Initializing create_model()
2023-04-25 20:20:00,216:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CFD260760>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFAD73F40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:20:00,217:INFO:Checking exceptions
2023-04-25 20:20:00,217:INFO:Importing libraries
2023-04-25 20:20:00,217:INFO:Copying training dataset
2023-04-25 20:20:00,227:INFO:Defining folds
2023-04-25 20:20:00,227:INFO:Declaring metric variables
2023-04-25 20:20:00,228:INFO:Importing untrained model
2023-04-25 20:20:00,229:INFO:Ridge Classifier Imported successfully
2023-04-25 20:20:00,229:INFO:Starting cross validation
2023-04-25 20:20:00,233:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 20:20:00,235:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning:

The least populated class in y has only 1 members, which is less than n_splits=10.


2023-04-25 20:20:02,064:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:20:02,072:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 20:20:02,073:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:02,073:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:02,075:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:02,077:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:02,079:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:02,080:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:20:02,081:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:02,081:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:20:02,084:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 20:20:02,085:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:02,086:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:02,086:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 20:20:02,087:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:02,088:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

, msg_start, len(result))

2023-04-25 20:20:02,089:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

art, len(result))

2023-04-25 20:20:02,091:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:02,091:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:02,092:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:02,092:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:20:02,092:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:02,093:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:20:02,093:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:02,098:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 20:20:02,099:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:02,101:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:02,101:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 20:20:02,103:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:02,103:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:02,104:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:02,105:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:02,106:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:02,107:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:02,108:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:02,109:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:02,110:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:02,111:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:02,112:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:20:02,116:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 20:20:02,117:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:02,118:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:02,119:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:02,120:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:20:02,120:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:02,121:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:02,122:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:02,130:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 20:20:02,132:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:02,134:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:02,137:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:02,141:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:02,142:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:02,143:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:02,165:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:20:02,170:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 20:20:02,172:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:02,173:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:02,174:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:02,175:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:02,176:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:02,177:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:03,724:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 20:20:03,725:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:03,727:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:03,728:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:03,730:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:03,732:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:03,734:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:03,802:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-25 20:20:03,804:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:03,806:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:03,808:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:03,809:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:04,442:INFO:Calculating mean and std
2023-04-25 20:20:04,444:INFO:Creating metrics dataframe
2023-04-25 20:20:04,703:INFO:Uploading results into container
2023-04-25 20:20:04,705:INFO:Uploading model into container now
2023-04-25 20:20:04,706:INFO:_master_model_container: 6
2023-04-25 20:20:04,706:INFO:_display_container: 2
2023-04-25 20:20:04,706:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=4926, solver='auto', tol=0.001)
2023-04-25 20:20:04,706:INFO:create_model() successfully completed......................................
2023-04-25 20:20:04,895:INFO:SubProcess create_model() end ==================================
2023-04-25 20:20:04,895:INFO:Creating metrics dataframe
2023-04-25 20:20:04,901:INFO:Initializing Random Forest Classifier
2023-04-25 20:20:04,902:INFO:Total runtime is 0.6111044605573018 minutes
2023-04-25 20:20:04,902:INFO:SubProcess create_model() called ==================================
2023-04-25 20:20:04,902:INFO:Initializing create_model()
2023-04-25 20:20:04,902:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CFD260760>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFAD73F40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:20:04,902:INFO:Checking exceptions
2023-04-25 20:20:04,902:INFO:Importing libraries
2023-04-25 20:20:04,903:INFO:Copying training dataset
2023-04-25 20:20:04,909:INFO:Defining folds
2023-04-25 20:20:04,909:INFO:Declaring metric variables
2023-04-25 20:20:04,910:INFO:Importing untrained model
2023-04-25 20:20:04,910:INFO:Random Forest Classifier Imported successfully
2023-04-25 20:20:04,910:INFO:Starting cross validation
2023-04-25 20:20:04,914:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 20:20:04,916:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning:

The least populated class in y has only 1 members, which is less than n_splits=10.


2023-04-25 20:20:07,955:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:20:08,082:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:20:08,101:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:20:08,341:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:20:08,428:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:08,429:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:08,432:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:08,433:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:08,436:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:08,437:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:08,440:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:08,576:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:08,578:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:08,580:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:08,580:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:08,582:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:08,583:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:08,584:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:08,584:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:08,585:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:08,587:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:08,588:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:08,589:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:08,591:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:08,593:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:08,718:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:20:08,749:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:20:08,768:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:20:08,795:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:08,796:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:08,799:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:08,801:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:08,804:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:08,807:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:08,808:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:09,154:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:20:09,219:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:09,221:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:09,224:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:09,226:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:09,229:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:09,231:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:09,233:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:09,303:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:09,305:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:09,308:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:09,311:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:09,313:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:09,315:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:09,318:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:09,328:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:09,329:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:09,331:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:09,332:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:09,335:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:09,337:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:09,340:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:09,481:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:09,483:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:09,485:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:09,486:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:09,486:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:09,487:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:09,489:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:11,133:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:11,134:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:11,135:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:11,136:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:11,137:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:11,137:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:11,138:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:11,219:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:11,220:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:11,221:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:11,221:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:11,222:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:11,258:INFO:Calculating mean and std
2023-04-25 20:20:11,259:INFO:Creating metrics dataframe
2023-04-25 20:20:11,373:INFO:Uploading results into container
2023-04-25 20:20:11,375:INFO:Uploading model into container now
2023-04-25 20:20:11,375:INFO:_master_model_container: 7
2023-04-25 20:20:11,375:INFO:_display_container: 2
2023-04-25 20:20:11,375:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=4926, verbose=0, warm_start=False)
2023-04-25 20:20:11,376:INFO:create_model() successfully completed......................................
2023-04-25 20:20:11,513:INFO:SubProcess create_model() end ==================================
2023-04-25 20:20:11,514:INFO:Creating metrics dataframe
2023-04-25 20:20:11,517:INFO:Initializing Quadratic Discriminant Analysis
2023-04-25 20:20:11,517:INFO:Total runtime is 0.7213445941607157 minutes
2023-04-25 20:20:11,517:INFO:SubProcess create_model() called ==================================
2023-04-25 20:20:11,517:INFO:Initializing create_model()
2023-04-25 20:20:11,517:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CFD260760>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFAD73F40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:20:11,517:INFO:Checking exceptions
2023-04-25 20:20:11,517:INFO:Importing libraries
2023-04-25 20:20:11,517:INFO:Copying training dataset
2023-04-25 20:20:11,520:INFO:Defining folds
2023-04-25 20:20:11,520:INFO:Declaring metric variables
2023-04-25 20:20:11,520:INFO:Importing untrained model
2023-04-25 20:20:11,520:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-25 20:20:11,521:INFO:Starting cross validation
2023-04-25 20:20:11,522:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 20:20:11,523:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning:

The least populated class in y has only 1 members, which is less than n_splits=10.


2023-04-25 20:20:11,864:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 20:20:11,864:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 20:20:11,865:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 20:20:11,866:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 20:20:11,867:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 20:20:11,869:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 20:20:11,872:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 20:20:11,874:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 20:20:12,209:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 20:20:12,212:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 20:20:12,406:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:12,406:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:12,407:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:12,408:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:12,408:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:12,691:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:372: FitFailedWarning:


9 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\91888\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py", line 869, in fit
    raise ValueError(
ValueError: y has only 1 sample in class 1, covariance is ill defined.



2023-04-25 20:20:12,692:INFO:Calculating mean and std
2023-04-25 20:20:12,692:INFO:Creating metrics dataframe
2023-04-25 20:20:12,799:INFO:Uploading results into container
2023-04-25 20:20:12,800:INFO:Uploading model into container now
2023-04-25 20:20:12,800:INFO:_master_model_container: 8
2023-04-25 20:20:12,800:INFO:_display_container: 2
2023-04-25 20:20:12,800:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-25 20:20:12,800:INFO:create_model() successfully completed......................................
2023-04-25 20:20:12,929:WARNING:create_model() for QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:20:12,939:WARNING:Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

2023-04-25 20:20:12,939:INFO:Initializing create_model()
2023-04-25 20:20:12,939:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CFD260760>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFAD73F40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:20:12,939:INFO:Checking exceptions
2023-04-25 20:20:12,939:INFO:Importing libraries
2023-04-25 20:20:12,940:INFO:Copying training dataset
2023-04-25 20:20:12,943:INFO:Defining folds
2023-04-25 20:20:12,943:INFO:Declaring metric variables
2023-04-25 20:20:12,943:INFO:Importing untrained model
2023-04-25 20:20:12,943:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-25 20:20:12,943:INFO:Starting cross validation
2023-04-25 20:20:12,944:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 20:20:12,946:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning:

The least populated class in y has only 1 members, which is less than n_splits=10.


2023-04-25 20:20:13,235:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 20:20:13,238:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 20:20:13,250:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 20:20:13,259:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 20:20:13,262:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 20:20:13,267:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 20:20:13,275:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 20:20:13,287:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 20:20:13,592:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 20:20:13,606:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-25 20:20:13,817:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:13,817:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:13,818:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:13,818:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:13,818:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:14,081:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:372: FitFailedWarning:


9 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\91888\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py", line 869, in fit
    raise ValueError(
ValueError: y has only 1 sample in class 1, covariance is ill defined.



2023-04-25 20:20:14,081:INFO:Calculating mean and std
2023-04-25 20:20:14,082:INFO:Creating metrics dataframe
2023-04-25 20:20:14,198:INFO:Uploading results into container
2023-04-25 20:20:14,199:INFO:Uploading model into container now
2023-04-25 20:20:14,199:INFO:_master_model_container: 9
2023-04-25 20:20:14,199:INFO:_display_container: 2
2023-04-25 20:20:14,200:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-25 20:20:14,200:INFO:create_model() successfully completed......................................
2023-04-25 20:20:14,333:ERROR:create_model() for QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) raised an exception or returned all 0.0:
2023-04-25 20:20:14,334:ERROR:Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 812, in compare_models
    assert (
AssertionError

2023-04-25 20:20:14,334:INFO:Initializing Ada Boost Classifier
2023-04-25 20:20:14,334:INFO:Total runtime is 0.768295395374298 minutes
2023-04-25 20:20:14,334:INFO:SubProcess create_model() called ==================================
2023-04-25 20:20:14,334:INFO:Initializing create_model()
2023-04-25 20:20:14,334:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CFD260760>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFAD73F40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:20:14,334:INFO:Checking exceptions
2023-04-25 20:20:14,334:INFO:Importing libraries
2023-04-25 20:20:14,334:INFO:Copying training dataset
2023-04-25 20:20:14,338:INFO:Defining folds
2023-04-25 20:20:14,338:INFO:Declaring metric variables
2023-04-25 20:20:14,338:INFO:Importing untrained model
2023-04-25 20:20:14,338:INFO:Ada Boost Classifier Imported successfully
2023-04-25 20:20:14,338:INFO:Starting cross validation
2023-04-25 20:20:14,340:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 20:20:14,341:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning:

The least populated class in y has only 1 members, which is less than n_splits=10.


2023-04-25 20:20:15,280:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:15,281:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,282:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:15,282:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,283:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:15,284:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:15,284:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,284:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,285:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:15,285:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:15,285:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,286:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,286:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:15,287:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,287:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,288:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,293:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:15,293:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,294:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:15,295:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

ric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:15,296:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,296:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:15,296:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,297:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:15,297:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:15,297:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,298:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:15,299:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,300:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:15,300:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:15,300:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,301:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:15,302:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,303:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:15,303:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,304:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:15,310:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:15,311:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,312:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:15,312:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,313:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:15,314:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,315:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:15,329:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:15,329:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,330:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:15,331:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,332:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:15,332:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,333:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:15,891:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:15,892:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,893:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,894:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:15,895:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,994:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:15,994:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,995:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:15,996:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,997:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:15,997:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:15,998:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:16,227:INFO:Calculating mean and std
2023-04-25 20:20:16,227:INFO:Creating metrics dataframe
2023-04-25 20:20:16,367:INFO:Uploading results into container
2023-04-25 20:20:16,367:INFO:Uploading model into container now
2023-04-25 20:20:16,367:INFO:_master_model_container: 10
2023-04-25 20:20:16,368:INFO:_display_container: 2
2023-04-25 20:20:16,368:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4926)
2023-04-25 20:20:16,368:INFO:create_model() successfully completed......................................
2023-04-25 20:20:16,496:INFO:SubProcess create_model() end ==================================
2023-04-25 20:20:16,496:INFO:Creating metrics dataframe
2023-04-25 20:20:16,499:INFO:Initializing Gradient Boosting Classifier
2023-04-25 20:20:16,500:INFO:Total runtime is 0.8044036746025085 minutes
2023-04-25 20:20:16,500:INFO:SubProcess create_model() called ==================================
2023-04-25 20:20:16,500:INFO:Initializing create_model()
2023-04-25 20:20:16,500:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CFD260760>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFAD73F40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:20:16,500:INFO:Checking exceptions
2023-04-25 20:20:16,500:INFO:Importing libraries
2023-04-25 20:20:16,500:INFO:Copying training dataset
2023-04-25 20:20:16,506:INFO:Defining folds
2023-04-25 20:20:16,506:INFO:Declaring metric variables
2023-04-25 20:20:16,506:INFO:Importing untrained model
2023-04-25 20:20:16,506:INFO:Gradient Boosting Classifier Imported successfully
2023-04-25 20:20:16,507:INFO:Starting cross validation
2023-04-25 20:20:16,508:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 20:20:16,510:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning:

The least populated class in y has only 1 members, which is less than n_splits=10.


2023-04-25 20:20:18,498:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:18,498:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:18,499:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:18,500:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:18,501:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:18,501:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:18,502:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:18,502:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:18,503:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:18,506:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:18,506:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:18,507:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:18,508:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:18,509:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:18,510:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:18,511:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:18,511:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:18,512:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:18,512:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:18,513:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:18,513:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:18,514:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:18,514:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:18,514:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:18,515:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:18,515:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:18,516:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:18,519:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:18,539:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:18,540:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:18,541:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:18,542:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:18,542:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:18,543:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:18,544:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:18,545:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:18,545:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:18,546:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:18,547:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:18,548:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:18,549:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:18,549:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:18,550:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:18,550:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:18,551:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:18,552:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:18,553:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:18,586:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:18,586:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:18,587:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:18,588:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:18,589:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:18,589:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:18,590:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:19,371:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:19,372:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:19,374:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:19,375:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:19,376:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:19,644:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:19,644:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:19,644:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:19,645:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:19,645:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:19,646:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:19,646:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:19,648:INFO:Calculating mean and std
2023-04-25 20:20:19,648:INFO:Creating metrics dataframe
2023-04-25 20:20:19,782:INFO:Uploading results into container
2023-04-25 20:20:19,782:INFO:Uploading model into container now
2023-04-25 20:20:19,783:INFO:_master_model_container: 11
2023-04-25 20:20:19,783:INFO:_display_container: 2
2023-04-25 20:20:19,784:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4926, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-25 20:20:19,784:INFO:create_model() successfully completed......................................
2023-04-25 20:20:19,913:INFO:SubProcess create_model() end ==================================
2023-04-25 20:20:19,913:INFO:Creating metrics dataframe
2023-04-25 20:20:19,922:INFO:Initializing Linear Discriminant Analysis
2023-04-25 20:20:19,922:INFO:Total runtime is 0.8614423712094624 minutes
2023-04-25 20:20:19,922:INFO:SubProcess create_model() called ==================================
2023-04-25 20:20:19,922:INFO:Initializing create_model()
2023-04-25 20:20:19,922:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CFD260760>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFAD73F40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:20:19,922:INFO:Checking exceptions
2023-04-25 20:20:19,923:INFO:Importing libraries
2023-04-25 20:20:19,923:INFO:Copying training dataset
2023-04-25 20:20:19,927:INFO:Defining folds
2023-04-25 20:20:19,927:INFO:Declaring metric variables
2023-04-25 20:20:19,927:INFO:Importing untrained model
2023-04-25 20:20:19,927:INFO:Linear Discriminant Analysis Imported successfully
2023-04-25 20:20:19,929:INFO:Starting cross validation
2023-04-25 20:20:19,930:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 20:20:19,931:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning:

The least populated class in y has only 1 members, which is less than n_splits=10.


2023-04-25 20:20:20,720:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:20,720:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:20,722:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:20,722:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:20,722:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:20,723:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:20,723:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:20,723:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:20,725:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:20,725:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:20,725:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:20,725:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:20,725:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:20,726:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:20,726:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:20,726:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:20,727:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:20,727:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:20,727:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:20,728:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:20,728:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:20,730:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:20,734:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:20,735:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:20,736:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:20,737:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:20,738:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:20,739:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:20,740:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:20,744:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:20,745:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:20,746:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:20,747:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:20,747:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:20,747:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:20,748:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:20,748:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:20,748:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:20,749:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:20,749:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:20,750:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:20,756:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:20,757:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:20,758:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:20,759:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:20,760:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:20,760:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:20,761:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:21,522:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:21,523:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:21,524:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:21,525:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:21,526:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:21,526:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:21,527:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:21,535:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:21,536:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:21,538:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:21,539:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:21,540:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:21,768:INFO:Calculating mean and std
2023-04-25 20:20:21,769:INFO:Creating metrics dataframe
2023-04-25 20:20:21,942:INFO:Uploading results into container
2023-04-25 20:20:21,943:INFO:Uploading model into container now
2023-04-25 20:20:21,944:INFO:_master_model_container: 12
2023-04-25 20:20:21,944:INFO:_display_container: 2
2023-04-25 20:20:21,944:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-25 20:20:21,944:INFO:create_model() successfully completed......................................
2023-04-25 20:20:22,098:INFO:SubProcess create_model() end ==================================
2023-04-25 20:20:22,099:INFO:Creating metrics dataframe
2023-04-25 20:20:22,103:INFO:Initializing Extra Trees Classifier
2023-04-25 20:20:22,104:INFO:Total runtime is 0.8978037397066752 minutes
2023-04-25 20:20:22,104:INFO:SubProcess create_model() called ==================================
2023-04-25 20:20:22,105:INFO:Initializing create_model()
2023-04-25 20:20:22,105:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CFD260760>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFAD73F40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:20:22,105:INFO:Checking exceptions
2023-04-25 20:20:22,105:INFO:Importing libraries
2023-04-25 20:20:22,105:INFO:Copying training dataset
2023-04-25 20:20:22,112:INFO:Defining folds
2023-04-25 20:20:22,112:INFO:Declaring metric variables
2023-04-25 20:20:22,113:INFO:Importing untrained model
2023-04-25 20:20:22,113:INFO:Extra Trees Classifier Imported successfully
2023-04-25 20:20:22,113:INFO:Starting cross validation
2023-04-25 20:20:22,116:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 20:20:22,118:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning:

The least populated class in y has only 1 members, which is less than n_splits=10.


2023-04-25 20:20:23,573:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:23,573:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:23,574:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:23,575:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:23,575:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:23,575:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:23,576:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:23,577:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:23,577:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:23,577:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:23,578:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:23,578:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:23,578:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:23,579:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:23,579:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:23,580:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:23,581:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:23,581:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:23,581:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:23,582:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:23,582:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:23,586:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:23,586:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:23,587:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:23,588:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:23,589:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:23,590:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:23,590:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:23,590:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:23,591:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:23,591:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:23,591:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:23,591:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:23,592:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:23,592:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:23,593:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:23,593:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:23,593:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:23,594:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:23,595:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:23,595:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:23,596:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:23,636:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:23,636:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:23,637:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:23,638:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:23,639:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:23,640:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:23,641:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:23,768:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:23,769:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:23,770:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:23,770:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:23,771:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:23,771:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:23,772:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:24,559:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:24,559:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:24,560:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:24,561:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:24,561:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:24,610:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:24,610:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:24,611:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:24,611:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:24,611:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:24,612:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:24,612:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:24,674:INFO:Calculating mean and std
2023-04-25 20:20:24,674:INFO:Creating metrics dataframe
2023-04-25 20:20:24,799:INFO:Uploading results into container
2023-04-25 20:20:24,799:INFO:Uploading model into container now
2023-04-25 20:20:24,800:INFO:_master_model_container: 13
2023-04-25 20:20:24,800:INFO:_display_container: 2
2023-04-25 20:20:24,800:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=4926, verbose=0, warm_start=False)
2023-04-25 20:20:24,800:INFO:create_model() successfully completed......................................
2023-04-25 20:20:24,946:INFO:SubProcess create_model() end ==================================
2023-04-25 20:20:24,946:INFO:Creating metrics dataframe
2023-04-25 20:20:24,949:INFO:Initializing Light Gradient Boosting Machine
2023-04-25 20:20:24,949:INFO:Total runtime is 0.9452165087064107 minutes
2023-04-25 20:20:24,949:INFO:SubProcess create_model() called ==================================
2023-04-25 20:20:24,949:INFO:Initializing create_model()
2023-04-25 20:20:24,949:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CFD260760>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFAD73F40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:20:24,949:INFO:Checking exceptions
2023-04-25 20:20:24,949:INFO:Importing libraries
2023-04-25 20:20:24,949:INFO:Copying training dataset
2023-04-25 20:20:24,952:INFO:Defining folds
2023-04-25 20:20:24,952:INFO:Declaring metric variables
2023-04-25 20:20:24,952:INFO:Importing untrained model
2023-04-25 20:20:24,953:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 20:20:24,953:INFO:Starting cross validation
2023-04-25 20:20:24,954:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 20:20:24,957:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning:

The least populated class in y has only 1 members, which is less than n_splits=10.


2023-04-25 20:20:27,270:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:27,274:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:27,277:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:27,279:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:27,281:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:27,283:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:27,285:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:27,317:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:27,318:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:27,319:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:27,319:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:27,320:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:27,321:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:27,323:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:27,324:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:27,325:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:27,328:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:27,330:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:27,330:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:20:27,332:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:27,338:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:27,340:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:27,343:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:27,344:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:27,345:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

ric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:27,347:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:27,347:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:27,349:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:27,350:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:27,352:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:27,359:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:27,360:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:27,360:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:27,361:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:27,377:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:27,379:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:27,390:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:27,393:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:27,395:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:27,396:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:27,397:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:27,448:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:27,450:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:27,453:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:27,455:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:27,456:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:27,456:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:27,457:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:27,600:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:20:27,744:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:27,746:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:27,749:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:27,751:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:27,753:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:27,755:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:27,759:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:29,616:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:29,617:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:29,619:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:29,621:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:29,622:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:29,673:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:29,674:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:29,675:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:29,677:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:29,678:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:29,680:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:29,681:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:30,301:INFO:Calculating mean and std
2023-04-25 20:20:30,303:INFO:Creating metrics dataframe
2023-04-25 20:20:30,797:INFO:Uploading results into container
2023-04-25 20:20:30,799:INFO:Uploading model into container now
2023-04-25 20:20:30,800:INFO:_master_model_container: 14
2023-04-25 20:20:30,800:INFO:_display_container: 2
2023-04-25 20:20:30,801:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4926, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-25 20:20:30,801:INFO:create_model() successfully completed......................................
2023-04-25 20:20:31,070:INFO:SubProcess create_model() end ==================================
2023-04-25 20:20:31,070:INFO:Creating metrics dataframe
2023-04-25 20:20:31,078:INFO:Initializing Dummy Classifier
2023-04-25 20:20:31,079:INFO:Total runtime is 1.0473833044370016 minutes
2023-04-25 20:20:31,080:INFO:SubProcess create_model() called ==================================
2023-04-25 20:20:31,080:INFO:Initializing create_model()
2023-04-25 20:20:31,080:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CFD260760>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017CFAD73F40>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:20:31,081:INFO:Checking exceptions
2023-04-25 20:20:31,081:INFO:Importing libraries
2023-04-25 20:20:31,081:INFO:Copying training dataset
2023-04-25 20:20:31,093:INFO:Defining folds
2023-04-25 20:20:31,093:INFO:Declaring metric variables
2023-04-25 20:20:31,093:INFO:Importing untrained model
2023-04-25 20:20:31,094:INFO:Dummy Classifier Imported successfully
2023-04-25 20:20:31,095:INFO:Starting cross validation
2023-04-25 20:20:31,099:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-25 20:20:31,102:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:676: UserWarning:

The least populated class in y has only 1 members, which is less than n_splits=10.


2023-04-25 20:20:33,075:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:20:33,129:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:20:33,133:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:20:33,172:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:20:33,180:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:20:33,190:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:20:33,194:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:20:33,204:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:33,206:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:33,208:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:33,210:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:33,213:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:33,215:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:33,217:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:33,260:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:33,262:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:33,264:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:33,265:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:33,267:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:33,269:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:33,272:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:33,273:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:33,275:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:33,277:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:33,280:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:33,282:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:33,284:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:33,286:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:33,299:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:33,300:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:33,303:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:33,304:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:33,305:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:33,306:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:33,307:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:33,309:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:33,309:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:33,311:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:33,312:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:33,312:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:33,312:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:33,314:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:33,314:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:33,317:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:33,317:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:33,323:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:33,326:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:33,326:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:33,328:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:33,328:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:33,329:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:33,331:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:33,331:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:33,334:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:33,336:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:33,346:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:34,285:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-25 20:20:34,362:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:34,362:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:34,364:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:34,365:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:34,365:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:34,366:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:34,367:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:35,385:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:35,387:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:35,389:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:35,389:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:35,390:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:35,391:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:35,392:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-04-25 20:20:35,401:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 561, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 665, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2023-04-25 20:20:35,403:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:35,405:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:35,406:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-25 20:20:35,406:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1370: UserWarning: Note that pos_label (set to 'notckd') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-04-25 20:20:35,828:INFO:Calculating mean and std
2023-04-25 20:20:35,830:INFO:Creating metrics dataframe
2023-04-25 20:20:35,988:INFO:Uploading results into container
2023-04-25 20:20:35,988:INFO:Uploading model into container now
2023-04-25 20:20:35,989:INFO:_master_model_container: 15
2023-04-25 20:20:35,989:INFO:_display_container: 2
2023-04-25 20:20:35,989:INFO:DummyClassifier(constant=None, random_state=4926, strategy='prior')
2023-04-25 20:20:35,989:INFO:create_model() successfully completed......................................
2023-04-25 20:20:36,132:INFO:SubProcess create_model() end ==================================
2023-04-25 20:20:36,132:INFO:Creating metrics dataframe
2023-04-25 20:20:36,138:INFO:Initializing create_model()
2023-04-25 20:20:36,138:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CFD260760>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=4926, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:20:36,138:INFO:Checking exceptions
2023-04-25 20:20:36,139:INFO:Importing libraries
2023-04-25 20:20:36,139:INFO:Copying training dataset
2023-04-25 20:20:36,143:INFO:Defining folds
2023-04-25 20:20:36,143:INFO:Declaring metric variables
2023-04-25 20:20:36,143:INFO:Importing untrained model
2023-04-25 20:20:36,143:INFO:Declaring custom model
2023-04-25 20:20:36,143:INFO:Random Forest Classifier Imported successfully
2023-04-25 20:20:36,145:INFO:Cross validation set to False
2023-04-25 20:20:36,145:INFO:Fitting Model
2023-04-25 20:20:36,619:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=4926, verbose=0, warm_start=False)
2023-04-25 20:20:36,619:INFO:create_model() successfully completed......................................
2023-04-25 20:20:36,770:INFO:_master_model_container: 15
2023-04-25 20:20:36,770:INFO:_display_container: 2
2023-04-25 20:20:36,770:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=4926, verbose=0, warm_start=False)
2023-04-25 20:20:36,770:INFO:compare_models() successfully completed......................................
2023-04-25 20:20:36,903:INFO:Initializing save_model()
2023-04-25 20:20:36,904:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=4926, verbose=0, warm_start=False), model_name=best_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\91888\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'age', 'bp', 'sg', 'al',
                                             'su', 'bgr', 'bu', 'sc', 'sod',
                                             'pot', 'hemo'],
                                    transformer=SimpleImputer(add_ind...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['pcv', 'wc', 'rc'],
                                    transformer=LeaveOneOutEncoder(cols=['pcv',
                                                                         'wc',
                                                                         'rc'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=4926,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-04-25 20:20:36,904:INFO:Adding model into prep_pipe
2023-04-25 20:20:36,946:INFO:best_model.pkl saved in current working directory
2023-04-25 20:20:37,076:INFO:Pipeline(memory=FastMemory(location=C:\Users\91888\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'age', 'bp', 'sg', 'al',
                                             'su', 'bgr', 'bu', 'sc', 'sod',
                                             'pot', 'hemo'],
                                    transformer=SimpleImputer(add_ind...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='auto',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=4926,
                                        verbose=0, warm_start=False))],
         verbose=False)
2023-04-25 20:20:37,076:INFO:save_model() successfully completed......................................
2023-04-25 20:20:37,336:INFO:Initializing plot_model()
2023-04-25 20:20:37,336:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=4926, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CFD260760>, system=True)
2023-04-25 20:20:37,336:INFO:Checking exceptions
2023-04-25 20:20:37,350:INFO:Preloading libraries
2023-04-25 20:20:37,366:INFO:Copying training dataset
2023-04-25 20:20:37,366:INFO:Plot type: confusion_matrix
2023-04-25 20:20:37,476:INFO:Fitting Model
2023-04-25 20:20:37,476:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning:

X does not have valid feature names, but RandomForestClassifier was fitted with feature names


2023-04-25 20:20:37,476:INFO:Scoring test/hold-out set
2023-04-25 20:20:37,578:WARNING:C:\Users\91888\anaconda3\lib\site-packages\yellowbrick\base.py:246: UserWarning:

Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.


2023-04-25 20:20:37,592:INFO:Visual Rendered Successfully
2023-04-25 20:20:37,727:INFO:plot_model() successfully completed......................................
2023-04-25 20:20:37,728:INFO:Initializing plot_model()
2023-04-25 20:20:37,728:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=4926, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017CFD260760>, system=True)
2023-04-25 20:20:37,728:INFO:Checking exceptions
2023-04-25 20:20:37,745:INFO:Preloading libraries
2023-04-25 20:20:37,752:INFO:Copying training dataset
2023-04-25 20:20:37,752:INFO:Plot type: feature
2023-04-25 20:20:37,753:WARNING:No coef_ found. Trying feature_importances_
2023-04-25 20:20:37,814:WARNING:C:\Users\91888\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:1896: UserWarning:

Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.


2023-04-25 20:20:37,815:INFO:Visual Rendered Successfully
2023-04-25 20:20:37,956:INFO:plot_model() successfully completed......................................
2023-04-26 16:39:17,431:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-26 16:39:17,431:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-26 16:39:17,431:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-26 16:39:17,432:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-26 16:39:19,032:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-26 16:40:00,223:INFO:PyCaret RegressionExperiment
2023-04-26 16:40:00,223:INFO:Logging name: reg-default-name
2023-04-26 16:40:00,223:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-26 16:40:00,224:INFO:version 3.0.0
2023-04-26 16:40:00,224:INFO:Initializing setup()
2023-04-26 16:40:00,225:INFO:self.USI: 4a5b
2023-04-26 16:40:00,225:INFO:self._variable_keys: {'y_train', 'y_test', 'USI', 'pipeline', 'fold_shuffle_param', 'memory', 'gpu_param', 'X_train', 'exp_name_log', 'fold_generator', 'transform_target_param', 'log_plots_param', 'n_jobs_param', 'data', 'fold_groups_param', 'exp_id', 'logging_param', 'html_param', '_available_plots', 'y', 'X_test', 'target_param', 'X', 'idx', 'seed', 'gpu_n_jobs_param', '_ml_usecase'}
2023-04-26 16:40:00,226:INFO:Checking environment
2023-04-26 16:40:00,226:INFO:python_version: 3.9.12
2023-04-26 16:40:00,226:INFO:python_build: ('main', 'Apr  4 2022 05:22:27')
2023-04-26 16:40:00,227:INFO:machine: AMD64
2023-04-26 16:40:00,263:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-26 16:40:00,264:INFO:Memory: svmem(total=8362713088, available=797212672, percent=90.5, used=7565500416, free=797212672)
2023-04-26 16:40:00,264:INFO:Physical Core: 4
2023-04-26 16:40:00,264:INFO:Logical Core: 8
2023-04-26 16:40:00,264:INFO:Checking libraries
2023-04-26 16:40:00,264:INFO:System:
2023-04-26 16:40:00,264:INFO:    python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]
2023-04-26 16:40:00,264:INFO:executable: C:\Users\91888\anaconda3\python.exe
2023-04-26 16:40:00,264:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-26 16:40:00,264:INFO:PyCaret required dependencies:
2023-04-26 16:40:00,265:INFO:                 pip: 21.2.4
2023-04-26 16:40:00,265:INFO:          setuptools: 61.2.0
2023-04-26 16:40:00,265:INFO:             pycaret: 3.0.0
2023-04-26 16:40:00,265:INFO:             IPython: 8.2.0
2023-04-26 16:40:00,265:INFO:          ipywidgets: 7.6.5
2023-04-26 16:40:00,265:INFO:                tqdm: 4.64.0
2023-04-26 16:40:00,265:INFO:               numpy: 1.21.5
2023-04-26 16:40:00,265:INFO:              pandas: 1.4.2
2023-04-26 16:40:00,265:INFO:              jinja2: 2.11.3
2023-04-26 16:40:00,265:INFO:               scipy: 1.7.3
2023-04-26 16:40:00,265:INFO:              joblib: 1.2.0
2023-04-26 16:40:00,266:INFO:             sklearn: 1.0.2
2023-04-26 16:40:00,266:INFO:                pyod: 1.0.9
2023-04-26 16:40:00,266:INFO:            imblearn: 0.10.1
2023-04-26 16:40:00,266:INFO:   category_encoders: 2.6.0
2023-04-26 16:40:00,266:INFO:            lightgbm: 3.3.5
2023-04-26 16:40:00,266:INFO:               numba: 0.55.1
2023-04-26 16:40:00,266:INFO:            requests: 2.27.1
2023-04-26 16:40:00,266:INFO:          matplotlib: 3.5.1
2023-04-26 16:40:00,266:INFO:          scikitplot: 0.3.7
2023-04-26 16:40:00,266:INFO:         yellowbrick: 1.5
2023-04-26 16:40:00,266:INFO:              plotly: 5.6.0
2023-04-26 16:40:00,266:INFO:             kaleido: 0.2.1
2023-04-26 16:40:00,267:INFO:         statsmodels: 0.13.2
2023-04-26 16:40:00,267:INFO:              sktime: 0.17.1
2023-04-26 16:40:00,267:INFO:               tbats: 1.1.3
2023-04-26 16:40:00,267:INFO:            pmdarima: 2.0.3
2023-04-26 16:40:00,267:INFO:              psutil: 5.9.5
2023-04-26 16:40:00,267:INFO:PyCaret optional dependencies:
2023-04-26 16:40:00,290:INFO:                shap: Not installed
2023-04-26 16:40:00,290:INFO:           interpret: Not installed
2023-04-26 16:40:00,290:INFO:                umap: Not installed
2023-04-26 16:40:00,290:INFO:    pandas_profiling: 4.1.2
2023-04-26 16:40:00,290:INFO:  explainerdashboard: Not installed
2023-04-26 16:40:00,290:INFO:             autoviz: Not installed
2023-04-26 16:40:00,291:INFO:           fairlearn: Not installed
2023-04-26 16:40:00,291:INFO:             xgboost: Not installed
2023-04-26 16:40:00,291:INFO:            catboost: Not installed
2023-04-26 16:40:00,291:INFO:              kmodes: Not installed
2023-04-26 16:40:00,291:INFO:             mlxtend: Not installed
2023-04-26 16:40:00,291:INFO:       statsforecast: Not installed
2023-04-26 16:40:00,291:INFO:        tune_sklearn: Not installed
2023-04-26 16:40:00,291:INFO:                 ray: Not installed
2023-04-26 16:40:00,291:INFO:            hyperopt: Not installed
2023-04-26 16:40:00,291:INFO:              optuna: Not installed
2023-04-26 16:40:00,292:INFO:               skopt: Not installed
2023-04-26 16:40:00,292:INFO:              mlflow: Not installed
2023-04-26 16:40:00,292:INFO:              gradio: Not installed
2023-04-26 16:40:00,292:INFO:             fastapi: Not installed
2023-04-26 16:40:00,292:INFO:             uvicorn: Not installed
2023-04-26 16:40:00,292:INFO:              m2cgen: Not installed
2023-04-26 16:40:00,293:INFO:           evidently: Not installed
2023-04-26 16:40:00,293:INFO:               fugue: Not installed
2023-04-26 16:40:00,293:INFO:           streamlit: 1.21.0
2023-04-26 16:40:00,293:INFO:             prophet: Not installed
2023-04-26 16:40:00,293:INFO:None
2023-04-26 16:40:00,293:INFO:Set up data.
2023-04-26 16:40:00,298:INFO:Set up train/test split.
2023-04-26 16:40:00,303:INFO:Set up index.
2023-04-26 16:40:00,303:INFO:Set up folding strategy.
2023-04-26 16:40:00,304:INFO:Assigning column types.
2023-04-26 16:40:00,309:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-26 16:40:00,310:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-26 16:40:00,325:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-26 16:40:00,340:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-26 16:40:00,479:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-26 16:40:00,605:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-26 16:40:00,607:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:00,663:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:00,664:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-26 16:40:00,679:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-26 16:40:00,693:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-26 16:40:00,908:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-26 16:40:01,042:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-26 16:40:01,043:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:01,044:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:01,044:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-26 16:40:01,056:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-26 16:40:01,069:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-26 16:40:01,237:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-26 16:40:01,379:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-26 16:40:01,380:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:01,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:01,393:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-26 16:40:01,403:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-26 16:40:01,556:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-26 16:40:01,693:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-26 16:40:01,696:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:01,697:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:01,697:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-26 16:40:01,734:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-26 16:40:01,905:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-26 16:40:02,047:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-26 16:40:02,049:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:02,054:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:02,081:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-26 16:40:02,283:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-26 16:40:02,405:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-26 16:40:02,407:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:02,407:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:02,408:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-26 16:40:02,587:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-26 16:40:02,714:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-26 16:40:02,716:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:02,717:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:02,888:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-26 16:40:03,042:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-26 16:40:03,045:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:03,046:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:03,047:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-26 16:40:03,283:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-26 16:40:03,418:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:03,418:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:03,620:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-26 16:40:03,736:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:03,737:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:03,738:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-26 16:40:04,012:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:04,012:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:04,303:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:04,304:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:04,318:INFO:Preparing preprocessing pipeline...
2023-04-26 16:40:04,318:INFO:Set up simple imputation.
2023-04-26 16:40:04,384:INFO:Finished creating preprocessing pipeline.
2023-04-26 16:40:04,397:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\91888\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['TV', 'Radio', 'Newspaper'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-04-26 16:40:04,397:INFO:Creating final display dataframe.
2023-04-26 16:40:04,536:INFO:Setup _display_container:                     Description             Value
0                    Session id              6541
1                        Target             Sales
2                   Target type        Regression
3           Original data shape          (200, 4)
4        Transformed data shape          (200, 4)
5   Transformed train set shape          (140, 4)
6    Transformed test set shape           (60, 4)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              4a5b
2023-04-26 16:40:04,863:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:04,863:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:05,213:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:05,214:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-26 16:40:05,215:INFO:setup() successfully completed in 5.6s...............
2023-04-26 16:40:05,224:INFO:Initializing compare_models()
2023-04-26 16:40:05,225:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAB0ACAAC0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001FAB0ACAAC0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-26 16:40:05,225:INFO:Checking exceptions
2023-04-26 16:40:05,228:INFO:Preparing display monitor
2023-04-26 16:40:05,238:INFO:Initializing Linear Regression
2023-04-26 16:40:05,238:INFO:Total runtime is 0.0 minutes
2023-04-26 16:40:05,238:INFO:SubProcess create_model() called ==================================
2023-04-26 16:40:05,239:INFO:Initializing create_model()
2023-04-26 16:40:05,239:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAB0ACAAC0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAB10C2970>, model_only=True, return_train_score=False, kwargs={})
2023-04-26 16:40:05,239:INFO:Checking exceptions
2023-04-26 16:40:05,240:INFO:Importing libraries
2023-04-26 16:40:05,240:INFO:Copying training dataset
2023-04-26 16:40:05,247:INFO:Defining folds
2023-04-26 16:40:05,248:INFO:Declaring metric variables
2023-04-26 16:40:05,248:INFO:Importing untrained model
2023-04-26 16:40:05,249:INFO:Linear Regression Imported successfully
2023-04-26 16:40:05,250:INFO:Starting cross validation
2023-04-26 16:40:05,263:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-26 16:40:13,910:INFO:Calculating mean and std
2023-04-26 16:40:13,929:INFO:Creating metrics dataframe
2023-04-26 16:40:14,381:INFO:Uploading results into container
2023-04-26 16:40:14,383:INFO:Uploading model into container now
2023-04-26 16:40:14,383:INFO:_master_model_container: 1
2023-04-26 16:40:14,384:INFO:_display_container: 2
2023-04-26 16:40:14,384:INFO:LinearRegression(n_jobs=-1)
2023-04-26 16:40:14,384:INFO:create_model() successfully completed......................................
2023-04-26 16:40:14,594:INFO:SubProcess create_model() end ==================================
2023-04-26 16:40:14,594:INFO:Creating metrics dataframe
2023-04-26 16:40:14,611:INFO:Initializing Lasso Regression
2023-04-26 16:40:14,612:INFO:Total runtime is 0.1562312444051107 minutes
2023-04-26 16:40:14,612:INFO:SubProcess create_model() called ==================================
2023-04-26 16:40:14,613:INFO:Initializing create_model()
2023-04-26 16:40:14,613:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAB0ACAAC0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAB10C2970>, model_only=True, return_train_score=False, kwargs={})
2023-04-26 16:40:14,613:INFO:Checking exceptions
2023-04-26 16:40:14,613:INFO:Importing libraries
2023-04-26 16:40:14,613:INFO:Copying training dataset
2023-04-26 16:40:14,621:INFO:Defining folds
2023-04-26 16:40:14,621:INFO:Declaring metric variables
2023-04-26 16:40:14,622:INFO:Importing untrained model
2023-04-26 16:40:14,622:INFO:Lasso Regression Imported successfully
2023-04-26 16:40:14,623:INFO:Starting cross validation
2023-04-26 16:40:14,624:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-26 16:40:17,419:INFO:Calculating mean and std
2023-04-26 16:40:17,421:INFO:Creating metrics dataframe
2023-04-26 16:40:17,833:INFO:Uploading results into container
2023-04-26 16:40:17,834:INFO:Uploading model into container now
2023-04-26 16:40:17,835:INFO:_master_model_container: 2
2023-04-26 16:40:17,835:INFO:_display_container: 2
2023-04-26 16:40:17,836:INFO:Lasso(random_state=6541)
2023-04-26 16:40:17,836:INFO:create_model() successfully completed......................................
2023-04-26 16:40:18,014:INFO:SubProcess create_model() end ==================================
2023-04-26 16:40:18,014:INFO:Creating metrics dataframe
2023-04-26 16:40:18,024:INFO:Initializing Ridge Regression
2023-04-26 16:40:18,024:INFO:Total runtime is 0.21309436957041422 minutes
2023-04-26 16:40:18,024:INFO:SubProcess create_model() called ==================================
2023-04-26 16:40:18,025:INFO:Initializing create_model()
2023-04-26 16:40:18,025:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAB0ACAAC0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAB10C2970>, model_only=True, return_train_score=False, kwargs={})
2023-04-26 16:40:18,025:INFO:Checking exceptions
2023-04-26 16:40:18,025:INFO:Importing libraries
2023-04-26 16:40:18,025:INFO:Copying training dataset
2023-04-26 16:40:18,031:INFO:Defining folds
2023-04-26 16:40:18,032:INFO:Declaring metric variables
2023-04-26 16:40:18,032:INFO:Importing untrained model
2023-04-26 16:40:18,033:INFO:Ridge Regression Imported successfully
2023-04-26 16:40:18,033:INFO:Starting cross validation
2023-04-26 16:40:18,035:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-26 16:40:21,271:INFO:Calculating mean and std
2023-04-26 16:40:21,273:INFO:Creating metrics dataframe
2023-04-26 16:40:21,730:INFO:Uploading results into container
2023-04-26 16:40:21,731:INFO:Uploading model into container now
2023-04-26 16:40:21,732:INFO:_master_model_container: 3
2023-04-26 16:40:21,732:INFO:_display_container: 2
2023-04-26 16:40:21,733:INFO:Ridge(random_state=6541)
2023-04-26 16:40:21,733:INFO:create_model() successfully completed......................................
2023-04-26 16:40:21,906:INFO:SubProcess create_model() end ==================================
2023-04-26 16:40:21,907:INFO:Creating metrics dataframe
2023-04-26 16:40:21,916:INFO:Initializing Elastic Net
2023-04-26 16:40:21,916:INFO:Total runtime is 0.2779708743095398 minutes
2023-04-26 16:40:21,917:INFO:SubProcess create_model() called ==================================
2023-04-26 16:40:21,917:INFO:Initializing create_model()
2023-04-26 16:40:21,917:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAB0ACAAC0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAB10C2970>, model_only=True, return_train_score=False, kwargs={})
2023-04-26 16:40:21,917:INFO:Checking exceptions
2023-04-26 16:40:21,917:INFO:Importing libraries
2023-04-26 16:40:21,917:INFO:Copying training dataset
2023-04-26 16:40:21,924:INFO:Defining folds
2023-04-26 16:40:21,924:INFO:Declaring metric variables
2023-04-26 16:40:21,924:INFO:Importing untrained model
2023-04-26 16:40:21,925:INFO:Elastic Net Imported successfully
2023-04-26 16:40:21,926:INFO:Starting cross validation
2023-04-26 16:40:21,927:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-26 16:40:24,809:INFO:Calculating mean and std
2023-04-26 16:40:24,810:INFO:Creating metrics dataframe
2023-04-26 16:40:25,324:INFO:Uploading results into container
2023-04-26 16:40:25,325:INFO:Uploading model into container now
2023-04-26 16:40:25,327:INFO:_master_model_container: 4
2023-04-26 16:40:25,327:INFO:_display_container: 2
2023-04-26 16:40:25,328:INFO:ElasticNet(random_state=6541)
2023-04-26 16:40:25,329:INFO:create_model() successfully completed......................................
2023-04-26 16:40:25,499:INFO:SubProcess create_model() end ==================================
2023-04-26 16:40:25,500:INFO:Creating metrics dataframe
2023-04-26 16:40:25,528:INFO:Initializing Least Angle Regression
2023-04-26 16:40:25,528:INFO:Total runtime is 0.33816171884536744 minutes
2023-04-26 16:40:25,529:INFO:SubProcess create_model() called ==================================
2023-04-26 16:40:25,529:INFO:Initializing create_model()
2023-04-26 16:40:25,529:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAB0ACAAC0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAB10C2970>, model_only=True, return_train_score=False, kwargs={})
2023-04-26 16:40:25,530:INFO:Checking exceptions
2023-04-26 16:40:25,530:INFO:Importing libraries
2023-04-26 16:40:25,530:INFO:Copying training dataset
2023-04-26 16:40:25,539:INFO:Defining folds
2023-04-26 16:40:25,540:INFO:Declaring metric variables
2023-04-26 16:40:25,540:INFO:Importing untrained model
2023-04-26 16:40:25,541:INFO:Least Angle Regression Imported successfully
2023-04-26 16:40:25,542:INFO:Starting cross validation
2023-04-26 16:40:25,543:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-26 16:40:25,628:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-26 16:40:25,649:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-26 16:40:25,665:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-26 16:40:25,676:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-26 16:40:25,703:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-26 16:40:25,732:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-26 16:40:25,755:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-26 16:40:25,779:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-26 16:40:26,160:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-26 16:40:26,228:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-26 16:40:28,205:INFO:Calculating mean and std
2023-04-26 16:40:28,206:INFO:Creating metrics dataframe
2023-04-26 16:40:28,680:INFO:Uploading results into container
2023-04-26 16:40:28,681:INFO:Uploading model into container now
2023-04-26 16:40:28,682:INFO:_master_model_container: 5
2023-04-26 16:40:28,682:INFO:_display_container: 2
2023-04-26 16:40:28,683:INFO:Lars(random_state=6541)
2023-04-26 16:40:28,683:INFO:create_model() successfully completed......................................
2023-04-26 16:40:28,853:INFO:SubProcess create_model() end ==================================
2023-04-26 16:40:28,853:INFO:Creating metrics dataframe
2023-04-26 16:40:28,863:INFO:Initializing Lasso Least Angle Regression
2023-04-26 16:40:28,863:INFO:Total runtime is 0.39375210205713906 minutes
2023-04-26 16:40:28,864:INFO:SubProcess create_model() called ==================================
2023-04-26 16:40:28,864:INFO:Initializing create_model()
2023-04-26 16:40:28,864:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAB0ACAAC0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAB10C2970>, model_only=True, return_train_score=False, kwargs={})
2023-04-26 16:40:28,865:INFO:Checking exceptions
2023-04-26 16:40:28,865:INFO:Importing libraries
2023-04-26 16:40:28,865:INFO:Copying training dataset
2023-04-26 16:40:28,872:INFO:Defining folds
2023-04-26 16:40:28,872:INFO:Declaring metric variables
2023-04-26 16:40:28,872:INFO:Importing untrained model
2023-04-26 16:40:28,873:INFO:Lasso Least Angle Regression Imported successfully
2023-04-26 16:40:28,874:INFO:Starting cross validation
2023-04-26 16:40:28,875:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-26 16:40:28,976:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-26 16:40:28,996:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-26 16:40:29,021:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-26 16:40:29,032:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-26 16:40:29,059:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-26 16:40:29,079:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-26 16:40:29,106:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-26 16:40:29,139:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-26 16:40:29,483:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-26 16:40:29,496:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-26 16:40:31,458:INFO:Calculating mean and std
2023-04-26 16:40:31,459:INFO:Creating metrics dataframe
2023-04-26 16:40:31,800:INFO:Uploading results into container
2023-04-26 16:40:31,800:INFO:Uploading model into container now
2023-04-26 16:40:31,801:INFO:_master_model_container: 6
2023-04-26 16:40:31,801:INFO:_display_container: 2
2023-04-26 16:40:31,802:INFO:LassoLars(random_state=6541)
2023-04-26 16:40:31,802:INFO:create_model() successfully completed......................................
2023-04-26 16:40:31,959:INFO:SubProcess create_model() end ==================================
2023-04-26 16:40:31,959:INFO:Creating metrics dataframe
2023-04-26 16:40:31,969:INFO:Initializing Orthogonal Matching Pursuit
2023-04-26 16:40:31,969:INFO:Total runtime is 0.4455130974451701 minutes
2023-04-26 16:40:31,970:INFO:SubProcess create_model() called ==================================
2023-04-26 16:40:31,970:INFO:Initializing create_model()
2023-04-26 16:40:31,970:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAB0ACAAC0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAB10C2970>, model_only=True, return_train_score=False, kwargs={})
2023-04-26 16:40:31,971:INFO:Checking exceptions
2023-04-26 16:40:31,971:INFO:Importing libraries
2023-04-26 16:40:31,971:INFO:Copying training dataset
2023-04-26 16:40:31,978:INFO:Defining folds
2023-04-26 16:40:31,978:INFO:Declaring metric variables
2023-04-26 16:40:31,978:INFO:Importing untrained model
2023-04-26 16:40:31,979:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-26 16:40:31,979:INFO:Starting cross validation
2023-04-26 16:40:31,981:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-26 16:40:32,061:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-26 16:40:32,078:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-26 16:40:32,095:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-26 16:40:32,106:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-26 16:40:32,148:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-26 16:40:32,161:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-26 16:40:32,167:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-26 16:40:32,182:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-26 16:40:32,566:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-26 16:40:32,589:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-26 16:40:34,718:INFO:Calculating mean and std
2023-04-26 16:40:34,720:INFO:Creating metrics dataframe
2023-04-26 16:40:35,158:INFO:Uploading results into container
2023-04-26 16:40:35,159:INFO:Uploading model into container now
2023-04-26 16:40:35,160:INFO:_master_model_container: 7
2023-04-26 16:40:35,160:INFO:_display_container: 2
2023-04-26 16:40:35,161:INFO:OrthogonalMatchingPursuit()
2023-04-26 16:40:35,161:INFO:create_model() successfully completed......................................
2023-04-26 16:40:35,365:INFO:SubProcess create_model() end ==================================
2023-04-26 16:40:35,366:INFO:Creating metrics dataframe
2023-04-26 16:40:35,375:INFO:Initializing Bayesian Ridge
2023-04-26 16:40:35,376:INFO:Total runtime is 0.5022966464360555 minutes
2023-04-26 16:40:35,376:INFO:SubProcess create_model() called ==================================
2023-04-26 16:40:35,377:INFO:Initializing create_model()
2023-04-26 16:40:35,377:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAB0ACAAC0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAB10C2970>, model_only=True, return_train_score=False, kwargs={})
2023-04-26 16:40:35,377:INFO:Checking exceptions
2023-04-26 16:40:35,377:INFO:Importing libraries
2023-04-26 16:40:35,377:INFO:Copying training dataset
2023-04-26 16:40:35,383:INFO:Defining folds
2023-04-26 16:40:35,383:INFO:Declaring metric variables
2023-04-26 16:40:35,384:INFO:Importing untrained model
2023-04-26 16:40:35,384:INFO:Bayesian Ridge Imported successfully
2023-04-26 16:40:35,385:INFO:Starting cross validation
2023-04-26 16:40:35,386:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-26 16:40:38,067:INFO:Calculating mean and std
2023-04-26 16:40:38,069:INFO:Creating metrics dataframe
2023-04-26 16:40:38,525:INFO:Uploading results into container
2023-04-26 16:40:38,526:INFO:Uploading model into container now
2023-04-26 16:40:38,527:INFO:_master_model_container: 8
2023-04-26 16:40:38,527:INFO:_display_container: 2
2023-04-26 16:40:38,528:INFO:BayesianRidge()
2023-04-26 16:40:38,528:INFO:create_model() successfully completed......................................
2023-04-26 16:40:38,698:INFO:SubProcess create_model() end ==================================
2023-04-26 16:40:38,698:INFO:Creating metrics dataframe
2023-04-26 16:40:38,707:INFO:Initializing Passive Aggressive Regressor
2023-04-26 16:40:38,707:INFO:Total runtime is 0.557810938358307 minutes
2023-04-26 16:40:38,708:INFO:SubProcess create_model() called ==================================
2023-04-26 16:40:38,708:INFO:Initializing create_model()
2023-04-26 16:40:38,708:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAB0ACAAC0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAB10C2970>, model_only=True, return_train_score=False, kwargs={})
2023-04-26 16:40:38,708:INFO:Checking exceptions
2023-04-26 16:40:38,708:INFO:Importing libraries
2023-04-26 16:40:38,708:INFO:Copying training dataset
2023-04-26 16:40:38,713:INFO:Defining folds
2023-04-26 16:40:38,714:INFO:Declaring metric variables
2023-04-26 16:40:38,714:INFO:Importing untrained model
2023-04-26 16:40:38,715:INFO:Passive Aggressive Regressor Imported successfully
2023-04-26 16:40:38,715:INFO:Starting cross validation
2023-04-26 16:40:38,717:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-26 16:40:41,424:INFO:Calculating mean and std
2023-04-26 16:40:41,426:INFO:Creating metrics dataframe
2023-04-26 16:40:41,833:INFO:Uploading results into container
2023-04-26 16:40:41,834:INFO:Uploading model into container now
2023-04-26 16:40:41,835:INFO:_master_model_container: 9
2023-04-26 16:40:41,835:INFO:_display_container: 2
2023-04-26 16:40:41,836:INFO:PassiveAggressiveRegressor(random_state=6541)
2023-04-26 16:40:41,836:INFO:create_model() successfully completed......................................
2023-04-26 16:40:42,016:INFO:SubProcess create_model() end ==================================
2023-04-26 16:40:42,016:INFO:Creating metrics dataframe
2023-04-26 16:40:42,025:INFO:Initializing Huber Regressor
2023-04-26 16:40:42,025:INFO:Total runtime is 0.6131205240885418 minutes
2023-04-26 16:40:42,025:INFO:SubProcess create_model() called ==================================
2023-04-26 16:40:42,026:INFO:Initializing create_model()
2023-04-26 16:40:42,026:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAB0ACAAC0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAB10C2970>, model_only=True, return_train_score=False, kwargs={})
2023-04-26 16:40:42,026:INFO:Checking exceptions
2023-04-26 16:40:42,026:INFO:Importing libraries
2023-04-26 16:40:42,026:INFO:Copying training dataset
2023-04-26 16:40:42,032:INFO:Defining folds
2023-04-26 16:40:42,032:INFO:Declaring metric variables
2023-04-26 16:40:42,032:INFO:Importing untrained model
2023-04-26 16:40:42,034:INFO:Huber Regressor Imported successfully
2023-04-26 16:40:42,034:INFO:Starting cross validation
2023-04-26 16:40:42,035:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-26 16:40:44,885:INFO:Calculating mean and std
2023-04-26 16:40:44,886:INFO:Creating metrics dataframe
2023-04-26 16:40:45,356:INFO:Uploading results into container
2023-04-26 16:40:45,357:INFO:Uploading model into container now
2023-04-26 16:40:45,358:INFO:_master_model_container: 10
2023-04-26 16:40:45,358:INFO:_display_container: 2
2023-04-26 16:40:45,358:INFO:HuberRegressor()
2023-04-26 16:40:45,358:INFO:create_model() successfully completed......................................
2023-04-26 16:40:45,536:INFO:SubProcess create_model() end ==================================
2023-04-26 16:40:45,536:INFO:Creating metrics dataframe
2023-04-26 16:40:45,545:INFO:Initializing K Neighbors Regressor
2023-04-26 16:40:45,546:INFO:Total runtime is 0.6718041300773622 minutes
2023-04-26 16:40:45,546:INFO:SubProcess create_model() called ==================================
2023-04-26 16:40:45,546:INFO:Initializing create_model()
2023-04-26 16:40:45,547:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAB0ACAAC0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAB10C2970>, model_only=True, return_train_score=False, kwargs={})
2023-04-26 16:40:45,547:INFO:Checking exceptions
2023-04-26 16:40:45,547:INFO:Importing libraries
2023-04-26 16:40:45,547:INFO:Copying training dataset
2023-04-26 16:40:45,554:INFO:Defining folds
2023-04-26 16:40:45,554:INFO:Declaring metric variables
2023-04-26 16:40:45,555:INFO:Importing untrained model
2023-04-26 16:40:45,556:INFO:K Neighbors Regressor Imported successfully
2023-04-26 16:40:45,557:INFO:Starting cross validation
2023-04-26 16:40:45,558:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-26 16:40:48,431:INFO:Calculating mean and std
2023-04-26 16:40:48,433:INFO:Creating metrics dataframe
2023-04-26 16:40:48,898:INFO:Uploading results into container
2023-04-26 16:40:48,900:INFO:Uploading model into container now
2023-04-26 16:40:48,900:INFO:_master_model_container: 11
2023-04-26 16:40:48,901:INFO:_display_container: 2
2023-04-26 16:40:48,901:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-26 16:40:48,901:INFO:create_model() successfully completed......................................
2023-04-26 16:40:49,076:INFO:SubProcess create_model() end ==================================
2023-04-26 16:40:49,078:INFO:Creating metrics dataframe
2023-04-26 16:40:49,088:INFO:Initializing Decision Tree Regressor
2023-04-26 16:40:49,088:INFO:Total runtime is 0.7308407386144004 minutes
2023-04-26 16:40:49,090:INFO:SubProcess create_model() called ==================================
2023-04-26 16:40:49,090:INFO:Initializing create_model()
2023-04-26 16:40:49,090:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAB0ACAAC0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAB10C2970>, model_only=True, return_train_score=False, kwargs={})
2023-04-26 16:40:49,090:INFO:Checking exceptions
2023-04-26 16:40:49,090:INFO:Importing libraries
2023-04-26 16:40:49,090:INFO:Copying training dataset
2023-04-26 16:40:49,097:INFO:Defining folds
2023-04-26 16:40:49,097:INFO:Declaring metric variables
2023-04-26 16:40:49,098:INFO:Importing untrained model
2023-04-26 16:40:49,099:INFO:Decision Tree Regressor Imported successfully
2023-04-26 16:40:49,099:INFO:Starting cross validation
2023-04-26 16:40:49,100:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-26 16:40:51,942:INFO:Calculating mean and std
2023-04-26 16:40:51,943:INFO:Creating metrics dataframe
2023-04-26 16:40:52,385:INFO:Uploading results into container
2023-04-26 16:40:52,387:INFO:Uploading model into container now
2023-04-26 16:40:52,387:INFO:_master_model_container: 12
2023-04-26 16:40:52,388:INFO:_display_container: 2
2023-04-26 16:40:52,388:INFO:DecisionTreeRegressor(random_state=6541)
2023-04-26 16:40:52,388:INFO:create_model() successfully completed......................................
2023-04-26 16:40:52,562:INFO:SubProcess create_model() end ==================================
2023-04-26 16:40:52,563:INFO:Creating metrics dataframe
2023-04-26 16:40:52,573:INFO:Initializing Random Forest Regressor
2023-04-26 16:40:52,573:INFO:Total runtime is 0.7889123121897381 minutes
2023-04-26 16:40:52,573:INFO:SubProcess create_model() called ==================================
2023-04-26 16:40:52,574:INFO:Initializing create_model()
2023-04-26 16:40:52,574:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAB0ACAAC0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAB10C2970>, model_only=True, return_train_score=False, kwargs={})
2023-04-26 16:40:52,574:INFO:Checking exceptions
2023-04-26 16:40:52,574:INFO:Importing libraries
2023-04-26 16:40:52,575:INFO:Copying training dataset
2023-04-26 16:40:52,581:INFO:Defining folds
2023-04-26 16:40:52,581:INFO:Declaring metric variables
2023-04-26 16:40:52,582:INFO:Importing untrained model
2023-04-26 16:40:52,583:INFO:Random Forest Regressor Imported successfully
2023-04-26 16:40:52,583:INFO:Starting cross validation
2023-04-26 16:40:52,585:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-26 16:40:56,529:INFO:Calculating mean and std
2023-04-26 16:40:56,530:INFO:Creating metrics dataframe
2023-04-26 16:40:56,902:INFO:Uploading results into container
2023-04-26 16:40:56,904:INFO:Uploading model into container now
2023-04-26 16:40:56,905:INFO:_master_model_container: 13
2023-04-26 16:40:56,905:INFO:_display_container: 2
2023-04-26 16:40:56,905:INFO:RandomForestRegressor(n_jobs=-1, random_state=6541)
2023-04-26 16:40:56,905:INFO:create_model() successfully completed......................................
2023-04-26 16:40:57,080:INFO:SubProcess create_model() end ==================================
2023-04-26 16:40:57,081:INFO:Creating metrics dataframe
2023-04-26 16:40:57,090:INFO:Initializing Extra Trees Regressor
2023-04-26 16:40:57,090:INFO:Total runtime is 0.8642072240511578 minutes
2023-04-26 16:40:57,090:INFO:SubProcess create_model() called ==================================
2023-04-26 16:40:57,092:INFO:Initializing create_model()
2023-04-26 16:40:57,092:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAB0ACAAC0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAB10C2970>, model_only=True, return_train_score=False, kwargs={})
2023-04-26 16:40:57,092:INFO:Checking exceptions
2023-04-26 16:40:57,092:INFO:Importing libraries
2023-04-26 16:40:57,092:INFO:Copying training dataset
2023-04-26 16:40:57,099:INFO:Defining folds
2023-04-26 16:40:57,099:INFO:Declaring metric variables
2023-04-26 16:40:57,100:INFO:Importing untrained model
2023-04-26 16:40:57,100:INFO:Extra Trees Regressor Imported successfully
2023-04-26 16:40:57,101:INFO:Starting cross validation
2023-04-26 16:40:57,103:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-26 16:41:00,684:INFO:Calculating mean and std
2023-04-26 16:41:00,687:INFO:Creating metrics dataframe
2023-04-26 16:41:01,126:INFO:Uploading results into container
2023-04-26 16:41:01,127:INFO:Uploading model into container now
2023-04-26 16:41:01,128:INFO:_master_model_container: 14
2023-04-26 16:41:01,128:INFO:_display_container: 2
2023-04-26 16:41:01,130:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6541)
2023-04-26 16:41:01,130:INFO:create_model() successfully completed......................................
2023-04-26 16:41:01,294:INFO:SubProcess create_model() end ==================================
2023-04-26 16:41:01,294:INFO:Creating metrics dataframe
2023-04-26 16:41:01,301:INFO:Initializing AdaBoost Regressor
2023-04-26 16:41:01,301:INFO:Total runtime is 0.93438990910848 minutes
2023-04-26 16:41:01,301:INFO:SubProcess create_model() called ==================================
2023-04-26 16:41:01,301:INFO:Initializing create_model()
2023-04-26 16:41:01,301:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAB0ACAAC0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAB10C2970>, model_only=True, return_train_score=False, kwargs={})
2023-04-26 16:41:01,301:INFO:Checking exceptions
2023-04-26 16:41:01,301:INFO:Importing libraries
2023-04-26 16:41:01,301:INFO:Copying training dataset
2023-04-26 16:41:01,306:INFO:Defining folds
2023-04-26 16:41:01,306:INFO:Declaring metric variables
2023-04-26 16:41:01,307:INFO:Importing untrained model
2023-04-26 16:41:01,307:INFO:AdaBoost Regressor Imported successfully
2023-04-26 16:41:01,308:INFO:Starting cross validation
2023-04-26 16:41:01,310:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-26 16:41:04,801:INFO:Calculating mean and std
2023-04-26 16:41:04,802:INFO:Creating metrics dataframe
2023-04-26 16:41:05,263:INFO:Uploading results into container
2023-04-26 16:41:05,265:INFO:Uploading model into container now
2023-04-26 16:41:05,266:INFO:_master_model_container: 15
2023-04-26 16:41:05,266:INFO:_display_container: 2
2023-04-26 16:41:05,266:INFO:AdaBoostRegressor(random_state=6541)
2023-04-26 16:41:05,266:INFO:create_model() successfully completed......................................
2023-04-26 16:41:05,435:INFO:SubProcess create_model() end ==================================
2023-04-26 16:41:05,435:INFO:Creating metrics dataframe
2023-04-26 16:41:05,446:INFO:Initializing Gradient Boosting Regressor
2023-04-26 16:41:05,446:INFO:Total runtime is 1.0034640510876975 minutes
2023-04-26 16:41:05,447:INFO:SubProcess create_model() called ==================================
2023-04-26 16:41:05,447:INFO:Initializing create_model()
2023-04-26 16:41:05,447:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAB0ACAAC0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAB10C2970>, model_only=True, return_train_score=False, kwargs={})
2023-04-26 16:41:05,448:INFO:Checking exceptions
2023-04-26 16:41:05,448:INFO:Importing libraries
2023-04-26 16:41:05,448:INFO:Copying training dataset
2023-04-26 16:41:05,456:INFO:Defining folds
2023-04-26 16:41:05,456:INFO:Declaring metric variables
2023-04-26 16:41:05,457:INFO:Importing untrained model
2023-04-26 16:41:05,458:INFO:Gradient Boosting Regressor Imported successfully
2023-04-26 16:41:05,458:INFO:Starting cross validation
2023-04-26 16:41:05,460:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-26 16:41:08,740:INFO:Calculating mean and std
2023-04-26 16:41:08,742:INFO:Creating metrics dataframe
2023-04-26 16:41:09,229:INFO:Uploading results into container
2023-04-26 16:41:09,230:INFO:Uploading model into container now
2023-04-26 16:41:09,231:INFO:_master_model_container: 16
2023-04-26 16:41:09,231:INFO:_display_container: 2
2023-04-26 16:41:09,233:INFO:GradientBoostingRegressor(random_state=6541)
2023-04-26 16:41:09,233:INFO:create_model() successfully completed......................................
2023-04-26 16:41:09,409:INFO:SubProcess create_model() end ==================================
2023-04-26 16:41:09,410:INFO:Creating metrics dataframe
2023-04-26 16:41:09,419:INFO:Initializing Light Gradient Boosting Machine
2023-04-26 16:41:09,419:INFO:Total runtime is 1.069688653945923 minutes
2023-04-26 16:41:09,419:INFO:SubProcess create_model() called ==================================
2023-04-26 16:41:09,421:INFO:Initializing create_model()
2023-04-26 16:41:09,421:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAB0ACAAC0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAB10C2970>, model_only=True, return_train_score=False, kwargs={})
2023-04-26 16:41:09,421:INFO:Checking exceptions
2023-04-26 16:41:09,421:INFO:Importing libraries
2023-04-26 16:41:09,421:INFO:Copying training dataset
2023-04-26 16:41:09,428:INFO:Defining folds
2023-04-26 16:41:09,429:INFO:Declaring metric variables
2023-04-26 16:41:09,429:INFO:Importing untrained model
2023-04-26 16:41:09,431:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-26 16:41:09,431:INFO:Starting cross validation
2023-04-26 16:41:09,432:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-26 16:41:14,166:INFO:Calculating mean and std
2023-04-26 16:41:14,167:INFO:Creating metrics dataframe
2023-04-26 16:41:14,634:INFO:Uploading results into container
2023-04-26 16:41:14,635:INFO:Uploading model into container now
2023-04-26 16:41:14,636:INFO:_master_model_container: 17
2023-04-26 16:41:14,636:INFO:_display_container: 2
2023-04-26 16:41:14,637:INFO:LGBMRegressor(random_state=6541)
2023-04-26 16:41:14,637:INFO:create_model() successfully completed......................................
2023-04-26 16:41:14,807:INFO:SubProcess create_model() end ==================================
2023-04-26 16:41:14,807:INFO:Creating metrics dataframe
2023-04-26 16:41:14,816:INFO:Initializing Dummy Regressor
2023-04-26 16:41:14,816:INFO:Total runtime is 1.1596404631932578 minutes
2023-04-26 16:41:14,817:INFO:SubProcess create_model() called ==================================
2023-04-26 16:41:14,817:INFO:Initializing create_model()
2023-04-26 16:41:14,817:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAB0ACAAC0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAB10C2970>, model_only=True, return_train_score=False, kwargs={})
2023-04-26 16:41:14,817:INFO:Checking exceptions
2023-04-26 16:41:14,817:INFO:Importing libraries
2023-04-26 16:41:14,819:INFO:Copying training dataset
2023-04-26 16:41:14,824:INFO:Defining folds
2023-04-26 16:41:14,825:INFO:Declaring metric variables
2023-04-26 16:41:14,825:INFO:Importing untrained model
2023-04-26 16:41:14,826:INFO:Dummy Regressor Imported successfully
2023-04-26 16:41:14,826:INFO:Starting cross validation
2023-04-26 16:41:14,828:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-26 16:41:17,882:INFO:Calculating mean and std
2023-04-26 16:41:17,883:INFO:Creating metrics dataframe
2023-04-26 16:41:18,384:INFO:Uploading results into container
2023-04-26 16:41:18,386:INFO:Uploading model into container now
2023-04-26 16:41:18,387:INFO:_master_model_container: 18
2023-04-26 16:41:18,387:INFO:_display_container: 2
2023-04-26 16:41:18,387:INFO:DummyRegressor()
2023-04-26 16:41:18,387:INFO:create_model() successfully completed......................................
2023-04-26 16:41:18,563:INFO:SubProcess create_model() end ==================================
2023-04-26 16:41:18,563:INFO:Creating metrics dataframe
2023-04-26 16:41:18,579:INFO:Initializing create_model()
2023-04-26 16:41:18,579:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAB0ACAAC0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=6541), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-26 16:41:18,579:INFO:Checking exceptions
2023-04-26 16:41:18,580:INFO:Importing libraries
2023-04-26 16:41:18,581:INFO:Copying training dataset
2023-04-26 16:41:18,587:INFO:Defining folds
2023-04-26 16:41:18,587:INFO:Declaring metric variables
2023-04-26 16:41:18,588:INFO:Importing untrained model
2023-04-26 16:41:18,588:INFO:Declaring custom model
2023-04-26 16:41:18,589:INFO:Extra Trees Regressor Imported successfully
2023-04-26 16:41:18,591:INFO:Cross validation set to False
2023-04-26 16:41:18,591:INFO:Fitting Model
2023-04-26 16:41:19,283:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6541)
2023-04-26 16:41:19,283:INFO:create_model() successfully completed......................................
2023-04-26 16:41:19,499:INFO:_master_model_container: 18
2023-04-26 16:41:19,499:INFO:_display_container: 2
2023-04-26 16:41:19,501:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6541)
2023-04-26 16:41:19,501:INFO:compare_models() successfully completed......................................
2023-04-26 16:41:19,510:INFO:Initializing save_model()
2023-04-26 16:41:19,511:INFO:save_model(model=ExtraTreesRegressor(n_jobs=-1, random_state=6541), model_name=best_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\91888\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['TV', 'Radio', 'Newspaper'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-04-26 16:41:19,511:INFO:Adding model into prep_pipe
2023-04-26 16:41:19,601:INFO:best_model.pkl saved in current working directory
2023-04-26 16:41:19,614:INFO:Pipeline(memory=FastMemory(location=C:\Users\91888\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['TV', 'Radio', 'Newspaper'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('trained_model',
                 ExtraTreesRegressor(n_jobs=-1, random_state=6541))])
2023-04-26 16:41:19,615:INFO:save_model() successfully completed......................................
2023-04-26 16:41:20,065:INFO:Initializing plot_model()
2023-04-26 16:41:20,065:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=6541), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAB0ACAAC0>, system=True)
2023-04-26 16:41:20,065:INFO:Checking exceptions
2023-04-26 16:41:20,099:INFO:Preloading libraries
2023-04-26 16:41:20,121:INFO:Copying training dataset
2023-04-26 16:41:20,121:INFO:Plot type: residuals
2023-04-26 16:41:20,540:INFO:Fitting Model
2023-04-26 16:41:20,541:WARNING:C:\Users\91888\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning:

X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names


2023-04-26 16:41:20,710:INFO:Scoring test/hold-out set
2023-04-26 16:41:20,879:WARNING:C:\Users\91888\anaconda3\lib\site-packages\yellowbrick\base.py:246: UserWarning:

Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.


2023-04-26 16:41:20,962:INFO:Visual Rendered Successfully
2023-04-26 16:41:21,152:INFO:plot_model() successfully completed......................................
